{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "# import cvxpy as cvx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "from pandas_datareader.data import DataReader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm \n",
    "from functools import reduce\n",
    "from math import sqrt, exp\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly data\n",
    "# returns dataframe\n",
    "\n",
    "def get_data_for_multiple_stocks_monthly(tickers, start_date, end_date):\n",
    "    \n",
    "    stocks = pd.DataFrame()\n",
    "\n",
    "    for ticker in tickers:\n",
    "        s = web.get_data_yahoo(ticker, start_date, end_date, interval='m')\n",
    "        \n",
    "        stocks[ticker+\" adj_close\"] = s['Adj Close']\n",
    "        stocks[ticker + ' prev_close'] = s['Adj Close'].shift(1)\n",
    "        stocks[ticker+\" log_returns\"] = np.log(s['Adj Close']/s['Adj Close'].shift(1))\n",
    "        \n",
    "    return stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily data\n",
    "# returns dataframe\n",
    "\n",
    "def get_data_for_multiple_stocks_daily(tickers, start_date, end_date):\n",
    "    \n",
    "    stocks = pd.DataFrame()\n",
    "\n",
    "    for ticker in tickers:\n",
    "        s = web.get_data_yahoo(ticker, start_date, end_date, interval='d')\n",
    "        \n",
    "        stocks[ticker+\" adj_close\"] = s['Adj Close']\n",
    "        stocks[ticker + ' prev_close'] = s['Adj Close'].shift(1)\n",
    "        stocks[ticker+\" log_returns\"] = np.log(s['Adj Close']/s['Adj Close'].shift(1))\n",
    "        \n",
    "    return stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PREVIOUS\n",
    "\n",
    "# def get_data_for_multiple_stocks(tickers, start_date, end_date):\n",
    "\n",
    "#     s = web.get_data_yahoo(tickers[0], start_date, end_date, interval='d')[[\"Adj Close\"]]\n",
    "#     # get log returns\n",
    "#     s[tickers[0]+\" adj_close\"] = s['Adj Close']\n",
    "#     s[tickers[0]+\" log_returns\"] = np.log(s['Adj Close']/s['Adj Close'].shift(1))\n",
    "#     s[tickers[0] + ' prev close'] = s['Adj Close'].shift(1)\n",
    "#     stocks = s[[tickers[0]+\" adj_close\"]]\n",
    "#     stocks[tickers[0]+\" log_returns\"] = s[tickers[0]+\" log_returns\"]\n",
    "#     stocks[tickers[0] + ' prev close'] = s[tickers[0] + ' prev close']\n",
    "\n",
    "#     for ticker in tickers[1:]:\n",
    "#         s = web.get_data_yahoo(ticker, start_date, end_date, interval='m')\n",
    "#         s[ticker+\" adj_close\"] = s['Adj Close'] # adj close price\n",
    "#         s[ticker+\" log_returns\"] = np.log(s['Adj Close']/s['Adj Close'].shift(1))\n",
    "#         s[ticker + ' prev close'] = s['Adj Close'].shift(1)\n",
    "#         stocks[ticker+\" adj_close\"] = s[ticker+\" adj_close\"]\n",
    "#         stocks[ticker+\" log_returns\"] = s[ticker+\" log_returns\"]\n",
    "#         stocks[ticker + ' prev close'] = s[ticker + ' prev close']\n",
    "#      #except KeyError:\n",
    "#        #pass\n",
    "#     # skip first row that will be na, and fillna by 0 incase there are trading halts on specific days\n",
    "#     return stocks#stocks.iloc[1:].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PREVIOUS\n",
    "\n",
    "# def get_data_for_multiple_stocks_daily(tickers, start_date, end_date):\n",
    "\n",
    "#     s = web.get_data_yahoo(tickers[0], start_date, end_date, interval='d')[[\"Adj Close\"]]\n",
    "#     # get log returns\n",
    "#     s[tickers[0]+\" adj_close\"] = s['Adj Close']\n",
    "#     s[tickers[0]+\" log_returns\"] = np.log(s['Adj Close']/s['Adj Close'].shift(1))\n",
    "#     s[tickers[0] + ' prev close'] = s['Adj Close'].shift(1)\n",
    "#     stocks = s[[tickers[0]+\" adj_close\"]]\n",
    "#     stocks[tickers[0]+\" log_returns\"] = s[tickers[0]+\" log_returns\"]\n",
    "#     stocks[tickers[0] + ' prev close'] = s[tickers[0] + ' prev close']\n",
    "\n",
    "#     for ticker in tickers[1:]:\n",
    "#         s = web.get_data_yahoo(ticker, start_date, end_date, interval='d')\n",
    "#         s[ticker+\" adj_close\"] = s['Adj Close'] # adj close price\n",
    "#         s[ticker+\" log_returns\"] = np.log(s['Adj Close']/s['Adj Close'].shift(1))\n",
    "#         s[ticker + ' prev close'] = s['Adj Close'].shift(1)\n",
    "#         stocks[ticker+\" adj_close\"] = s[ticker+\" adj_close\"]\n",
    "#         stocks[ticker+\" log_returns\"] = s[ticker+\" log_returns\"]\n",
    "#         stocks[ticker + ' prev close'] = s[ticker + ' prev close']\n",
    "#      #except KeyError:\n",
    "#        #pass\n",
    "#     # skip first row that will be na, and fillna by 0 incase there are trading halts on specific days\n",
    "#     return stocks#stocks.iloc[1:].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns for best portfolio (FSTPX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_best = [\"AAPL\", \"MSFT\", \"ADBE\", \"CRM\", \"NVDA\", \"MA\", \"PYPL\", \"V\", \"MU\", \"FIS\",\n",
    "           \"LRCX\", \"FB\", \"AMAT\", \"QCOM\", \"TWLO\", \"WDAY\", \"AMZN\", \"INTU\", \"ADSK\", \"AMD\",\n",
    "           \"HUBS\", \"MELI\", \"ESTC\", \"G\", \"GDDY\", \"FLEX\", \"MDB\", \"NXPI\", \"FISV\", \"MRVL\"]\n",
    "\n",
    "returns_df_best = get_data_for_multiple_stocks_monthly(tickers_best,\n",
    "                                          start_date = \"2019-12-01\", end_date = \"2020-10-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>ADBE adj_close</th>\n",
       "      <th>ADBE prev_close</th>\n",
       "      <th>ADBE log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>MDB log_returns</th>\n",
       "      <th>NXPI adj_close</th>\n",
       "      <th>NXPI prev_close</th>\n",
       "      <th>NXPI log_returns</th>\n",
       "      <th>FISV adj_close</th>\n",
       "      <th>FISV prev_close</th>\n",
       "      <th>FISV log_returns</th>\n",
       "      <th>MRVL adj_close</th>\n",
       "      <th>MRVL prev_close</th>\n",
       "      <th>MRVL log_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>76.091995</td>\n",
       "      <td>72.192863</td>\n",
       "      <td>0.052602</td>\n",
       "      <td>168.886551</td>\n",
       "      <td>156.455429</td>\n",
       "      <td>0.076456</td>\n",
       "      <td>351.140015</td>\n",
       "      <td>329.809998</td>\n",
       "      <td>0.062668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219475</td>\n",
       "      <td>125.501968</td>\n",
       "      <td>125.516884</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>118.610001</td>\n",
       "      <td>115.629997</td>\n",
       "      <td>0.025445</td>\n",
       "      <td>23.901917</td>\n",
       "      <td>26.347651</td>\n",
       "      <td>-0.097420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>67.204628</td>\n",
       "      <td>76.091995</td>\n",
       "      <td>-0.124201</td>\n",
       "      <td>160.731430</td>\n",
       "      <td>168.886551</td>\n",
       "      <td>-0.049492</td>\n",
       "      <td>345.119995</td>\n",
       "      <td>351.140015</td>\n",
       "      <td>-0.017293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072153</td>\n",
       "      <td>112.472961</td>\n",
       "      <td>125.501968</td>\n",
       "      <td>-0.109609</td>\n",
       "      <td>109.360001</td>\n",
       "      <td>118.610001</td>\n",
       "      <td>-0.081196</td>\n",
       "      <td>21.177654</td>\n",
       "      <td>23.901917</td>\n",
       "      <td>-0.121012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>62.664707</td>\n",
       "      <td>67.204628</td>\n",
       "      <td>-0.069944</td>\n",
       "      <td>156.892731</td>\n",
       "      <td>160.731430</td>\n",
       "      <td>-0.024173</td>\n",
       "      <td>318.239990</td>\n",
       "      <td>345.119995</td>\n",
       "      <td>-0.081086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110547</td>\n",
       "      <td>82.042236</td>\n",
       "      <td>112.472961</td>\n",
       "      <td>-0.315479</td>\n",
       "      <td>94.989998</td>\n",
       "      <td>109.360001</td>\n",
       "      <td>-0.140874</td>\n",
       "      <td>22.500013</td>\n",
       "      <td>21.177654</td>\n",
       "      <td>0.060569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>72.401154</td>\n",
       "      <td>62.664707</td>\n",
       "      <td>0.144424</td>\n",
       "      <td>178.281311</td>\n",
       "      <td>156.892731</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>353.640015</td>\n",
       "      <td>318.239990</td>\n",
       "      <td>0.105474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171781</td>\n",
       "      <td>98.907402</td>\n",
       "      <td>82.042236</td>\n",
       "      <td>0.186950</td>\n",
       "      <td>103.059998</td>\n",
       "      <td>94.989998</td>\n",
       "      <td>0.081540</td>\n",
       "      <td>26.586407</td>\n",
       "      <td>22.500013</td>\n",
       "      <td>0.166884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>78.349983</td>\n",
       "      <td>72.401154</td>\n",
       "      <td>0.078964</td>\n",
       "      <td>182.300385</td>\n",
       "      <td>178.281311</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>386.600006</td>\n",
       "      <td>353.640015</td>\n",
       "      <td>0.089111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358813</td>\n",
       "      <td>95.460487</td>\n",
       "      <td>98.907402</td>\n",
       "      <td>-0.035472</td>\n",
       "      <td>106.769997</td>\n",
       "      <td>103.059998</td>\n",
       "      <td>0.035366</td>\n",
       "      <td>32.522808</td>\n",
       "      <td>26.586407</td>\n",
       "      <td>0.201542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>90.879066</td>\n",
       "      <td>78.349983</td>\n",
       "      <td>0.148344</td>\n",
       "      <td>203.019226</td>\n",
       "      <td>182.300385</td>\n",
       "      <td>0.107645</td>\n",
       "      <td>435.309998</td>\n",
       "      <td>386.600006</td>\n",
       "      <td>0.118668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025173</td>\n",
       "      <td>113.281105</td>\n",
       "      <td>95.460487</td>\n",
       "      <td>0.171160</td>\n",
       "      <td>97.620003</td>\n",
       "      <td>106.769997</td>\n",
       "      <td>-0.089595</td>\n",
       "      <td>34.955540</td>\n",
       "      <td>32.522808</td>\n",
       "      <td>0.072135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>105.886086</td>\n",
       "      <td>90.879066</td>\n",
       "      <td>0.152834</td>\n",
       "      <td>204.515610</td>\n",
       "      <td>203.019226</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>444.320007</td>\n",
       "      <td>435.309998</td>\n",
       "      <td>0.020487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012033</td>\n",
       "      <td>117.176697</td>\n",
       "      <td>113.281105</td>\n",
       "      <td>0.033811</td>\n",
       "      <td>99.790001</td>\n",
       "      <td>97.620003</td>\n",
       "      <td>0.021986</td>\n",
       "      <td>36.361336</td>\n",
       "      <td>34.955540</td>\n",
       "      <td>0.039429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>128.585907</td>\n",
       "      <td>105.886086</td>\n",
       "      <td>0.194233</td>\n",
       "      <td>224.986130</td>\n",
       "      <td>204.515610</td>\n",
       "      <td>0.095394</td>\n",
       "      <td>513.390015</td>\n",
       "      <td>444.320007</td>\n",
       "      <td>0.144491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>125.381966</td>\n",
       "      <td>117.176697</td>\n",
       "      <td>0.067682</td>\n",
       "      <td>99.580002</td>\n",
       "      <td>99.790001</td>\n",
       "      <td>-0.002107</td>\n",
       "      <td>38.725403</td>\n",
       "      <td>36.361336</td>\n",
       "      <td>0.062990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>128.585907</td>\n",
       "      <td>-0.106370</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>224.986130</td>\n",
       "      <td>-0.067361</td>\n",
       "      <td>490.429993</td>\n",
       "      <td>513.390015</td>\n",
       "      <td>-0.045753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009843</td>\n",
       "      <td>124.434814</td>\n",
       "      <td>125.381966</td>\n",
       "      <td>-0.007583</td>\n",
       "      <td>103.050003</td>\n",
       "      <td>99.580002</td>\n",
       "      <td>0.034253</td>\n",
       "      <td>39.644112</td>\n",
       "      <td>38.725403</td>\n",
       "      <td>0.023447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>-0.061888</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>447.100006</td>\n",
       "      <td>490.429993</td>\n",
       "      <td>-0.092500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013218</td>\n",
       "      <td>135.119995</td>\n",
       "      <td>124.434814</td>\n",
       "      <td>0.082381</td>\n",
       "      <td>95.470001</td>\n",
       "      <td>103.050003</td>\n",
       "      <td>-0.076402</td>\n",
       "      <td>37.457191</td>\n",
       "      <td>39.644112</td>\n",
       "      <td>-0.056744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AAPL adj_close  AAPL prev_close  AAPL log_returns  \\\n",
       "0 2020-01-01       76.091995        72.192863          0.052602   \n",
       "1 2020-02-01       67.204628        76.091995         -0.124201   \n",
       "2 2020-03-01       62.664707        67.204628         -0.069944   \n",
       "3 2020-04-01       72.401154        62.664707          0.144424   \n",
       "4 2020-05-01       78.349983        72.401154          0.078964   \n",
       "5 2020-06-01       90.879066        78.349983          0.148344   \n",
       "6 2020-07-01      105.886086        90.879066          0.152834   \n",
       "7 2020-08-01      128.585907       105.886086          0.194233   \n",
       "8 2020-09-01      115.610542       128.585907         -0.106370   \n",
       "9 2020-10-01      108.672516       115.610542         -0.061888   \n",
       "\n",
       "   MSFT adj_close  MSFT prev_close  MSFT log_returns  ADBE adj_close  \\\n",
       "0      168.886551       156.455429          0.076456      351.140015   \n",
       "1      160.731430       168.886551         -0.049492      345.119995   \n",
       "2      156.892731       160.731430         -0.024173      318.239990   \n",
       "3      178.281311       156.892731          0.127800      353.640015   \n",
       "4      182.300385       178.281311          0.022293      386.600006   \n",
       "5      203.019226       182.300385          0.107645      435.309998   \n",
       "6      204.515610       203.019226          0.007344      444.320007   \n",
       "7      224.986130       204.515610          0.095394      513.390015   \n",
       "8      210.330002       224.986130         -0.067361      490.429993   \n",
       "9      202.470001       210.330002         -0.038086      447.100006   \n",
       "\n",
       "   ADBE prev_close  ADBE log_returns  ...  MDB log_returns  NXPI adj_close  \\\n",
       "0       329.809998          0.062668  ...         0.219475      125.501968   \n",
       "1       351.140015         -0.017293  ...        -0.072153      112.472961   \n",
       "2       345.119995         -0.081086  ...        -0.110547       82.042236   \n",
       "3       318.239990          0.105474  ...         0.171781       98.907402   \n",
       "4       353.640015          0.089111  ...         0.358813       95.460487   \n",
       "5       386.600006          0.118668  ...        -0.025173      113.281105   \n",
       "6       435.309998          0.020487  ...         0.012033      117.176697   \n",
       "7       444.320007          0.144491  ...         0.020395      125.381966   \n",
       "8       513.390015         -0.045753  ...        -0.009843      124.434814   \n",
       "9       490.429993         -0.092500  ...        -0.013218      135.119995   \n",
       "\n",
       "   NXPI prev_close  NXPI log_returns  FISV adj_close  FISV prev_close  \\\n",
       "0       125.516884         -0.000119      118.610001       115.629997   \n",
       "1       125.501968         -0.109609      109.360001       118.610001   \n",
       "2       112.472961         -0.315479       94.989998       109.360001   \n",
       "3        82.042236          0.186950      103.059998        94.989998   \n",
       "4        98.907402         -0.035472      106.769997       103.059998   \n",
       "5        95.460487          0.171160       97.620003       106.769997   \n",
       "6       113.281105          0.033811       99.790001        97.620003   \n",
       "7       117.176697          0.067682       99.580002        99.790001   \n",
       "8       125.381966         -0.007583      103.050003        99.580002   \n",
       "9       124.434814          0.082381       95.470001       103.050003   \n",
       "\n",
       "   FISV log_returns  MRVL adj_close  MRVL prev_close  MRVL log_returns  \n",
       "0          0.025445       23.901917        26.347651         -0.097420  \n",
       "1         -0.081196       21.177654        23.901917         -0.121012  \n",
       "2         -0.140874       22.500013        21.177654          0.060569  \n",
       "3          0.081540       26.586407        22.500013          0.166884  \n",
       "4          0.035366       32.522808        26.586407          0.201542  \n",
       "5         -0.089595       34.955540        32.522808          0.072135  \n",
       "6          0.021986       36.361336        34.955540          0.039429  \n",
       "7         -0.002107       38.725403        36.361336          0.062990  \n",
       "8          0.034253       39.644112        38.725403          0.023447  \n",
       "9         -0.076402       37.457191        39.644112         -0.056744  \n",
       "\n",
       "[10 rows x 91 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_best.dropna(inplace = True)\n",
    "returns_df_best.reset_index(inplace=True)\n",
    "returns_df_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15956934.0, 7219840.0, 641861.0, 1070184.0, 445652.0, 613139.0, 1040187.0, 879814.0, 4066983.0, 1191646.0, 493512.0, 553108.0, 2638331.0, 1226502.0, 452186.0, 497271.0, 33655.0, 327091.0, 443415.0, 1190949.0, 353309.0, 85322.0, 904051.0, 2111030.0, 996333.0, 7011334.0, 318341.0, 558207.0, 669494.0, 1595579.0]\n"
     ]
    }
   ],
   "source": [
    "array_values_best = [2051836821, 1624363933, 329525040, 291785537, 238343597, 219364830, 212343810, 186230240, 185088374, 179336117, 165346944, 162171231, 161982940, 145298238, 121981574, 119200951,116143756, 112774797, 108946944,108161967, 105879493, 99706579, 98161895, 88818510, 83373164, 76143081, 74428092, 69989115, 66668202, 61789443]\n",
    "\n",
    "array_price = []\n",
    "for i in range(len(tickers_best)):\n",
    "    x = returns_df_best.loc[returns_df_best['Date']=='2020-08-01'][tickers_best[i]+' adj_close'].values\n",
    "    array_price.append(x)\n",
    "    \n",
    "shares = []\n",
    "for i in range(len(array_price)):\n",
    "    shares.append(np.round(array_values_best[i]/array_price[i],0)[0])\n",
    "\n",
    "print(shares)\n",
    "# values = sum of adj close price * num of shares of all stocks\n",
    "\n",
    "total = 0\n",
    "for y in range(len(shares)):\n",
    "    total += (returns_df_best[tickers_best[y]+\" prev_close\"]*shares[y])\n",
    "    \n",
    "for y in range(len(shares)):\n",
    "    returns_df_best[\"value\"] = total\n",
    "\n",
    "for x in range(len(shares)):\n",
    "    returns_df_best[tickers_best[x]+\"_weight\"] = (returns_df_best[tickers_best[x]+\" prev_close\"]*shares[x])/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>ADBE adj_close</th>\n",
       "      <th>ADBE prev_close</th>\n",
       "      <th>ADBE log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>MELI_weight</th>\n",
       "      <th>ESTC_weight</th>\n",
       "      <th>G_weight</th>\n",
       "      <th>GDDY_weight</th>\n",
       "      <th>FLEX_weight</th>\n",
       "      <th>MDB_weight</th>\n",
       "      <th>NXPI_weight</th>\n",
       "      <th>FISV_weight</th>\n",
       "      <th>MRVL_weight</th>\n",
       "      <th>portfolio return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>76.091995</td>\n",
       "      <td>72.192863</td>\n",
       "      <td>0.052602</td>\n",
       "      <td>168.886551</td>\n",
       "      <td>156.455429</td>\n",
       "      <td>0.076456</td>\n",
       "      <td>351.140015</td>\n",
       "      <td>329.809998</td>\n",
       "      <td>0.062668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009417</td>\n",
       "      <td>0.011218</td>\n",
       "      <td>0.017012</td>\n",
       "      <td>0.013059</td>\n",
       "      <td>0.017076</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.013521</td>\n",
       "      <td>0.014939</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.052644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>67.204628</td>\n",
       "      <td>76.091995</td>\n",
       "      <td>-0.124201</td>\n",
       "      <td>160.731430</td>\n",
       "      <td>168.886551</td>\n",
       "      <td>-0.049492</td>\n",
       "      <td>345.119995</td>\n",
       "      <td>351.140015</td>\n",
       "      <td>-0.017293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010357</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>0.016979</td>\n",
       "      <td>0.012260</td>\n",
       "      <td>0.016880</td>\n",
       "      <td>0.009553</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>0.014539</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>-0.061766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>62.664707</td>\n",
       "      <td>67.204628</td>\n",
       "      <td>-0.069944</td>\n",
       "      <td>156.892731</td>\n",
       "      <td>160.731430</td>\n",
       "      <td>-0.024173</td>\n",
       "      <td>318.239990</td>\n",
       "      <td>345.119995</td>\n",
       "      <td>-0.081086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>0.013004</td>\n",
       "      <td>0.015691</td>\n",
       "      <td>0.013579</td>\n",
       "      <td>0.015170</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>0.014259</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>-0.110870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>72.401154</td>\n",
       "      <td>62.664707</td>\n",
       "      <td>0.144424</td>\n",
       "      <td>178.281311</td>\n",
       "      <td>156.892731</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>353.640015</td>\n",
       "      <td>318.239990</td>\n",
       "      <td>0.105474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.010978</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>0.012381</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>0.009458</td>\n",
       "      <td>0.009965</td>\n",
       "      <td>0.013837</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.138666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>78.349983</td>\n",
       "      <td>72.401154</td>\n",
       "      <td>0.078964</td>\n",
       "      <td>182.300385</td>\n",
       "      <td>178.281311</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>386.600006</td>\n",
       "      <td>353.640015</td>\n",
       "      <td>0.089111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009430</td>\n",
       "      <td>0.010983</td>\n",
       "      <td>0.013696</td>\n",
       "      <td>0.013103</td>\n",
       "      <td>0.012962</td>\n",
       "      <td>0.009776</td>\n",
       "      <td>0.010458</td>\n",
       "      <td>0.013069</td>\n",
       "      <td>0.008035</td>\n",
       "      <td>0.084689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>90.879066</td>\n",
       "      <td>78.349983</td>\n",
       "      <td>0.148344</td>\n",
       "      <td>203.019226</td>\n",
       "      <td>182.300385</td>\n",
       "      <td>0.107645</td>\n",
       "      <td>435.309998</td>\n",
       "      <td>386.600006</td>\n",
       "      <td>0.118668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012646</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>0.013139</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>0.011848</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>0.009274</td>\n",
       "      <td>0.012440</td>\n",
       "      <td>0.009031</td>\n",
       "      <td>0.091070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>105.886086</td>\n",
       "      <td>90.879066</td>\n",
       "      <td>0.152834</td>\n",
       "      <td>204.515610</td>\n",
       "      <td>203.019226</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>444.320007</td>\n",
       "      <td>435.309998</td>\n",
       "      <td>0.020487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.012186</td>\n",
       "      <td>0.011608</td>\n",
       "      <td>0.011418</td>\n",
       "      <td>0.011448</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>0.010384</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.076226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>128.585907</td>\n",
       "      <td>105.886086</td>\n",
       "      <td>0.194233</td>\n",
       "      <td>224.986130</td>\n",
       "      <td>204.515610</td>\n",
       "      <td>0.095394</td>\n",
       "      <td>513.390015</td>\n",
       "      <td>444.320007</td>\n",
       "      <td>0.144491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>0.012803</td>\n",
       "      <td>0.012344</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.011860</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>0.008541</td>\n",
       "      <td>0.120874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>128.585907</td>\n",
       "      <td>-0.106370</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>224.986130</td>\n",
       "      <td>-0.067361</td>\n",
       "      <td>490.429993</td>\n",
       "      <td>513.390015</td>\n",
       "      <td>-0.045753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>0.012806</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.010877</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.009710</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.008698</td>\n",
       "      <td>0.008061</td>\n",
       "      <td>-0.064527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>-0.061888</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>447.100006</td>\n",
       "      <td>490.429993</td>\n",
       "      <td>-0.092500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.013573</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.010869</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>0.008802</td>\n",
       "      <td>-0.040388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AAPL adj_close  AAPL prev_close  AAPL log_returns  \\\n",
       "0 2020-01-01       76.091995        72.192863          0.052602   \n",
       "1 2020-02-01       67.204628        76.091995         -0.124201   \n",
       "2 2020-03-01       62.664707        67.204628         -0.069944   \n",
       "3 2020-04-01       72.401154        62.664707          0.144424   \n",
       "4 2020-05-01       78.349983        72.401154          0.078964   \n",
       "5 2020-06-01       90.879066        78.349983          0.148344   \n",
       "6 2020-07-01      105.886086        90.879066          0.152834   \n",
       "7 2020-08-01      128.585907       105.886086          0.194233   \n",
       "8 2020-09-01      115.610542       128.585907         -0.106370   \n",
       "9 2020-10-01      108.672516       115.610542         -0.061888   \n",
       "\n",
       "   MSFT adj_close  MSFT prev_close  MSFT log_returns  ADBE adj_close  \\\n",
       "0      168.886551       156.455429          0.076456      351.140015   \n",
       "1      160.731430       168.886551         -0.049492      345.119995   \n",
       "2      156.892731       160.731430         -0.024173      318.239990   \n",
       "3      178.281311       156.892731          0.127800      353.640015   \n",
       "4      182.300385       178.281311          0.022293      386.600006   \n",
       "5      203.019226       182.300385          0.107645      435.309998   \n",
       "6      204.515610       203.019226          0.007344      444.320007   \n",
       "7      224.986130       204.515610          0.095394      513.390015   \n",
       "8      210.330002       224.986130         -0.067361      490.429993   \n",
       "9      202.470001       210.330002         -0.038086      447.100006   \n",
       "\n",
       "   ADBE prev_close  ADBE log_returns  ...  MELI_weight  ESTC_weight  G_weight  \\\n",
       "0       329.809998          0.062668  ...     0.009417     0.011218  0.017012   \n",
       "1       351.140015         -0.017293  ...     0.010357     0.010739  0.016979   \n",
       "2       345.119995         -0.081086  ...     0.010236     0.013004  0.015691   \n",
       "3       318.239990          0.105474  ...     0.009070     0.010978  0.013310   \n",
       "4       353.640015          0.089111  ...     0.009430     0.010983  0.013696   \n",
       "5       386.600006          0.118668  ...     0.012646     0.013518  0.013139   \n",
       "6       435.309998          0.020487  ...     0.013363     0.013245  0.012186   \n",
       "7       444.320007          0.144491  ...     0.014127     0.012803  0.012344   \n",
       "8       513.390015         -0.045753  ...     0.013008     0.012806  0.011587   \n",
       "9       490.429993         -0.092500  ...     0.012852     0.013573  0.011413   \n",
       "\n",
       "   GDDY_weight  FLEX_weight  MDB_weight  NXPI_weight  FISV_weight  \\\n",
       "0     0.013059     0.017076    0.008085     0.013521     0.014939   \n",
       "1     0.012260     0.016880    0.009553     0.012826     0.014539   \n",
       "2     0.013579     0.015170    0.009455     0.012227     0.014259   \n",
       "3     0.012381     0.012784    0.009458     0.009965     0.013837   \n",
       "4     0.013103     0.012962    0.009776     0.010458     0.013069   \n",
       "5     0.013395     0.011848    0.012859     0.009274     0.012440   \n",
       "6     0.011608     0.011418    0.011448     0.010047     0.010384   \n",
       "7     0.010309     0.011860    0.010736     0.009630     0.009836   \n",
       "8     0.010877     0.009934    0.009710     0.009131     0.008698   \n",
       "9     0.010533     0.010869    0.010256     0.009666     0.009601   \n",
       "\n",
       "   MRVL_weight  portfolio return  \n",
       "0     0.008113          0.052644  \n",
       "1     0.006982         -0.061766  \n",
       "2     0.006581         -0.110870  \n",
       "3     0.007811          0.138666  \n",
       "4     0.008035          0.084689  \n",
       "5     0.009031          0.091070  \n",
       "6     0.008862          0.076226  \n",
       "7     0.008541          0.120874  \n",
       "8     0.008061         -0.064527  \n",
       "9     0.008802         -0.040388  \n",
       "\n",
       "[10 rows x 123 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_best[\"portfolio return\"] = 0\n",
    "\n",
    "for i in range(len(tickers_best)):\n",
    "    returns_df_best[\"portfolio return\"] += returns_df_best[tickers_best[i]+\"_weight\"]*(np.exp(returns_df_best[tickers_best[i]+\" log_returns\"]) - 1)\n",
    "\n",
    "returns_df_best[\"portfolio return\"] = np.log(1+returns_df_best[\"portfolio return\"])\n",
    "returns_df_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns for worst portfolio (FDMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_worst = [\"ERIC\", \"NOK\", \"CSCO\", \"FFIV\", \"CIEN\", \"JNPR\", \"MSI\", \"LITE\", \"SATS\", \"VIAV\", \"ACIA\", \"ANET\", \"CALX\", \"IDCC\", \n",
    "           \"VSAT\", \"NTCT\", \"COMM\", \"ET.TO\", \"FTNT\", \"PANW\", \"TENB\", \"HLIT\", \"ADTN\", \"EXTR\",\n",
    "           \"INSG\", \"RPD\", \"SW.TO\", \"CVLT\", \"GLW\", \"RBBN\"]\n",
    "\n",
    "returns_df_worst = get_data_for_multiple_stocks_monthly(tickers_worst,\n",
    "                                          start_date = \"2019-12-01\", end_date = \"2020-10-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ERIC adj_close</th>\n",
       "      <th>ERIC prev_close</th>\n",
       "      <th>ERIC log_returns</th>\n",
       "      <th>NOK adj_close</th>\n",
       "      <th>NOK prev_close</th>\n",
       "      <th>NOK log_returns</th>\n",
       "      <th>CSCO adj_close</th>\n",
       "      <th>CSCO prev_close</th>\n",
       "      <th>CSCO log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>SW.TO log_returns</th>\n",
       "      <th>CVLT adj_close</th>\n",
       "      <th>CVLT prev_close</th>\n",
       "      <th>CVLT log_returns</th>\n",
       "      <th>GLW adj_close</th>\n",
       "      <th>GLW prev_close</th>\n",
       "      <th>GLW log_returns</th>\n",
       "      <th>RBBN adj_close</th>\n",
       "      <th>RBBN prev_close</th>\n",
       "      <th>RBBN log_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7.723459</td>\n",
       "      <td>8.627477</td>\n",
       "      <td>-0.110690</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0.044803</td>\n",
       "      <td>44.442673</td>\n",
       "      <td>46.366550</td>\n",
       "      <td>-0.042378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030209</td>\n",
       "      <td>45.020000</td>\n",
       "      <td>44.639999</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>26.032068</td>\n",
       "      <td>28.392416</td>\n",
       "      <td>-0.086793</td>\n",
       "      <td>2.82</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-0.094665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>7.900332</td>\n",
       "      <td>7.723459</td>\n",
       "      <td>0.022642</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.88</td>\n",
       "      <td>-0.002581</td>\n",
       "      <td>38.887131</td>\n",
       "      <td>44.442673</td>\n",
       "      <td>-0.133537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.201454</td>\n",
       "      <td>41.700001</td>\n",
       "      <td>45.020000</td>\n",
       "      <td>-0.076606</td>\n",
       "      <td>23.271832</td>\n",
       "      <td>26.032068</td>\n",
       "      <td>-0.112085</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.135745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>7.949464</td>\n",
       "      <td>7.900332</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.87</td>\n",
       "      <td>-0.221852</td>\n",
       "      <td>38.283325</td>\n",
       "      <td>38.887131</td>\n",
       "      <td>-0.015649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272473</td>\n",
       "      <td>40.480000</td>\n",
       "      <td>41.700001</td>\n",
       "      <td>-0.029693</td>\n",
       "      <td>20.209759</td>\n",
       "      <td>23.271832</td>\n",
       "      <td>-0.141078</td>\n",
       "      <td>3.03</td>\n",
       "      <td>3.23</td>\n",
       "      <td>-0.063920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>8.313036</td>\n",
       "      <td>7.949464</td>\n",
       "      <td>0.044720</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.143961</td>\n",
       "      <td>41.273144</td>\n",
       "      <td>38.283325</td>\n",
       "      <td>0.075198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496382</td>\n",
       "      <td>42.689999</td>\n",
       "      <td>40.480000</td>\n",
       "      <td>0.053157</td>\n",
       "      <td>21.656122</td>\n",
       "      <td>20.209759</td>\n",
       "      <td>0.069123</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.186165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>9.068660</td>\n",
       "      <td>8.313036</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.098353</td>\n",
       "      <td>47.012615</td>\n",
       "      <td>41.273144</td>\n",
       "      <td>0.130204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084648</td>\n",
       "      <td>40.459999</td>\n",
       "      <td>42.689999</td>\n",
       "      <td>-0.053651</td>\n",
       "      <td>22.423580</td>\n",
       "      <td>21.656122</td>\n",
       "      <td>0.034825</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.186877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>9.227410</td>\n",
       "      <td>9.068660</td>\n",
       "      <td>0.017354</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.107889</td>\n",
       "      <td>45.852539</td>\n",
       "      <td>47.012615</td>\n",
       "      <td>-0.024985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015709</td>\n",
       "      <td>38.700001</td>\n",
       "      <td>40.459999</td>\n",
       "      <td>-0.044474</td>\n",
       "      <td>25.726173</td>\n",
       "      <td>22.423580</td>\n",
       "      <td>0.137396</td>\n",
       "      <td>3.93</td>\n",
       "      <td>4.40</td>\n",
       "      <td>-0.112965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>11.459848</td>\n",
       "      <td>9.227410</td>\n",
       "      <td>0.216671</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>46.304768</td>\n",
       "      <td>45.852539</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379705</td>\n",
       "      <td>44.080002</td>\n",
       "      <td>38.700001</td>\n",
       "      <td>0.130167</td>\n",
       "      <td>30.791946</td>\n",
       "      <td>25.726173</td>\n",
       "      <td>0.179744</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.93</td>\n",
       "      <td>0.112965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>11.559068</td>\n",
       "      <td>11.459848</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>41.834137</td>\n",
       "      <td>46.304768</td>\n",
       "      <td>-0.101532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095928</td>\n",
       "      <td>43.230000</td>\n",
       "      <td>44.080002</td>\n",
       "      <td>-0.019472</td>\n",
       "      <td>32.242146</td>\n",
       "      <td>30.791946</td>\n",
       "      <td>0.046021</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.40</td>\n",
       "      <td>-0.027652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>10.805000</td>\n",
       "      <td>11.559068</td>\n",
       "      <td>-0.067461</td>\n",
       "      <td>3.91</td>\n",
       "      <td>4.90</td>\n",
       "      <td>-0.225698</td>\n",
       "      <td>39.029999</td>\n",
       "      <td>41.834137</td>\n",
       "      <td>-0.069382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085721</td>\n",
       "      <td>40.799999</td>\n",
       "      <td>43.230000</td>\n",
       "      <td>-0.057853</td>\n",
       "      <td>32.410000</td>\n",
       "      <td>32.242146</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4.28</td>\n",
       "      <td>-0.100699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>11.122502</td>\n",
       "      <td>10.805000</td>\n",
       "      <td>0.028961</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.91</td>\n",
       "      <td>-0.148625</td>\n",
       "      <td>35.571899</td>\n",
       "      <td>39.029999</td>\n",
       "      <td>-0.092775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005398</td>\n",
       "      <td>39.590000</td>\n",
       "      <td>40.799999</td>\n",
       "      <td>-0.030105</td>\n",
       "      <td>31.969999</td>\n",
       "      <td>32.410000</td>\n",
       "      <td>-0.013669</td>\n",
       "      <td>4.31</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.107683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  ERIC adj_close  ERIC prev_close  ERIC log_returns  \\\n",
       "0 2020-01-01        7.723459         8.627477         -0.110690   \n",
       "1 2020-02-01        7.900332         7.723459          0.022642   \n",
       "2 2020-03-01        7.949464         7.900332          0.006200   \n",
       "3 2020-04-01        8.313036         7.949464          0.044720   \n",
       "4 2020-05-01        9.068660         8.313036          0.087000   \n",
       "5 2020-06-01        9.227410         9.068660          0.017354   \n",
       "6 2020-07-01       11.459848         9.227410          0.216671   \n",
       "7 2020-08-01       11.559068        11.459848          0.008621   \n",
       "8 2020-09-01       10.805000        11.559068         -0.067461   \n",
       "9 2020-10-01       11.122502        10.805000          0.028961   \n",
       "\n",
       "   NOK adj_close  NOK prev_close  NOK log_returns  CSCO adj_close  \\\n",
       "0           3.88            3.71         0.044803       44.442673   \n",
       "1           3.87            3.88        -0.002581       38.887131   \n",
       "2           3.10            3.87        -0.221852       38.283325   \n",
       "3           3.58            3.10         0.143961       41.273144   \n",
       "4           3.95            3.58         0.098353       47.012615   \n",
       "5           4.40            3.95         0.107889       45.852539   \n",
       "6           4.78            4.40         0.082836       46.304768   \n",
       "7           4.90            4.78         0.024795       41.834137   \n",
       "8           3.91            4.90        -0.225698       39.029999   \n",
       "9           3.37            3.91        -0.148625       35.571899   \n",
       "\n",
       "   CSCO prev_close  CSCO log_returns  ...  SW.TO log_returns  CVLT adj_close  \\\n",
       "0        46.366550         -0.042378  ...           0.030209       45.020000   \n",
       "1        44.442673         -0.133537  ...          -0.201454       41.700001   \n",
       "2        38.887131         -0.015649  ...          -0.272473       40.480000   \n",
       "3        38.283325          0.075198  ...           0.496382       42.689999   \n",
       "4        41.273144          0.130204  ...          -0.084648       40.459999   \n",
       "5        47.012615         -0.024985  ...           0.015709       38.700001   \n",
       "6        45.852539          0.009814  ...           0.379705       44.080002   \n",
       "7        46.304768         -0.101532  ...          -0.095928       43.230000   \n",
       "8        41.834137         -0.069382  ...          -0.085721       40.799999   \n",
       "9        39.029999         -0.092775  ...          -0.005398       39.590000   \n",
       "\n",
       "   CVLT prev_close  CVLT log_returns  GLW adj_close  GLW prev_close  \\\n",
       "0        44.639999          0.008477      26.032068       28.392416   \n",
       "1        45.020000         -0.076606      23.271832       26.032068   \n",
       "2        41.700001         -0.029693      20.209759       23.271832   \n",
       "3        40.480000          0.053157      21.656122       20.209759   \n",
       "4        42.689999         -0.053651      22.423580       21.656122   \n",
       "5        40.459999         -0.044474      25.726173       22.423580   \n",
       "6        38.700001          0.130167      30.791946       25.726173   \n",
       "7        44.080002         -0.019472      32.242146       30.791946   \n",
       "8        43.230000         -0.057853      32.410000       32.242146   \n",
       "9        40.799999         -0.030105      31.969999       32.410000   \n",
       "\n",
       "   GLW log_returns  RBBN adj_close  RBBN prev_close  RBBN log_returns  \n",
       "0        -0.086793            2.82             3.10         -0.094665  \n",
       "1        -0.112085            3.23             2.82          0.135745  \n",
       "2        -0.141078            3.03             3.23         -0.063920  \n",
       "3         0.069123            3.65             3.03          0.186165  \n",
       "4         0.034825            4.40             3.65          0.186877  \n",
       "5         0.137396            3.93             4.40         -0.112965  \n",
       "6         0.179744            4.40             3.93          0.112965  \n",
       "7         0.046021            4.28             4.40         -0.027652  \n",
       "8         0.005193            3.87             4.28         -0.100699  \n",
       "9        -0.013669            4.31             3.87          0.107683  \n",
       "\n",
       "[10 rows x 91 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_worst.dropna(inplace = True)\n",
    "returns_df_worst.reset_index(inplace=True)\n",
    "returns_df_worst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_values_worst = [4077954, 1123183, 3142012, 903417, 870909, 866150, 810271, 631412, 554312, 536947, 523982, 413829, 402207, 400227, \n",
    "               369211, 348419, 240423, 49133, 50162, 180187, 154173, 116425, 109336, 106724,\n",
    "               104755, 102925, 96791, 93550, 56253, 52006]\n",
    "\n",
    "array_price = []\n",
    "for i in range(len(tickers_worst)):\n",
    "    x = returns_df_worst.loc[returns_df_worst['Date']=='2020-08-01'][tickers_worst[i]+' adj_close'].values\n",
    "    array_price.append(x)\n",
    "    \n",
    "shares = []\n",
    "for i in range(len(array_price)):\n",
    "    shares.append(np.round(array_values_worst[i]/array_price[i],0))\n",
    "\n",
    "# values = sum of adj close price * num of shares of all stocks\n",
    "\n",
    "total = 0\n",
    "for y in range(len(shares)):\n",
    "    total += (returns_df_worst[tickers_worst[y]+\" prev_close\"]*shares[y])\n",
    "    \n",
    "for y in range(len(shares)):\n",
    "    returns_df_worst[\"value\"] = total\n",
    "\n",
    "for x in range(len(shares)):\n",
    "    returns_df_worst[tickers_worst[x]+\"_weight\"] = (returns_df_worst[tickers_worst[x]+\" prev_close\"]*shares[x])/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ERIC adj_close</th>\n",
       "      <th>ERIC prev_close</th>\n",
       "      <th>ERIC log_returns</th>\n",
       "      <th>NOK adj_close</th>\n",
       "      <th>NOK prev_close</th>\n",
       "      <th>NOK log_returns</th>\n",
       "      <th>CSCO adj_close</th>\n",
       "      <th>CSCO prev_close</th>\n",
       "      <th>CSCO log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>HLIT_weight</th>\n",
       "      <th>ADTN_weight</th>\n",
       "      <th>EXTR_weight</th>\n",
       "      <th>INSG_weight</th>\n",
       "      <th>RPD_weight</th>\n",
       "      <th>SW.TO_weight</th>\n",
       "      <th>CVLT_weight</th>\n",
       "      <th>GLW_weight</th>\n",
       "      <th>RBBN_weight</th>\n",
       "      <th>portfolio return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7.723459</td>\n",
       "      <td>8.627477</td>\n",
       "      <td>-0.110690</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0.044803</td>\n",
       "      <td>44.442673</td>\n",
       "      <td>46.366550</td>\n",
       "      <td>-0.042378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>-0.046572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>7.900332</td>\n",
       "      <td>7.723459</td>\n",
       "      <td>0.022642</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.88</td>\n",
       "      <td>-0.002581</td>\n",
       "      <td>38.887131</td>\n",
       "      <td>44.442673</td>\n",
       "      <td>-0.133537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>0.003849</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>-0.060855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>7.949464</td>\n",
       "      <td>7.900332</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>3.10</td>\n",
       "      <td>3.87</td>\n",
       "      <td>-0.221852</td>\n",
       "      <td>38.283325</td>\n",
       "      <td>38.887131</td>\n",
       "      <td>-0.015649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008094</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.006028</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>-0.081382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>8.313036</td>\n",
       "      <td>7.949464</td>\n",
       "      <td>0.044720</td>\n",
       "      <td>3.58</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.143961</td>\n",
       "      <td>41.273144</td>\n",
       "      <td>38.283325</td>\n",
       "      <td>0.075198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>0.106648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>9.068660</td>\n",
       "      <td>8.313036</td>\n",
       "      <td>0.087000</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.098353</td>\n",
       "      <td>47.012615</td>\n",
       "      <td>41.273144</td>\n",
       "      <td>0.130204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007455</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.065252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>9.227410</td>\n",
       "      <td>9.068660</td>\n",
       "      <td>0.017354</td>\n",
       "      <td>4.40</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.107889</td>\n",
       "      <td>45.852539</td>\n",
       "      <td>47.012615</td>\n",
       "      <td>-0.024985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.005914</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>-0.005376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>11.459848</td>\n",
       "      <td>9.227410</td>\n",
       "      <td>0.216671</td>\n",
       "      <td>4.78</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.082836</td>\n",
       "      <td>46.304768</td>\n",
       "      <td>45.852539</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>0.006611</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.093150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>11.559068</td>\n",
       "      <td>11.459848</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>41.834137</td>\n",
       "      <td>46.304768</td>\n",
       "      <td>-0.101532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.006845</td>\n",
       "      <td>0.006211</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.022788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>10.805000</td>\n",
       "      <td>11.559068</td>\n",
       "      <td>-0.067461</td>\n",
       "      <td>3.91</td>\n",
       "      <td>4.90</td>\n",
       "      <td>-0.225698</td>\n",
       "      <td>39.029999</td>\n",
       "      <td>41.834137</td>\n",
       "      <td>-0.069382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>0.005886</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>-0.097768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>11.122502</td>\n",
       "      <td>10.805000</td>\n",
       "      <td>0.028961</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.91</td>\n",
       "      <td>-0.148625</td>\n",
       "      <td>35.571899</td>\n",
       "      <td>39.029999</td>\n",
       "      <td>-0.092775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006943</td>\n",
       "      <td>0.006426</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>-0.009769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  ERIC adj_close  ERIC prev_close  ERIC log_returns  \\\n",
       "0 2020-01-01        7.723459         8.627477         -0.110690   \n",
       "1 2020-02-01        7.900332         7.723459          0.022642   \n",
       "2 2020-03-01        7.949464         7.900332          0.006200   \n",
       "3 2020-04-01        8.313036         7.949464          0.044720   \n",
       "4 2020-05-01        9.068660         8.313036          0.087000   \n",
       "5 2020-06-01        9.227410         9.068660          0.017354   \n",
       "6 2020-07-01       11.459848         9.227410          0.216671   \n",
       "7 2020-08-01       11.559068        11.459848          0.008621   \n",
       "8 2020-09-01       10.805000        11.559068         -0.067461   \n",
       "9 2020-10-01       11.122502        10.805000          0.028961   \n",
       "\n",
       "   NOK adj_close  NOK prev_close  NOK log_returns  CSCO adj_close  \\\n",
       "0           3.88            3.71         0.044803       44.442673   \n",
       "1           3.87            3.88        -0.002581       38.887131   \n",
       "2           3.10            3.87        -0.221852       38.283325   \n",
       "3           3.58            3.10         0.143961       41.273144   \n",
       "4           3.95            3.58         0.098353       47.012615   \n",
       "5           4.40            3.95         0.107889       45.852539   \n",
       "6           4.78            4.40         0.082836       46.304768   \n",
       "7           4.90            4.78         0.024795       41.834137   \n",
       "8           3.91            4.90        -0.225698       39.029999   \n",
       "9           3.37            3.91        -0.148625       35.571899   \n",
       "\n",
       "   CSCO prev_close  CSCO log_returns  ...  HLIT_weight  ADTN_weight  \\\n",
       "0        46.366550         -0.042378  ...     0.009235     0.005742   \n",
       "1        44.442673         -0.133537  ...     0.008733     0.005505   \n",
       "2        38.887131         -0.015649  ...     0.008094     0.005204   \n",
       "3        38.283325          0.075198  ...     0.008237     0.005442   \n",
       "4        41.273144          0.130204  ...     0.007455     0.006548   \n",
       "5        47.012615         -0.024985  ...     0.006491     0.006803   \n",
       "6        45.852539          0.009814  ...     0.005751     0.006611   \n",
       "7        46.304768         -0.101532  ...     0.006155     0.006845   \n",
       "8        41.834137         -0.069382  ...     0.006658     0.006252   \n",
       "9        39.029999         -0.092775  ...     0.006943     0.006426   \n",
       "\n",
       "   EXTR_weight  INSG_weight  RPD_weight  SW.TO_weight  CVLT_weight  \\\n",
       "0     0.010800     0.004013    0.005358      0.004444     0.005796   \n",
       "1     0.009058     0.003849    0.005950      0.004799     0.006124   \n",
       "2     0.008207     0.004231    0.004930      0.004169     0.006028   \n",
       "3     0.005469     0.004120    0.005005      0.003444     0.006348   \n",
       "4     0.005409     0.007103    0.004730      0.005086     0.006018   \n",
       "5     0.004918     0.005914    0.004756      0.004378     0.005343   \n",
       "6     0.006503     0.006494    0.004990      0.004471     0.005138   \n",
       "7     0.006211     0.006875    0.005308      0.005954     0.005332   \n",
       "8     0.006103     0.005990    0.005886      0.005535     0.005350   \n",
       "9     0.006191     0.005938    0.006155      0.005602     0.005567   \n",
       "\n",
       "   GLW_weight  RBBN_weight  portfolio return  \n",
       "0    0.002973     0.002260         -0.046572  \n",
       "1    0.002856     0.002154         -0.060855  \n",
       "2    0.002713     0.002622         -0.081382  \n",
       "3    0.002556     0.002668          0.106648  \n",
       "4    0.002462     0.002889          0.065252  \n",
       "5    0.002388     0.003263         -0.005376  \n",
       "6    0.002754     0.002930          0.093150  \n",
       "7    0.003003     0.002988         -0.022788  \n",
       "8    0.003217     0.002974         -0.097768  \n",
       "9    0.003566     0.002965         -0.009769  \n",
       "\n",
       "[10 rows x 123 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_worst[\"portfolio return\"] = 0\n",
    "\n",
    "for i in range(len(tickers_worst)):\n",
    "    returns_df_worst[\"portfolio return\"] += returns_df_worst[tickers_worst[i]+\"_weight\"]*(np.exp(returns_df_worst[tickers_worst[i]+\" log_returns\"]) - 1)\n",
    "\n",
    "returns_df_worst[\"portfolio return\"] = np.log(1+returns_df_worst[\"portfolio return\"])\n",
    "returns_df_worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns for optimal portfolio (before adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_optimal = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]\n",
    "\n",
    "returns_df_optimal = get_data_for_multiple_stocks_monthly(tickers_optimal,\n",
    "                                          start_date = \"2019-12-01\", end_date = \"2020-10-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>MA adj_close</th>\n",
       "      <th>MA prev_close</th>\n",
       "      <th>MA log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>MELI log_returns</th>\n",
       "      <th>G adj_close</th>\n",
       "      <th>G prev_close</th>\n",
       "      <th>G log_returns</th>\n",
       "      <th>MDB adj_close</th>\n",
       "      <th>MDB prev_close</th>\n",
       "      <th>MDB log_returns</th>\n",
       "      <th>NXPI adj_close</th>\n",
       "      <th>NXPI prev_close</th>\n",
       "      <th>NXPI log_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>76.091995</td>\n",
       "      <td>72.192863</td>\n",
       "      <td>0.052602</td>\n",
       "      <td>168.886551</td>\n",
       "      <td>156.455429</td>\n",
       "      <td>0.076456</td>\n",
       "      <td>314.245819</td>\n",
       "      <td>296.988831</td>\n",
       "      <td>0.056481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147741</td>\n",
       "      <td>43.930374</td>\n",
       "      <td>41.758850</td>\n",
       "      <td>0.050695</td>\n",
       "      <td>163.910004</td>\n",
       "      <td>131.610001</td>\n",
       "      <td>0.219475</td>\n",
       "      <td>125.501968</td>\n",
       "      <td>125.516884</td>\n",
       "      <td>-0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>67.204628</td>\n",
       "      <td>76.091995</td>\n",
       "      <td>-0.124201</td>\n",
       "      <td>160.731430</td>\n",
       "      <td>168.886551</td>\n",
       "      <td>-0.049492</td>\n",
       "      <td>289.078735</td>\n",
       "      <td>314.245819</td>\n",
       "      <td>-0.083476</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073479</td>\n",
       "      <td>38.164944</td>\n",
       "      <td>43.930374</td>\n",
       "      <td>-0.140689</td>\n",
       "      <td>152.500000</td>\n",
       "      <td>163.910004</td>\n",
       "      <td>-0.072153</td>\n",
       "      <td>112.472961</td>\n",
       "      <td>125.501968</td>\n",
       "      <td>-0.109609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>62.664707</td>\n",
       "      <td>67.204628</td>\n",
       "      <td>-0.069944</td>\n",
       "      <td>156.892731</td>\n",
       "      <td>160.731430</td>\n",
       "      <td>-0.024173</td>\n",
       "      <td>240.585220</td>\n",
       "      <td>289.078735</td>\n",
       "      <td>-0.183625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231793</td>\n",
       "      <td>28.975985</td>\n",
       "      <td>38.164944</td>\n",
       "      <td>-0.275450</td>\n",
       "      <td>136.539993</td>\n",
       "      <td>152.500000</td>\n",
       "      <td>-0.110547</td>\n",
       "      <td>82.042236</td>\n",
       "      <td>112.472961</td>\n",
       "      <td>-0.315479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>72.401154</td>\n",
       "      <td>62.664707</td>\n",
       "      <td>0.144424</td>\n",
       "      <td>178.281311</td>\n",
       "      <td>156.892731</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>273.860382</td>\n",
       "      <td>240.585220</td>\n",
       "      <td>0.129544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177558</td>\n",
       "      <td>34.252018</td>\n",
       "      <td>28.975985</td>\n",
       "      <td>0.167278</td>\n",
       "      <td>162.130005</td>\n",
       "      <td>136.539993</td>\n",
       "      <td>0.171781</td>\n",
       "      <td>98.907402</td>\n",
       "      <td>82.042236</td>\n",
       "      <td>0.186950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>78.349983</td>\n",
       "      <td>72.401154</td>\n",
       "      <td>0.078964</td>\n",
       "      <td>182.300385</td>\n",
       "      <td>178.281311</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>300.139191</td>\n",
       "      <td>273.860382</td>\n",
       "      <td>0.091628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378138</td>\n",
       "      <td>35.764160</td>\n",
       "      <td>34.252018</td>\n",
       "      <td>0.043201</td>\n",
       "      <td>232.110001</td>\n",
       "      <td>162.130005</td>\n",
       "      <td>0.358813</td>\n",
       "      <td>95.460487</td>\n",
       "      <td>98.907402</td>\n",
       "      <td>-0.035472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>90.879066</td>\n",
       "      <td>78.349983</td>\n",
       "      <td>0.148344</td>\n",
       "      <td>203.019226</td>\n",
       "      <td>182.300385</td>\n",
       "      <td>0.107645</td>\n",
       "      <td>294.962158</td>\n",
       "      <td>300.139191</td>\n",
       "      <td>-0.017399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146224</td>\n",
       "      <td>36.331215</td>\n",
       "      <td>35.764160</td>\n",
       "      <td>0.015731</td>\n",
       "      <td>226.339996</td>\n",
       "      <td>232.110001</td>\n",
       "      <td>-0.025173</td>\n",
       "      <td>113.281105</td>\n",
       "      <td>95.460487</td>\n",
       "      <td>0.171160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>105.886086</td>\n",
       "      <td>90.879066</td>\n",
       "      <td>0.152834</td>\n",
       "      <td>204.515610</td>\n",
       "      <td>203.019226</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>307.760132</td>\n",
       "      <td>294.962158</td>\n",
       "      <td>0.042474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131777</td>\n",
       "      <td>39.719501</td>\n",
       "      <td>36.331215</td>\n",
       "      <td>0.089165</td>\n",
       "      <td>229.080002</td>\n",
       "      <td>226.339996</td>\n",
       "      <td>0.012033</td>\n",
       "      <td>117.176697</td>\n",
       "      <td>113.281105</td>\n",
       "      <td>0.033811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>128.585907</td>\n",
       "      <td>105.886086</td>\n",
       "      <td>0.194233</td>\n",
       "      <td>224.986130</td>\n",
       "      <td>204.515610</td>\n",
       "      <td>0.095394</td>\n",
       "      <td>357.773376</td>\n",
       "      <td>307.760132</td>\n",
       "      <td>0.150579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038353</td>\n",
       "      <td>42.073544</td>\n",
       "      <td>39.719501</td>\n",
       "      <td>0.057577</td>\n",
       "      <td>233.800003</td>\n",
       "      <td>229.080002</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>125.381966</td>\n",
       "      <td>117.176697</td>\n",
       "      <td>0.067682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>128.585907</td>\n",
       "      <td>-0.106370</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>224.986130</td>\n",
       "      <td>-0.067361</td>\n",
       "      <td>337.776672</td>\n",
       "      <td>357.773376</td>\n",
       "      <td>-0.057515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076543</td>\n",
       "      <td>38.851696</td>\n",
       "      <td>42.073544</td>\n",
       "      <td>-0.079667</td>\n",
       "      <td>231.509995</td>\n",
       "      <td>233.800003</td>\n",
       "      <td>-0.009843</td>\n",
       "      <td>124.434814</td>\n",
       "      <td>125.381966</td>\n",
       "      <td>-0.007583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>-0.061888</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>288.304291</td>\n",
       "      <td>337.776672</td>\n",
       "      <td>-0.158368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114707</td>\n",
       "      <td>34.369999</td>\n",
       "      <td>38.851696</td>\n",
       "      <td>-0.122568</td>\n",
       "      <td>228.470001</td>\n",
       "      <td>231.509995</td>\n",
       "      <td>-0.013218</td>\n",
       "      <td>135.119995</td>\n",
       "      <td>124.434814</td>\n",
       "      <td>0.082381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AAPL adj_close  AAPL prev_close  AAPL log_returns  \\\n",
       "0 2020-01-01       76.091995        72.192863          0.052602   \n",
       "1 2020-02-01       67.204628        76.091995         -0.124201   \n",
       "2 2020-03-01       62.664707        67.204628         -0.069944   \n",
       "3 2020-04-01       72.401154        62.664707          0.144424   \n",
       "4 2020-05-01       78.349983        72.401154          0.078964   \n",
       "5 2020-06-01       90.879066        78.349983          0.148344   \n",
       "6 2020-07-01      105.886086        90.879066          0.152834   \n",
       "7 2020-08-01      128.585907       105.886086          0.194233   \n",
       "8 2020-09-01      115.610542       128.585907         -0.106370   \n",
       "9 2020-10-01      108.672516       115.610542         -0.061888   \n",
       "\n",
       "   MSFT adj_close  MSFT prev_close  MSFT log_returns  MA adj_close  \\\n",
       "0      168.886551       156.455429          0.076456    314.245819   \n",
       "1      160.731430       168.886551         -0.049492    289.078735   \n",
       "2      156.892731       160.731430         -0.024173    240.585220   \n",
       "3      178.281311       156.892731          0.127800    273.860382   \n",
       "4      182.300385       178.281311          0.022293    300.139191   \n",
       "5      203.019226       182.300385          0.107645    294.962158   \n",
       "6      204.515610       203.019226          0.007344    307.760132   \n",
       "7      224.986130       204.515610          0.095394    357.773376   \n",
       "8      210.330002       224.986130         -0.067361    337.776672   \n",
       "9      202.470001       210.330002         -0.038086    288.304291   \n",
       "\n",
       "   MA prev_close  MA log_returns  ...  MELI log_returns  G adj_close  \\\n",
       "0     296.988831        0.056481  ...          0.147741    43.930374   \n",
       "1     314.245819       -0.083476  ...         -0.073479    38.164944   \n",
       "2     289.078735       -0.183625  ...         -0.231793    28.975985   \n",
       "3     240.585220        0.129544  ...          0.177558    34.252018   \n",
       "4     273.860382        0.091628  ...          0.378138    35.764160   \n",
       "5     300.139191       -0.017399  ...          0.146224    36.331215   \n",
       "6     294.962158        0.042474  ...          0.131777    39.719501   \n",
       "7     307.760132        0.150579  ...          0.038353    42.073544   \n",
       "8     357.773376       -0.057515  ...         -0.076543    38.851696   \n",
       "9     337.776672       -0.158368  ...          0.114707    34.369999   \n",
       "\n",
       "   G prev_close  G log_returns  MDB adj_close  MDB prev_close  \\\n",
       "0     41.758850       0.050695     163.910004      131.610001   \n",
       "1     43.930374      -0.140689     152.500000      163.910004   \n",
       "2     38.164944      -0.275450     136.539993      152.500000   \n",
       "3     28.975985       0.167278     162.130005      136.539993   \n",
       "4     34.252018       0.043201     232.110001      162.130005   \n",
       "5     35.764160       0.015731     226.339996      232.110001   \n",
       "6     36.331215       0.089165     229.080002      226.339996   \n",
       "7     39.719501       0.057577     233.800003      229.080002   \n",
       "8     42.073544      -0.079667     231.509995      233.800003   \n",
       "9     38.851696      -0.122568     228.470001      231.509995   \n",
       "\n",
       "   MDB log_returns  NXPI adj_close  NXPI prev_close  NXPI log_returns  \n",
       "0         0.219475      125.501968       125.516884         -0.000119  \n",
       "1        -0.072153      112.472961       125.501968         -0.109609  \n",
       "2        -0.110547       82.042236       112.472961         -0.315479  \n",
       "3         0.171781       98.907402        82.042236          0.186950  \n",
       "4         0.358813       95.460487        98.907402         -0.035472  \n",
       "5        -0.025173      113.281105        95.460487          0.171160  \n",
       "6         0.012033      117.176697       113.281105          0.033811  \n",
       "7         0.020395      125.381966       117.176697          0.067682  \n",
       "8        -0.009843      124.434814       125.381966         -0.007583  \n",
       "9        -0.013218      135.119995       124.434814          0.082381  \n",
       "\n",
       "[10 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_optimal.dropna(inplace = True)\n",
    "returns_df_optimal.reset_index(inplace=True)\n",
    "returns_df_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>MA adj_close</th>\n",
       "      <th>MA prev_close</th>\n",
       "      <th>MA log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>G adj_close</th>\n",
       "      <th>G prev_close</th>\n",
       "      <th>G log_returns</th>\n",
       "      <th>MDB adj_close</th>\n",
       "      <th>MDB prev_close</th>\n",
       "      <th>MDB log_returns</th>\n",
       "      <th>NXPI adj_close</th>\n",
       "      <th>NXPI prev_close</th>\n",
       "      <th>NXPI log_returns</th>\n",
       "      <th>portfolio return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>76.091995</td>\n",
       "      <td>72.192863</td>\n",
       "      <td>0.052602</td>\n",
       "      <td>168.886551</td>\n",
       "      <td>156.455429</td>\n",
       "      <td>0.076456</td>\n",
       "      <td>314.245819</td>\n",
       "      <td>296.988831</td>\n",
       "      <td>0.056481</td>\n",
       "      <td>...</td>\n",
       "      <td>43.930374</td>\n",
       "      <td>41.758850</td>\n",
       "      <td>0.050695</td>\n",
       "      <td>163.910004</td>\n",
       "      <td>131.610001</td>\n",
       "      <td>0.219475</td>\n",
       "      <td>125.501968</td>\n",
       "      <td>125.516884</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>0.052707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>67.204628</td>\n",
       "      <td>76.091995</td>\n",
       "      <td>-0.124201</td>\n",
       "      <td>160.731430</td>\n",
       "      <td>168.886551</td>\n",
       "      <td>-0.049492</td>\n",
       "      <td>289.078735</td>\n",
       "      <td>314.245819</td>\n",
       "      <td>-0.083476</td>\n",
       "      <td>...</td>\n",
       "      <td>38.164944</td>\n",
       "      <td>43.930374</td>\n",
       "      <td>-0.140689</td>\n",
       "      <td>152.500000</td>\n",
       "      <td>163.910004</td>\n",
       "      <td>-0.072153</td>\n",
       "      <td>112.472961</td>\n",
       "      <td>125.501968</td>\n",
       "      <td>-0.109609</td>\n",
       "      <td>-0.070809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>62.664707</td>\n",
       "      <td>67.204628</td>\n",
       "      <td>-0.069944</td>\n",
       "      <td>156.892731</td>\n",
       "      <td>160.731430</td>\n",
       "      <td>-0.024173</td>\n",
       "      <td>240.585220</td>\n",
       "      <td>289.078735</td>\n",
       "      <td>-0.183625</td>\n",
       "      <td>...</td>\n",
       "      <td>28.975985</td>\n",
       "      <td>38.164944</td>\n",
       "      <td>-0.275450</td>\n",
       "      <td>136.539993</td>\n",
       "      <td>152.500000</td>\n",
       "      <td>-0.110547</td>\n",
       "      <td>82.042236</td>\n",
       "      <td>112.472961</td>\n",
       "      <td>-0.315479</td>\n",
       "      <td>-0.144133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>72.401154</td>\n",
       "      <td>62.664707</td>\n",
       "      <td>0.144424</td>\n",
       "      <td>178.281311</td>\n",
       "      <td>156.892731</td>\n",
       "      <td>0.127800</td>\n",
       "      <td>273.860382</td>\n",
       "      <td>240.585220</td>\n",
       "      <td>0.129544</td>\n",
       "      <td>...</td>\n",
       "      <td>34.252018</td>\n",
       "      <td>28.975985</td>\n",
       "      <td>0.167278</td>\n",
       "      <td>162.130005</td>\n",
       "      <td>136.539993</td>\n",
       "      <td>0.171781</td>\n",
       "      <td>98.907402</td>\n",
       "      <td>82.042236</td>\n",
       "      <td>0.186950</td>\n",
       "      <td>0.135605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>78.349983</td>\n",
       "      <td>72.401154</td>\n",
       "      <td>0.078964</td>\n",
       "      <td>182.300385</td>\n",
       "      <td>178.281311</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>300.139191</td>\n",
       "      <td>273.860382</td>\n",
       "      <td>0.091628</td>\n",
       "      <td>...</td>\n",
       "      <td>35.764160</td>\n",
       "      <td>34.252018</td>\n",
       "      <td>0.043201</td>\n",
       "      <td>232.110001</td>\n",
       "      <td>162.130005</td>\n",
       "      <td>0.358813</td>\n",
       "      <td>95.460487</td>\n",
       "      <td>98.907402</td>\n",
       "      <td>-0.035472</td>\n",
       "      <td>0.070840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>90.879066</td>\n",
       "      <td>78.349983</td>\n",
       "      <td>0.148344</td>\n",
       "      <td>203.019226</td>\n",
       "      <td>182.300385</td>\n",
       "      <td>0.107645</td>\n",
       "      <td>294.962158</td>\n",
       "      <td>300.139191</td>\n",
       "      <td>-0.017399</td>\n",
       "      <td>...</td>\n",
       "      <td>36.331215</td>\n",
       "      <td>35.764160</td>\n",
       "      <td>0.015731</td>\n",
       "      <td>226.339996</td>\n",
       "      <td>232.110001</td>\n",
       "      <td>-0.025173</td>\n",
       "      <td>113.281105</td>\n",
       "      <td>95.460487</td>\n",
       "      <td>0.171160</td>\n",
       "      <td>0.045264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>105.886086</td>\n",
       "      <td>90.879066</td>\n",
       "      <td>0.152834</td>\n",
       "      <td>204.515610</td>\n",
       "      <td>203.019226</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>307.760132</td>\n",
       "      <td>294.962158</td>\n",
       "      <td>0.042474</td>\n",
       "      <td>...</td>\n",
       "      <td>39.719501</td>\n",
       "      <td>36.331215</td>\n",
       "      <td>0.089165</td>\n",
       "      <td>229.080002</td>\n",
       "      <td>226.339996</td>\n",
       "      <td>0.012033</td>\n",
       "      <td>117.176697</td>\n",
       "      <td>113.281105</td>\n",
       "      <td>0.033811</td>\n",
       "      <td>0.071441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>128.585907</td>\n",
       "      <td>105.886086</td>\n",
       "      <td>0.194233</td>\n",
       "      <td>224.986130</td>\n",
       "      <td>204.515610</td>\n",
       "      <td>0.095394</td>\n",
       "      <td>357.773376</td>\n",
       "      <td>307.760132</td>\n",
       "      <td>0.150579</td>\n",
       "      <td>...</td>\n",
       "      <td>42.073544</td>\n",
       "      <td>39.719501</td>\n",
       "      <td>0.057577</td>\n",
       "      <td>233.800003</td>\n",
       "      <td>229.080002</td>\n",
       "      <td>0.020395</td>\n",
       "      <td>125.381966</td>\n",
       "      <td>117.176697</td>\n",
       "      <td>0.067682</td>\n",
       "      <td>0.100891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>128.585907</td>\n",
       "      <td>-0.106370</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>224.986130</td>\n",
       "      <td>-0.067361</td>\n",
       "      <td>337.776672</td>\n",
       "      <td>357.773376</td>\n",
       "      <td>-0.057515</td>\n",
       "      <td>...</td>\n",
       "      <td>38.851696</td>\n",
       "      <td>42.073544</td>\n",
       "      <td>-0.079667</td>\n",
       "      <td>231.509995</td>\n",
       "      <td>233.800003</td>\n",
       "      <td>-0.009843</td>\n",
       "      <td>124.434814</td>\n",
       "      <td>125.381966</td>\n",
       "      <td>-0.007583</td>\n",
       "      <td>-0.052966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>-0.061888</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>288.304291</td>\n",
       "      <td>337.776672</td>\n",
       "      <td>-0.158368</td>\n",
       "      <td>...</td>\n",
       "      <td>34.369999</td>\n",
       "      <td>38.851696</td>\n",
       "      <td>-0.122568</td>\n",
       "      <td>228.470001</td>\n",
       "      <td>231.509995</td>\n",
       "      <td>-0.013218</td>\n",
       "      <td>135.119995</td>\n",
       "      <td>124.434814</td>\n",
       "      <td>0.082381</td>\n",
       "      <td>-0.059174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AAPL adj_close  AAPL prev_close  AAPL log_returns  \\\n",
       "0 2020-01-01       76.091995        72.192863          0.052602   \n",
       "1 2020-02-01       67.204628        76.091995         -0.124201   \n",
       "2 2020-03-01       62.664707        67.204628         -0.069944   \n",
       "3 2020-04-01       72.401154        62.664707          0.144424   \n",
       "4 2020-05-01       78.349983        72.401154          0.078964   \n",
       "5 2020-06-01       90.879066        78.349983          0.148344   \n",
       "6 2020-07-01      105.886086        90.879066          0.152834   \n",
       "7 2020-08-01      128.585907       105.886086          0.194233   \n",
       "8 2020-09-01      115.610542       128.585907         -0.106370   \n",
       "9 2020-10-01      108.672516       115.610542         -0.061888   \n",
       "\n",
       "   MSFT adj_close  MSFT prev_close  MSFT log_returns  MA adj_close  \\\n",
       "0      168.886551       156.455429          0.076456    314.245819   \n",
       "1      160.731430       168.886551         -0.049492    289.078735   \n",
       "2      156.892731       160.731430         -0.024173    240.585220   \n",
       "3      178.281311       156.892731          0.127800    273.860382   \n",
       "4      182.300385       178.281311          0.022293    300.139191   \n",
       "5      203.019226       182.300385          0.107645    294.962158   \n",
       "6      204.515610       203.019226          0.007344    307.760132   \n",
       "7      224.986130       204.515610          0.095394    357.773376   \n",
       "8      210.330002       224.986130         -0.067361    337.776672   \n",
       "9      202.470001       210.330002         -0.038086    288.304291   \n",
       "\n",
       "   MA prev_close  MA log_returns  ...  G adj_close  G prev_close  \\\n",
       "0     296.988831        0.056481  ...    43.930374     41.758850   \n",
       "1     314.245819       -0.083476  ...    38.164944     43.930374   \n",
       "2     289.078735       -0.183625  ...    28.975985     38.164944   \n",
       "3     240.585220        0.129544  ...    34.252018     28.975985   \n",
       "4     273.860382        0.091628  ...    35.764160     34.252018   \n",
       "5     300.139191       -0.017399  ...    36.331215     35.764160   \n",
       "6     294.962158        0.042474  ...    39.719501     36.331215   \n",
       "7     307.760132        0.150579  ...    42.073544     39.719501   \n",
       "8     357.773376       -0.057515  ...    38.851696     42.073544   \n",
       "9     337.776672       -0.158368  ...    34.369999     38.851696   \n",
       "\n",
       "   G log_returns  MDB adj_close  MDB prev_close  MDB log_returns  \\\n",
       "0       0.050695     163.910004      131.610001         0.219475   \n",
       "1      -0.140689     152.500000      163.910004        -0.072153   \n",
       "2      -0.275450     136.539993      152.500000        -0.110547   \n",
       "3       0.167278     162.130005      136.539993         0.171781   \n",
       "4       0.043201     232.110001      162.130005         0.358813   \n",
       "5       0.015731     226.339996      232.110001        -0.025173   \n",
       "6       0.089165     229.080002      226.339996         0.012033   \n",
       "7       0.057577     233.800003      229.080002         0.020395   \n",
       "8      -0.079667     231.509995      233.800003        -0.009843   \n",
       "9      -0.122568     228.470001      231.509995        -0.013218   \n",
       "\n",
       "   NXPI adj_close  NXPI prev_close  NXPI log_returns  portfolio return  \n",
       "0      125.501968       125.516884         -0.000119          0.052707  \n",
       "1      112.472961       125.501968         -0.109609         -0.070809  \n",
       "2       82.042236       112.472961         -0.315479         -0.144133  \n",
       "3       98.907402        82.042236          0.186950          0.135605  \n",
       "4       95.460487        98.907402         -0.035472          0.070840  \n",
       "5      113.281105        95.460487          0.171160          0.045264  \n",
       "6      117.176697       113.281105          0.033811          0.071441  \n",
       "7      125.381966       117.176697          0.067682          0.100891  \n",
       "8      124.434814       125.381966         -0.007583         -0.052966  \n",
       "9      135.119995       124.434814          0.082381         -0.059174  \n",
       "\n",
       "[10 rows x 44 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_optimal[\"portfolio return\"] = 0\n",
    "\n",
    "optimal_weights = [0.052990, 0.092569, 0.156987,  0.137560, 0.074765,\n",
    "                   0.050595, 0.000872,  0.040578,  0.199530, 0.045174,\n",
    "                    0.016148,0.044405, 0.015470, 0.072358]\n",
    "\n",
    "for i in range(len(tickers_optimal)):\n",
    "    returns_df_optimal[\"portfolio return\"] += optimal_weights[i]*(np.exp(returns_df_optimal[tickers_optimal[i]+\" log_returns\"]) - 1)\n",
    "\n",
    "returns_df_optimal[\"portfolio return\"] = np.log(1+returns_df_optimal[\"portfolio return\"])\n",
    "returns_df_optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly returns graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(returns_df_best['Date'], returns_df_best['portfolio return'], 'g', label='Portfolio Log Returns for Best Portfolio (FSPTX) in 2020')\n",
    "plt.plot(returns_df_worst['Date'], returns_df_worst['portfolio return'], 'r', label='Portfolio Log Returns for Worst Portfolio (FDMAX) in 2020')\n",
    "plt.plot(returns_df_optimal['Date'], returns_df_optimal['portfolio return'], 'b', label='Portfolio Log Returns for our Optimal Portfolio in 2020')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Date')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=45)\n",
    "plt.title('Portfolio Log Returns for Best, Worst and Optimal Portfolio in 2020')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly returns table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Best</th>\n",
       "      <th>Worst</th>\n",
       "      <th>Optimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan</td>\n",
       "      <td>0.052644</td>\n",
       "      <td>-0.046572</td>\n",
       "      <td>0.052707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feb</td>\n",
       "      <td>-0.061766</td>\n",
       "      <td>-0.060855</td>\n",
       "      <td>-0.070809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mar</td>\n",
       "      <td>-0.110870</td>\n",
       "      <td>-0.081382</td>\n",
       "      <td>-0.144133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr</td>\n",
       "      <td>0.138666</td>\n",
       "      <td>0.106648</td>\n",
       "      <td>0.135605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May</td>\n",
       "      <td>0.084689</td>\n",
       "      <td>0.065252</td>\n",
       "      <td>0.070840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jun</td>\n",
       "      <td>0.091070</td>\n",
       "      <td>-0.005376</td>\n",
       "      <td>0.045264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jul</td>\n",
       "      <td>0.076226</td>\n",
       "      <td>0.093150</td>\n",
       "      <td>0.071441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aug</td>\n",
       "      <td>0.120874</td>\n",
       "      <td>-0.022788</td>\n",
       "      <td>0.100891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sept</td>\n",
       "      <td>-0.064527</td>\n",
       "      <td>-0.097768</td>\n",
       "      <td>-0.052966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oct</td>\n",
       "      <td>-0.040388</td>\n",
       "      <td>-0.009769</td>\n",
       "      <td>-0.059174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month      Best     Worst   Optimal\n",
       "0   Jan  0.052644 -0.046572  0.052707\n",
       "1   Feb -0.061766 -0.060855 -0.070809\n",
       "2   Mar -0.110870 -0.081382 -0.144133\n",
       "3   Apr  0.138666  0.106648  0.135605\n",
       "4   May  0.084689  0.065252  0.070840\n",
       "5   Jun  0.091070 -0.005376  0.045264\n",
       "6   Jul  0.076226  0.093150  0.071441\n",
       "7   Aug  0.120874 -0.022788  0.100891\n",
       "8  Sept -0.064527 -0.097768 -0.052966\n",
       "9   Oct -0.040388 -0.009769 -0.059174"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sept','Oct']\n",
    "table_monthly_returns=pd.DataFrame({'Month':months,'Best':returns_df_best['portfolio return'],'Worst':returns_df_worst['portfolio return'],'Optimal':returns_df_optimal['portfolio return']})\n",
    "table_monthly_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns of optimal portfolio (after  adjustment) for Oct 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_optimal = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]\n",
    "\n",
    "returns_df_optimal_after = get_data_for_multiple_stocks_monthly(tickers_optimal,\n",
    "                                          start_date = \"2020-09-01\", end_date = \"2020-10-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>MA adj_close</th>\n",
       "      <th>MA prev_close</th>\n",
       "      <th>MA log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>MELI log_returns</th>\n",
       "      <th>G adj_close</th>\n",
       "      <th>G prev_close</th>\n",
       "      <th>G log_returns</th>\n",
       "      <th>MDB adj_close</th>\n",
       "      <th>MDB prev_close</th>\n",
       "      <th>MDB log_returns</th>\n",
       "      <th>NXPI adj_close</th>\n",
       "      <th>NXPI prev_close</th>\n",
       "      <th>NXPI log_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>-0.061888</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>288.304291</td>\n",
       "      <td>337.776672</td>\n",
       "      <td>-0.158368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114707</td>\n",
       "      <td>34.369999</td>\n",
       "      <td>38.851696</td>\n",
       "      <td>-0.122568</td>\n",
       "      <td>228.470001</td>\n",
       "      <td>231.509995</td>\n",
       "      <td>-0.013218</td>\n",
       "      <td>135.119995</td>\n",
       "      <td>124.434814</td>\n",
       "      <td>0.082381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AAPL adj_close  AAPL prev_close  AAPL log_returns  \\\n",
       "0 2020-10-01      108.672516       115.610542         -0.061888   \n",
       "\n",
       "   MSFT adj_close  MSFT prev_close  MSFT log_returns  MA adj_close  \\\n",
       "0      202.470001       210.330002         -0.038086    288.304291   \n",
       "\n",
       "   MA prev_close  MA log_returns  ...  MELI log_returns  G adj_close  \\\n",
       "0     337.776672       -0.158368  ...          0.114707    34.369999   \n",
       "\n",
       "   G prev_close  G log_returns  MDB adj_close  MDB prev_close  \\\n",
       "0     38.851696      -0.122568     228.470001      231.509995   \n",
       "\n",
       "   MDB log_returns  NXPI adj_close  NXPI prev_close  NXPI log_returns  \n",
       "0        -0.013218      135.119995       124.434814          0.082381  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_optimal_after.dropna(inplace = True)\n",
    "returns_df_optimal_after.reset_index(inplace=True)\n",
    "returns_df_optimal_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>MA adj_close</th>\n",
       "      <th>MA prev_close</th>\n",
       "      <th>MA log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>G adj_close</th>\n",
       "      <th>G prev_close</th>\n",
       "      <th>G log_returns</th>\n",
       "      <th>MDB adj_close</th>\n",
       "      <th>MDB prev_close</th>\n",
       "      <th>MDB log_returns</th>\n",
       "      <th>NXPI adj_close</th>\n",
       "      <th>NXPI prev_close</th>\n",
       "      <th>NXPI log_returns</th>\n",
       "      <th>portfolio return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>-0.061888</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>288.304291</td>\n",
       "      <td>337.776672</td>\n",
       "      <td>-0.158368</td>\n",
       "      <td>...</td>\n",
       "      <td>34.369999</td>\n",
       "      <td>38.851696</td>\n",
       "      <td>-0.122568</td>\n",
       "      <td>228.470001</td>\n",
       "      <td>231.509995</td>\n",
       "      <td>-0.013218</td>\n",
       "      <td>135.119995</td>\n",
       "      <td>124.434814</td>\n",
       "      <td>0.082381</td>\n",
       "      <td>-0.052905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AAPL adj_close  AAPL prev_close  AAPL log_returns  \\\n",
       "0 2020-10-01      108.672516       115.610542         -0.061888   \n",
       "\n",
       "   MSFT adj_close  MSFT prev_close  MSFT log_returns  MA adj_close  \\\n",
       "0      202.470001       210.330002         -0.038086    288.304291   \n",
       "\n",
       "   MA prev_close  MA log_returns  ...  G adj_close  G prev_close  \\\n",
       "0     337.776672       -0.158368  ...    34.369999     38.851696   \n",
       "\n",
       "   G log_returns  MDB adj_close  MDB prev_close  MDB log_returns  \\\n",
       "0      -0.122568     228.470001      231.509995        -0.013218   \n",
       "\n",
       "   NXPI adj_close  NXPI prev_close  NXPI log_returns  portfolio return  \n",
       "0      135.119995       124.434814          0.082381         -0.052905  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_optimal_after[\"portfolio return\"] = 0\n",
    "\n",
    "optimal_weights_after = [0.0609385, 0.1295965999999999998, 0.1334389499999999997, 0.137560,0.074765,\n",
    "                   0.070833, 0.0556545, 0.040578, 0.119718, 0.0383979,\n",
    "                   0.016148, 0.044405,0.015470, 0.072358]\n",
    "\n",
    "for i in range(len(tickers_optimal)):\n",
    "    returns_df_optimal_after[\"portfolio return\"] += optimal_weights_after[i]*(np.exp(returns_df_optimal_after[tickers_optimal[i]+\" log_returns\"]) - 1)\n",
    "\n",
    "returns_df_optimal_after[\"portfolio return\"] = np.log(1+returns_df_optimal_after[\"portfolio return\"])\n",
    "returns_df_optimal_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 - Annualised Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annualised SD for Best Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_best = [\"AAPL\", \"MSFT\", \"ADBE\", \"CRM\", \"NVDA\", \"MA\", \"PYPL\", \"V\", \"MU\", \"FIS\",\n",
    "           \"LRCX\", \"FB\", \"AMAT\", \"QCOM\", \"TWLO\", \"WDAY\", \"AMZN\", \"INTU\", \"ADSK\", \"AMD\",\n",
    "           \"HUBS\", \"MELI\", \"ESTC\", \"G\", \"GDDY\", \"FLEX\", \"MDB\", \"NXPI\", \"FISV\", \"MRVL\"]\n",
    "returns_df_best_daily = get_data_for_multiple_stocks_daily(tickers_best,\n",
    "                                          start_date = \"2020-01-01\", end_date = \"2020-10-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>ADBE adj_close</th>\n",
       "      <th>ADBE prev_close</th>\n",
       "      <th>ADBE log_returns</th>\n",
       "      <th>CRM adj_close</th>\n",
       "      <th>...</th>\n",
       "      <th>MDB log_returns</th>\n",
       "      <th>NXPI adj_close</th>\n",
       "      <th>NXPI prev_close</th>\n",
       "      <th>NXPI log_returns</th>\n",
       "      <th>FISV adj_close</th>\n",
       "      <th>FISV prev_close</th>\n",
       "      <th>FISV log_returns</th>\n",
       "      <th>MRVL adj_close</th>\n",
       "      <th>MRVL prev_close</th>\n",
       "      <th>MRVL log_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>72.192863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.455429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>329.809998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.639999</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.897690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.629997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.407440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>73.840042</td>\n",
       "      <td>72.192863</td>\n",
       "      <td>0.022560</td>\n",
       "      <td>159.352386</td>\n",
       "      <td>156.455429</td>\n",
       "      <td>0.018347</td>\n",
       "      <td>334.429993</td>\n",
       "      <td>329.809998</td>\n",
       "      <td>0.013911</td>\n",
       "      <td>166.990005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>127.163986</td>\n",
       "      <td>125.897690</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>115.519997</td>\n",
       "      <td>115.629997</td>\n",
       "      <td>-0.000952</td>\n",
       "      <td>27.222731</td>\n",
       "      <td>26.407440</td>\n",
       "      <td>0.030407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>73.122154</td>\n",
       "      <td>73.840042</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>157.368179</td>\n",
       "      <td>159.352386</td>\n",
       "      <td>-0.012530</td>\n",
       "      <td>331.809998</td>\n",
       "      <td>334.429993</td>\n",
       "      <td>-0.007865</td>\n",
       "      <td>166.169998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>125.937263</td>\n",
       "      <td>127.163986</td>\n",
       "      <td>-0.009694</td>\n",
       "      <td>116.370003</td>\n",
       "      <td>115.519997</td>\n",
       "      <td>0.007331</td>\n",
       "      <td>26.516809</td>\n",
       "      <td>27.222731</td>\n",
       "      <td>-0.026273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>73.704819</td>\n",
       "      <td>73.122154</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>157.774948</td>\n",
       "      <td>157.368179</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>333.709991</td>\n",
       "      <td>331.809998</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>173.449997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037787</td>\n",
       "      <td>125.046890</td>\n",
       "      <td>125.937263</td>\n",
       "      <td>-0.007095</td>\n",
       "      <td>116.930000</td>\n",
       "      <td>116.370003</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>25.532495</td>\n",
       "      <td>26.516809</td>\n",
       "      <td>-0.037827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>73.358185</td>\n",
       "      <td>73.704819</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>156.336395</td>\n",
       "      <td>157.774948</td>\n",
       "      <td>-0.009160</td>\n",
       "      <td>333.390015</td>\n",
       "      <td>333.709991</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>126.669334</td>\n",
       "      <td>125.046890</td>\n",
       "      <td>0.012891</td>\n",
       "      <td>116.480003</td>\n",
       "      <td>116.930000</td>\n",
       "      <td>-0.003856</td>\n",
       "      <td>26.099222</td>\n",
       "      <td>25.532495</td>\n",
       "      <td>0.021954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-26</th>\n",
       "      <td>114.851852</td>\n",
       "      <td>114.841873</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>216.229996</td>\n",
       "      <td>-0.028854</td>\n",
       "      <td>475.200012</td>\n",
       "      <td>488.500000</td>\n",
       "      <td>-0.027604</td>\n",
       "      <td>241.979996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032373</td>\n",
       "      <td>134.889999</td>\n",
       "      <td>137.179993</td>\n",
       "      <td>-0.016834</td>\n",
       "      <td>98.379997</td>\n",
       "      <td>101.180000</td>\n",
       "      <td>-0.028064</td>\n",
       "      <td>40.889999</td>\n",
       "      <td>41.430000</td>\n",
       "      <td>-0.013120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27</th>\n",
       "      <td>116.399178</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>0.013382</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>478.559998</td>\n",
       "      <td>475.200012</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>250.300003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>133.229996</td>\n",
       "      <td>134.889999</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>96.610001</td>\n",
       "      <td>98.379997</td>\n",
       "      <td>-0.018155</td>\n",
       "      <td>41.470001</td>\n",
       "      <td>40.889999</td>\n",
       "      <td>0.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-28</th>\n",
       "      <td>111.008476</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>-0.047419</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>-0.050837</td>\n",
       "      <td>456.970001</td>\n",
       "      <td>478.559998</td>\n",
       "      <td>-0.046164</td>\n",
       "      <td>238.429993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016404</td>\n",
       "      <td>129.770004</td>\n",
       "      <td>133.229996</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>93.519997</td>\n",
       "      <td>96.610001</td>\n",
       "      <td>-0.032507</td>\n",
       "      <td>39.529999</td>\n",
       "      <td>41.470001</td>\n",
       "      <td>-0.047910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>115.121384</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>0.036381</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>461.109985</td>\n",
       "      <td>456.970001</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>237.139999</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018288</td>\n",
       "      <td>136.169998</td>\n",
       "      <td>129.770004</td>\n",
       "      <td>0.048140</td>\n",
       "      <td>95.769997</td>\n",
       "      <td>93.519997</td>\n",
       "      <td>0.023774</td>\n",
       "      <td>38.209999</td>\n",
       "      <td>39.529999</td>\n",
       "      <td>-0.033963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-30</th>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>-0.057648</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>-0.011051</td>\n",
       "      <td>447.100006</td>\n",
       "      <td>461.109985</td>\n",
       "      <td>-0.030854</td>\n",
       "      <td>232.270004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031112</td>\n",
       "      <td>135.119995</td>\n",
       "      <td>136.169998</td>\n",
       "      <td>-0.007741</td>\n",
       "      <td>95.470001</td>\n",
       "      <td>95.769997</td>\n",
       "      <td>-0.003137</td>\n",
       "      <td>37.509998</td>\n",
       "      <td>38.209999</td>\n",
       "      <td>-0.018490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>212 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AAPL adj_close  AAPL prev_close  AAPL log_returns  MSFT adj_close  \\\n",
       "Date                                                                            \n",
       "2019-12-31       72.192863              NaN               NaN      156.455429   \n",
       "2020-01-02       73.840042        72.192863          0.022560      159.352386   \n",
       "2020-01-03       73.122154        73.840042         -0.009770      157.368179   \n",
       "2020-01-06       73.704819        73.122154          0.007937      157.774948   \n",
       "2020-01-07       73.358185        73.704819         -0.004714      156.336395   \n",
       "...                    ...              ...               ...             ...   \n",
       "2020-10-26      114.851852       114.841873          0.000087      210.080002   \n",
       "2020-10-27      116.399178       114.851852          0.013382      213.250000   \n",
       "2020-10-28      111.008476       116.399178         -0.047419      202.679993   \n",
       "2020-10-29      115.121384       111.008476          0.036381      204.720001   \n",
       "2020-10-30      108.672516       115.121384         -0.057648      202.470001   \n",
       "\n",
       "            MSFT prev_close  MSFT log_returns  ADBE adj_close  \\\n",
       "Date                                                            \n",
       "2019-12-31              NaN               NaN      329.809998   \n",
       "2020-01-02       156.455429          0.018347      334.429993   \n",
       "2020-01-03       159.352386         -0.012530      331.809998   \n",
       "2020-01-06       157.368179          0.002581      333.709991   \n",
       "2020-01-07       157.774948         -0.009160      333.390015   \n",
       "...                     ...               ...             ...   \n",
       "2020-10-26       216.229996         -0.028854      475.200012   \n",
       "2020-10-27       210.080002          0.014977      478.559998   \n",
       "2020-10-28       213.250000         -0.050837      456.970001   \n",
       "2020-10-29       202.679993          0.010015      461.109985   \n",
       "2020-10-30       204.720001         -0.011051      447.100006   \n",
       "\n",
       "            ADBE prev_close  ADBE log_returns  CRM adj_close  ...  \\\n",
       "Date                                                          ...   \n",
       "2019-12-31              NaN               NaN     162.639999  ...   \n",
       "2020-01-02       329.809998          0.013911     166.990005  ...   \n",
       "2020-01-03       334.429993         -0.007865     166.169998  ...   \n",
       "2020-01-06       331.809998          0.005710     173.449997  ...   \n",
       "2020-01-07       333.709991         -0.000959     176.000000  ...   \n",
       "...                     ...               ...            ...  ...   \n",
       "2020-10-26       488.500000         -0.027604     241.979996  ...   \n",
       "2020-10-27       475.200012          0.007046     250.300003  ...   \n",
       "2020-10-28       478.559998         -0.046164     238.429993  ...   \n",
       "2020-10-29       456.970001          0.009019     237.139999  ...   \n",
       "2020-10-30       461.109985         -0.030854     232.270004  ...   \n",
       "\n",
       "            MDB log_returns  NXPI adj_close  NXPI prev_close  \\\n",
       "Date                                                           \n",
       "2019-12-31              NaN      125.897690              NaN   \n",
       "2020-01-02         0.020456      127.163986       125.897690   \n",
       "2020-01-03         0.007121      125.937263       127.163986   \n",
       "2020-01-06         0.037787      125.046890       125.937263   \n",
       "2020-01-07        -0.011741      126.669334       125.046890   \n",
       "...                     ...             ...              ...   \n",
       "2020-10-26        -0.032373      134.889999       137.179993   \n",
       "2020-10-27         0.016154      133.229996       134.889999   \n",
       "2020-10-28        -0.016404      129.770004       133.229996   \n",
       "2020-10-29        -0.018288      136.169998       129.770004   \n",
       "2020-10-30        -0.031112      135.119995       136.169998   \n",
       "\n",
       "            NXPI log_returns  FISV adj_close  FISV prev_close  \\\n",
       "Date                                                            \n",
       "2019-12-31               NaN      115.629997              NaN   \n",
       "2020-01-02          0.010008      115.519997       115.629997   \n",
       "2020-01-03         -0.009694      116.370003       115.519997   \n",
       "2020-01-06         -0.007095      116.930000       116.370003   \n",
       "2020-01-07          0.012891      116.480003       116.930000   \n",
       "...                      ...             ...              ...   \n",
       "2020-10-26         -0.016834       98.379997       101.180000   \n",
       "2020-10-27         -0.012383       96.610001        98.379997   \n",
       "2020-10-28         -0.026313       93.519997        96.610001   \n",
       "2020-10-29          0.048140       95.769997        93.519997   \n",
       "2020-10-30         -0.007741       95.470001        95.769997   \n",
       "\n",
       "            FISV log_returns  MRVL adj_close  MRVL prev_close  \\\n",
       "Date                                                            \n",
       "2019-12-31               NaN       26.407440              NaN   \n",
       "2020-01-02         -0.000952       27.222731        26.407440   \n",
       "2020-01-03          0.007331       26.516809        27.222731   \n",
       "2020-01-06          0.004801       25.532495        26.516809   \n",
       "2020-01-07         -0.003856       26.099222        25.532495   \n",
       "...                      ...             ...              ...   \n",
       "2020-10-26         -0.028064       40.889999        41.430000   \n",
       "2020-10-27         -0.018155       41.470001        40.889999   \n",
       "2020-10-28         -0.032507       39.529999        41.470001   \n",
       "2020-10-29          0.023774       38.209999        39.529999   \n",
       "2020-10-30         -0.003137       37.509998        38.209999   \n",
       "\n",
       "            MRVL log_returns  \n",
       "Date                          \n",
       "2019-12-31               NaN  \n",
       "2020-01-02          0.030407  \n",
       "2020-01-03         -0.026273  \n",
       "2020-01-06         -0.037827  \n",
       "2020-01-07          0.021954  \n",
       "...                      ...  \n",
       "2020-10-26         -0.013120  \n",
       "2020-10-27          0.014085  \n",
       "2020-10-28         -0.047910  \n",
       "2020-10-29         -0.033963  \n",
       "2020-10-30         -0.018490  \n",
       "\n",
       "[212 rows x 90 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_best_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df_best_daily.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_of_values_best = [2051836821, 1624363933, 329525040, 291785537, 238343597, 219364830, 212343810, 186230240, 185088374, 179336117, 165346944, 162171231, 161982940, 145298238, 121981574, 119200951,116143756, 112774797, 108946944,108161967, 105879493, 99706579, 98161895, 88818510, 83373164, 76143081, 74428092, 69989115, 66668202, 61789443]\n",
    "\n",
    "array_price=[]\n",
    "for i in range(len(tickers_best)):\n",
    "    x=returns_df_best_daily.loc[returns_df_best_daily['Date']=='2020-07-31'][tickers_best[i]+' adj_close'].values\n",
    "    array_price.append(x)\n",
    "\n",
    "shares=[]\n",
    "for i in range(len(array_price)):\n",
    "    shares.append(np.round(array_of_values_best[i]/array_price[i],0))\n",
    "\n",
    "# values = sum of adj close price*num of shares  for all stocks\n",
    "\n",
    "total=0\n",
    "for y in range(len(shares)):\n",
    "    total+=(returns_df_best_daily[tickers_best[y]+\" prev_close\"]*shares[y])\n",
    "    \n",
    "for y in range(len(shares)):\n",
    "    returns_df_best_daily[\"value\"]=total\n",
    "\n",
    "for x in range(len(shares)):\n",
    "    returns_df_best_daily[tickers_best[x]+\"_weight\"]=(returns_df_best_daily[tickers_best[x]+\" prev_close\"]*shares[x])/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>ADBE adj_close</th>\n",
       "      <th>ADBE prev_close</th>\n",
       "      <th>ADBE log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>MELI_weight</th>\n",
       "      <th>ESTC_weight</th>\n",
       "      <th>G_weight</th>\n",
       "      <th>GDDY_weight</th>\n",
       "      <th>FLEX_weight</th>\n",
       "      <th>MDB_weight</th>\n",
       "      <th>NXPI_weight</th>\n",
       "      <th>FISV_weight</th>\n",
       "      <th>MRVL_weight</th>\n",
       "      <th>portfolio return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>73.840042</td>\n",
       "      <td>72.192863</td>\n",
       "      <td>0.022560</td>\n",
       "      <td>159.352386</td>\n",
       "      <td>156.455429</td>\n",
       "      <td>0.018347</td>\n",
       "      <td>334.429993</td>\n",
       "      <td>329.809998</td>\n",
       "      <td>0.013911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008710</td>\n",
       "      <td>0.011271</td>\n",
       "      <td>0.016074</td>\n",
       "      <td>0.013840</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.012917</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.007696</td>\n",
       "      <td>0.020266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>73.122154</td>\n",
       "      <td>73.840042</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>157.368179</td>\n",
       "      <td>159.352386</td>\n",
       "      <td>-0.012530</td>\n",
       "      <td>331.809998</td>\n",
       "      <td>334.429993</td>\n",
       "      <td>-0.007865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009106</td>\n",
       "      <td>0.011301</td>\n",
       "      <td>0.015934</td>\n",
       "      <td>0.013690</td>\n",
       "      <td>0.014256</td>\n",
       "      <td>0.007346</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>-0.009570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>73.704819</td>\n",
       "      <td>73.122154</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>157.774948</td>\n",
       "      <td>157.368179</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>333.709991</td>\n",
       "      <td>331.809998</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009158</td>\n",
       "      <td>0.011460</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>0.013862</td>\n",
       "      <td>0.014134</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.012784</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.005179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>73.358185</td>\n",
       "      <td>73.704819</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>156.336395</td>\n",
       "      <td>157.774948</td>\n",
       "      <td>-0.009160</td>\n",
       "      <td>333.390015</td>\n",
       "      <td>333.709991</td>\n",
       "      <td>-0.000959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009092</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.015989</td>\n",
       "      <td>0.013903</td>\n",
       "      <td>0.013803</td>\n",
       "      <td>0.007718</td>\n",
       "      <td>0.012628</td>\n",
       "      <td>0.013207</td>\n",
       "      <td>0.007324</td>\n",
       "      <td>0.003342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>74.538239</td>\n",
       "      <td>73.358185</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>158.826569</td>\n",
       "      <td>156.336395</td>\n",
       "      <td>0.015803</td>\n",
       "      <td>337.869995</td>\n",
       "      <td>333.390015</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>0.011934</td>\n",
       "      <td>0.015932</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>0.013992</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>0.012749</td>\n",
       "      <td>0.013113</td>\n",
       "      <td>0.007462</td>\n",
       "      <td>0.012042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>114.841873</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>216.229996</td>\n",
       "      <td>-0.028854</td>\n",
       "      <td>475.200012</td>\n",
       "      <td>488.500000</td>\n",
       "      <td>-0.027604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013898</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.010611</td>\n",
       "      <td>0.011574</td>\n",
       "      <td>0.009626</td>\n",
       "      <td>0.009789</td>\n",
       "      <td>0.008076</td>\n",
       "      <td>0.008397</td>\n",
       "      <td>-0.019979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>0.013382</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>478.559998</td>\n",
       "      <td>475.200012</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>0.010541</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>0.009507</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>0.008010</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>0.008141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>-0.047419</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>-0.050837</td>\n",
       "      <td>456.970001</td>\n",
       "      <td>478.559998</td>\n",
       "      <td>-0.046164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013745</td>\n",
       "      <td>0.013311</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>0.010360</td>\n",
       "      <td>0.011095</td>\n",
       "      <td>0.009584</td>\n",
       "      <td>0.009620</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>-0.043257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>0.036381</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>461.109985</td>\n",
       "      <td>456.970001</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014253</td>\n",
       "      <td>0.013660</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>0.009845</td>\n",
       "      <td>0.009784</td>\n",
       "      <td>0.007887</td>\n",
       "      <td>0.008466</td>\n",
       "      <td>0.019106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>-0.057648</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>-0.011051</td>\n",
       "      <td>447.100006</td>\n",
       "      <td>461.109985</td>\n",
       "      <td>-0.030854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>0.013302</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.011235</td>\n",
       "      <td>0.009483</td>\n",
       "      <td>0.010073</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>-0.032134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AAPL adj_close  AAPL prev_close  AAPL log_returns  \\\n",
       "1   2020-01-02       73.840042        72.192863          0.022560   \n",
       "2   2020-01-03       73.122154        73.840042         -0.009770   \n",
       "3   2020-01-06       73.704819        73.122154          0.007937   \n",
       "4   2020-01-07       73.358185        73.704819         -0.004714   \n",
       "5   2020-01-08       74.538239        73.358185          0.015958   \n",
       "..         ...             ...              ...               ...   \n",
       "207 2020-10-26      114.851852       114.841873          0.000087   \n",
       "208 2020-10-27      116.399178       114.851852          0.013382   \n",
       "209 2020-10-28      111.008476       116.399178         -0.047419   \n",
       "210 2020-10-29      115.121384       111.008476          0.036381   \n",
       "211 2020-10-30      108.672516       115.121384         -0.057648   \n",
       "\n",
       "     MSFT adj_close  MSFT prev_close  MSFT log_returns  ADBE adj_close  \\\n",
       "1        159.352386       156.455429          0.018347      334.429993   \n",
       "2        157.368179       159.352386         -0.012530      331.809998   \n",
       "3        157.774948       157.368179          0.002581      333.709991   \n",
       "4        156.336395       157.774948         -0.009160      333.390015   \n",
       "5        158.826569       156.336395          0.015803      337.869995   \n",
       "..              ...              ...               ...             ...   \n",
       "207      210.080002       216.229996         -0.028854      475.200012   \n",
       "208      213.250000       210.080002          0.014977      478.559998   \n",
       "209      202.679993       213.250000         -0.050837      456.970001   \n",
       "210      204.720001       202.679993          0.010015      461.109985   \n",
       "211      202.470001       204.720001         -0.011051      447.100006   \n",
       "\n",
       "     ADBE prev_close  ADBE log_returns  ...  MELI_weight  ESTC_weight  \\\n",
       "1         329.809998          0.013911  ...     0.008710     0.011271   \n",
       "2         334.429993         -0.007865  ...     0.009106     0.011301   \n",
       "3         331.809998          0.005710  ...     0.009158     0.011460   \n",
       "4         333.709991         -0.000959  ...     0.009092     0.011699   \n",
       "5         333.390015          0.013348  ...     0.009337     0.011934   \n",
       "..               ...               ...  ...          ...          ...   \n",
       "207       488.500000         -0.027604  ...     0.013898     0.013289   \n",
       "208       475.200012          0.007046  ...     0.013846     0.013240   \n",
       "209       478.559998         -0.046164  ...     0.013745     0.013311   \n",
       "210       456.970001          0.009019  ...     0.014253     0.013660   \n",
       "211       461.109985         -0.030854  ...     0.014284     0.013302   \n",
       "\n",
       "     G_weight  GDDY_weight  FLEX_weight  MDB_weight  NXPI_weight  FISV_weight  \\\n",
       "1    0.016074     0.013840     0.014366    0.007345     0.012917     0.013270   \n",
       "2    0.015934     0.013690     0.014256    0.007346     0.012785     0.012991   \n",
       "3    0.016012     0.013862     0.014134    0.007470     0.012784     0.013212   \n",
       "4    0.015989     0.013903     0.013803    0.007718     0.012628     0.013207   \n",
       "5    0.015932     0.013799     0.013992    0.007602     0.012749     0.013113   \n",
       "..        ...          ...          ...         ...          ...          ...   \n",
       "207  0.009884     0.010611     0.011574    0.009626     0.009789     0.008076   \n",
       "208  0.009689     0.010541     0.011388    0.009507     0.009820     0.008010   \n",
       "209  0.009542     0.010360     0.011095    0.009584     0.009620     0.007803   \n",
       "210  0.009600     0.010656     0.011143    0.009845     0.009784     0.007887   \n",
       "211  0.009479     0.010693     0.011235    0.009483     0.010073     0.007924   \n",
       "\n",
       "     MRVL_weight  portfolio return  \n",
       "1       0.007696          0.020266  \n",
       "2       0.007775         -0.009570  \n",
       "3       0.007646          0.005179  \n",
       "4       0.007324          0.003342  \n",
       "5       0.007462          0.012042  \n",
       "..           ...               ...  \n",
       "207     0.008397         -0.019979  \n",
       "208     0.008455          0.008141  \n",
       "209     0.008506         -0.043257  \n",
       "210     0.008466          0.019106  \n",
       "211     0.008029         -0.032134  \n",
       "\n",
       "[211 rows x 123 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_best_daily[\"portfolio return\"]=0\n",
    "for i in range(len(tickers_best)):\n",
    "    returns_df_best_daily[\"portfolio return\"]+=returns_df_best_daily[tickers_best[i]+\"_weight\"]*(np.exp(returns_df_best_daily[tickers_best[i]+\" log_returns\"]) - 1)\n",
    "\n",
    "returns_df_best_daily[\"portfolio return\"]=np.log(1+returns_df_best_daily[\"portfolio return\"])\n",
    "returns_df_best_daily.dropna(inplace = True)\n",
    "returns_df_best_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.012155486928623463,\n",
       " 0.02053812318370994,\n",
       " 0.06461068567133327,\n",
       " 0.031446742629496316,\n",
       " 0.01419758867941381,\n",
       " 0.018167936083650662,\n",
       " 0.016375017684581935,\n",
       " 0.012490297341864116,\n",
       " 0.02465854414683307,\n",
       " 0.018400899831519706]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = [\"2019-12-31\",\"2020-01-31\",\"2020-02-28\",\"2020-03-31\",\"2020-04-30\",\"2020-05-31\",\"2020-06-30\",\"2020-07-31\",\"2020-08-31\", \n",
    "         \"2020-09-30\", \"2020-10-31\"]\n",
    "sd_best_monthly = []\n",
    "for i in range(len(dates)-1):\n",
    "    sd_best_monthly.append(np.std(np.exp(returns_df_best_daily.loc[(returns_df_best_daily['Date'] > dates[i]) & \n",
    "                                                      (returns_df_best_daily['Date'] <= dates[i+1])]['portfolio return'])-1))\n",
    "sd_best_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Annualised SD for Best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan</td>\n",
       "      <td>19.296237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feb</td>\n",
       "      <td>32.603260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mar</td>\n",
       "      <td>102.566284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr</td>\n",
       "      <td>49.920156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May</td>\n",
       "      <td>22.537973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jun</td>\n",
       "      <td>28.840704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jul</td>\n",
       "      <td>25.994535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aug</td>\n",
       "      <td>19.827732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sept</td>\n",
       "      <td>39.144225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oct</td>\n",
       "      <td>29.210523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month  Annualised SD for Best\n",
       "0   Jan               19.296237\n",
       "1   Feb               32.603260\n",
       "2   Mar              102.566284\n",
       "3   Apr               49.920156\n",
       "4   May               22.537973\n",
       "5   Jun               28.840704\n",
       "6   Jul               25.994535\n",
       "7   Aug               19.827732\n",
       "8  Sept               39.144225\n",
       "9   Oct               29.210523"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_best = pd.Series(sd_best_monthly)*np.sqrt(252)*100\n",
    "months=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sept','Oct']\n",
    "monthly_sd_best =pd.DataFrame({'Month':months,'Annualised SD for Best':sd_best})\n",
    "monthly_sd_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annualised SD for Worst Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_worst = [\"ERIC\", \"NOK\", \"CSCO\", \"FFIV\", \"CIEN\", \"JNPR\", \"MSI\", \"LITE\", \"SATS\", \"VIAV\", \"ACIA\", \"ANET\", \"CALX\", \"IDCC\", \n",
    "           \"VSAT\", \"NTCT\", \"COMM\", \"ET.TO\", \"FTNT\", \"PANW\", \"TENB\", \"HLIT\", \"ADTN\", \"EXTR\",\n",
    "           \"INSG\", \"RPD\", \"SW.TO\", \"CVLT\", \"GLW\", \"RBBN\"]\n",
    "returns_df_worst_daily = get_data_for_multiple_stocks_daily(tickers_worst,\n",
    "                                          start_date = \"2020-01-01\", end_date = \"2020-10-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ERIC adj_close</th>\n",
       "      <th>ERIC prev_close</th>\n",
       "      <th>ERIC log_returns</th>\n",
       "      <th>NOK adj_close</th>\n",
       "      <th>NOK prev_close</th>\n",
       "      <th>NOK log_returns</th>\n",
       "      <th>CSCO adj_close</th>\n",
       "      <th>CSCO prev_close</th>\n",
       "      <th>CSCO log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>SW.TO log_returns</th>\n",
       "      <th>CVLT adj_close</th>\n",
       "      <th>CVLT prev_close</th>\n",
       "      <th>CVLT log_returns</th>\n",
       "      <th>GLW adj_close</th>\n",
       "      <th>GLW prev_close</th>\n",
       "      <th>GLW log_returns</th>\n",
       "      <th>RBBN adj_close</th>\n",
       "      <th>RBBN prev_close</th>\n",
       "      <th>RBBN log_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>8.853482</td>\n",
       "      <td>8.627477</td>\n",
       "      <td>0.025859</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0.042223</td>\n",
       "      <td>47.155396</td>\n",
       "      <td>46.366550</td>\n",
       "      <td>0.016870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028642</td>\n",
       "      <td>45.200001</td>\n",
       "      <td>44.639999</td>\n",
       "      <td>0.012467</td>\n",
       "      <td>29.250721</td>\n",
       "      <td>28.392416</td>\n",
       "      <td>0.029782</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.10</td>\n",
       "      <td>-0.019545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>8.696262</td>\n",
       "      <td>8.853482</td>\n",
       "      <td>-0.017918</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.87</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>46.386028</td>\n",
       "      <td>47.155396</td>\n",
       "      <td>-0.016450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019803</td>\n",
       "      <td>45.180000</td>\n",
       "      <td>45.200001</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>28.870333</td>\n",
       "      <td>29.250721</td>\n",
       "      <td>-0.013090</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.035545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>8.755219</td>\n",
       "      <td>8.696262</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0.033552</td>\n",
       "      <td>46.551586</td>\n",
       "      <td>46.386028</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008032</td>\n",
       "      <td>46.020000</td>\n",
       "      <td>45.180000</td>\n",
       "      <td>0.018422</td>\n",
       "      <td>28.948362</td>\n",
       "      <td>28.870333</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.012618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>8.666782</td>\n",
       "      <td>8.755219</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>46.249683</td>\n",
       "      <td>46.551586</td>\n",
       "      <td>-0.006506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015441</td>\n",
       "      <td>45.930000</td>\n",
       "      <td>46.020000</td>\n",
       "      <td>-0.001958</td>\n",
       "      <td>29.162939</td>\n",
       "      <td>28.948362</td>\n",
       "      <td>0.007385</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>8.745392</td>\n",
       "      <td>8.666782</td>\n",
       "      <td>0.009029</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.017566</td>\n",
       "      <td>46.278904</td>\n",
       "      <td>46.249683</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021070</td>\n",
       "      <td>45.209999</td>\n",
       "      <td>45.930000</td>\n",
       "      <td>-0.015800</td>\n",
       "      <td>29.299488</td>\n",
       "      <td>29.162939</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>12.080000</td>\n",
       "      <td>12.360000</td>\n",
       "      <td>-0.022914</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.30</td>\n",
       "      <td>-0.016413</td>\n",
       "      <td>37.669998</td>\n",
       "      <td>38.820000</td>\n",
       "      <td>-0.030072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014716</td>\n",
       "      <td>41.139999</td>\n",
       "      <td>42.320000</td>\n",
       "      <td>-0.028279</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>35.560001</td>\n",
       "      <td>-0.037535</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.02</td>\n",
       "      <td>-0.020101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>11.780000</td>\n",
       "      <td>12.080000</td>\n",
       "      <td>-0.025148</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.23</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>36.869999</td>\n",
       "      <td>37.669998</td>\n",
       "      <td>-0.021466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>42.459999</td>\n",
       "      <td>41.139999</td>\n",
       "      <td>0.031582</td>\n",
       "      <td>32.849998</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>-0.041735</td>\n",
       "      <td>3.82</td>\n",
       "      <td>3.94</td>\n",
       "      <td>-0.030930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>11.380000</td>\n",
       "      <td>11.780000</td>\n",
       "      <td>-0.034546</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.24</td>\n",
       "      <td>-0.045846</td>\n",
       "      <td>35.709999</td>\n",
       "      <td>36.869999</td>\n",
       "      <td>-0.031967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012947</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>42.459999</td>\n",
       "      <td>-0.059683</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>32.849998</td>\n",
       "      <td>-0.034689</td>\n",
       "      <td>3.77</td>\n",
       "      <td>3.82</td>\n",
       "      <td>-0.013175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>11.330000</td>\n",
       "      <td>11.380000</td>\n",
       "      <td>-0.004403</td>\n",
       "      <td>3.35</td>\n",
       "      <td>4.05</td>\n",
       "      <td>-0.189757</td>\n",
       "      <td>35.689999</td>\n",
       "      <td>35.709999</td>\n",
       "      <td>-0.000560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>40.169998</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>32.099998</td>\n",
       "      <td>31.730000</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.023592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>11.210000</td>\n",
       "      <td>11.330000</td>\n",
       "      <td>-0.010648</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>35.900002</td>\n",
       "      <td>35.689999</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008086</td>\n",
       "      <td>39.590000</td>\n",
       "      <td>40.169998</td>\n",
       "      <td>-0.014544</td>\n",
       "      <td>31.969999</td>\n",
       "      <td>32.099998</td>\n",
       "      <td>-0.004058</td>\n",
       "      <td>4.31</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.110271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  ERIC adj_close  ERIC prev_close  ERIC log_returns  \\\n",
       "0   2020-01-02        8.853482         8.627477          0.025859   \n",
       "1   2020-01-03        8.696262         8.853482         -0.017918   \n",
       "2   2020-01-06        8.755219         8.696262          0.006757   \n",
       "3   2020-01-07        8.666782         8.755219         -0.010152   \n",
       "4   2020-01-08        8.745392         8.666782          0.009029   \n",
       "..         ...             ...              ...               ...   \n",
       "202 2020-10-26       12.080000        12.360000         -0.022914   \n",
       "203 2020-10-27       11.780000        12.080000         -0.025148   \n",
       "204 2020-10-28       11.380000        11.780000         -0.034546   \n",
       "205 2020-10-29       11.330000        11.380000         -0.004403   \n",
       "206 2020-10-30       11.210000        11.330000         -0.010648   \n",
       "\n",
       "     NOK adj_close  NOK prev_close  NOK log_returns  CSCO adj_close  \\\n",
       "0             3.87            3.71         0.042223       47.155396   \n",
       "1             3.81            3.87        -0.015625       46.386028   \n",
       "2             3.94            3.81         0.033552       46.551586   \n",
       "3             3.95            3.94         0.002535       46.249683   \n",
       "4             4.02            3.95         0.017566       46.278904   \n",
       "..             ...             ...              ...             ...   \n",
       "202           4.23            4.30        -0.016413       37.669998   \n",
       "203           4.24            4.23         0.002361       36.869999   \n",
       "204           4.05            4.24        -0.045846       35.709999   \n",
       "205           3.35            4.05        -0.189757       35.689999   \n",
       "206           3.37            3.35         0.005952       35.900002   \n",
       "\n",
       "     CSCO prev_close  CSCO log_returns  ...  SW.TO log_returns  \\\n",
       "0          46.366550          0.016870  ...           0.028642   \n",
       "1          47.155396         -0.016450  ...          -0.019803   \n",
       "2          46.386028          0.003563  ...          -0.008032   \n",
       "3          46.551586         -0.006506  ...          -0.015441   \n",
       "4          46.249683          0.000632  ...           0.021070   \n",
       "..               ...               ...  ...                ...   \n",
       "202        38.820000         -0.030072  ...          -0.014716   \n",
       "203        37.669998         -0.021466  ...          -0.004728   \n",
       "204        36.869999         -0.031967  ...          -0.012947   \n",
       "205        35.709999         -0.000560  ...           0.021710   \n",
       "206        35.689999          0.005867  ...          -0.008086   \n",
       "\n",
       "     CVLT adj_close  CVLT prev_close  CVLT log_returns  GLW adj_close  \\\n",
       "0         45.200001        44.639999          0.012467      29.250721   \n",
       "1         45.180000        45.200001         -0.000443      28.870333   \n",
       "2         46.020000        45.180000          0.018422      28.948362   \n",
       "3         45.930000        46.020000         -0.001958      29.162939   \n",
       "4         45.209999        45.930000         -0.015800      29.299488   \n",
       "..              ...              ...               ...            ...   \n",
       "202       41.139999        42.320000         -0.028279      34.250000   \n",
       "203       42.459999        41.139999          0.031582      32.849998   \n",
       "204       40.000000        42.459999         -0.059683      31.730000   \n",
       "205       40.169998        40.000000          0.004241      32.099998   \n",
       "206       39.590000        40.169998         -0.014544      31.969999   \n",
       "\n",
       "     GLW prev_close  GLW log_returns  RBBN adj_close  RBBN prev_close  \\\n",
       "0         28.392416         0.029782            3.04             3.10   \n",
       "1         29.250721        -0.013090            3.15             3.04   \n",
       "2         28.870333         0.002699            3.19             3.15   \n",
       "3         28.948362         0.007385            3.19             3.19   \n",
       "4         29.162939         0.004671            3.19             3.19   \n",
       "..              ...              ...             ...              ...   \n",
       "202       35.560001        -0.037535            3.94             4.02   \n",
       "203       34.250000        -0.041735            3.82             3.94   \n",
       "204       32.849998        -0.034689            3.77             3.82   \n",
       "205       31.730000         0.011593            3.86             3.77   \n",
       "206       32.099998        -0.004058            4.31             3.86   \n",
       "\n",
       "     RBBN log_returns  \n",
       "0           -0.019545  \n",
       "1            0.035545  \n",
       "2            0.012618  \n",
       "3            0.000000  \n",
       "4            0.000000  \n",
       "..                ...  \n",
       "202         -0.020101  \n",
       "203         -0.030930  \n",
       "204         -0.013175  \n",
       "205          0.023592  \n",
       "206          0.110271  \n",
       "\n",
       "[207 rows x 91 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_worst_daily.dropna(inplace = True)\n",
    "returns_df_worst_daily.reset_index(inplace=True)\n",
    "returns_df_worst_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_values_worst = [4077954, 1123183, 3142012, 903417, 870909, 866150, 810271, 631412, 554312, 536947, 523982, 413829, 402207, 400227, \n",
    "               369211, 348419, 240423, 49133, 50162, 180187, 154173, 116425, 109336, 106724,\n",
    "               104755, 102925, 96791, 93550, 56253, 52006]\n",
    "array_price=[]\n",
    "for i in range(len(tickers_worst)):\n",
    "    x=returns_df_worst_daily.loc[returns_df_worst_daily['Date']=='2020-07-31'][tickers_worst[i]+' adj_close'].values\n",
    "    array_price.append(x)\n",
    "    \n",
    "shares=[]\n",
    "for i in range(len(array_price)):\n",
    "    shares.append(np.round(stock_values_worst[i]/array_price[i],0))\n",
    "\n",
    "# values = sum of adj close price*num of shares  for all stocks\n",
    "\n",
    "total=0\n",
    "for y in range(len(shares)):\n",
    "    total+=(returns_df_worst_daily[tickers_worst[y]+\" prev_close\"]*shares[y])\n",
    "    \n",
    "for y in range(len(shares)):\n",
    "    returns_df_worst_daily[\"value\"]=total\n",
    "\n",
    "for x in range(len(shares)):\n",
    "    returns_df_worst_daily[tickers_worst[x]+\"_weight\"]=(returns_df_worst_daily[tickers_worst[x]+\" prev_close\"]*shares[x])/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ERIC adj_close</th>\n",
       "      <th>ERIC prev_close</th>\n",
       "      <th>ERIC log_returns</th>\n",
       "      <th>NOK adj_close</th>\n",
       "      <th>NOK prev_close</th>\n",
       "      <th>NOK log_returns</th>\n",
       "      <th>CSCO adj_close</th>\n",
       "      <th>CSCO prev_close</th>\n",
       "      <th>CSCO log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>HLIT_weight</th>\n",
       "      <th>ADTN_weight</th>\n",
       "      <th>EXTR_weight</th>\n",
       "      <th>INSG_weight</th>\n",
       "      <th>RPD_weight</th>\n",
       "      <th>SW.TO_weight</th>\n",
       "      <th>CVLT_weight</th>\n",
       "      <th>GLW_weight</th>\n",
       "      <th>RBBN_weight</th>\n",
       "      <th>portfolio return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>8.853482</td>\n",
       "      <td>8.627477</td>\n",
       "      <td>0.025859</td>\n",
       "      <td>3.87</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0.042223</td>\n",
       "      <td>47.155396</td>\n",
       "      <td>46.366550</td>\n",
       "      <td>0.016870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009959</td>\n",
       "      <td>0.005229</td>\n",
       "      <td>0.010578</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>0.005923</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.015365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>8.696262</td>\n",
       "      <td>8.853482</td>\n",
       "      <td>-0.017918</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.87</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>46.386028</td>\n",
       "      <td>47.155396</td>\n",
       "      <td>-0.016450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009731</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.010374</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>-0.010961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>8.755219</td>\n",
       "      <td>8.696262</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.81</td>\n",
       "      <td>0.033552</td>\n",
       "      <td>46.551586</td>\n",
       "      <td>46.386028</td>\n",
       "      <td>0.003563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009826</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.005841</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.004729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>8.666782</td>\n",
       "      <td>8.755219</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>46.249683</td>\n",
       "      <td>46.551586</td>\n",
       "      <td>-0.006506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009754</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.006347</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>-0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>8.745392</td>\n",
       "      <td>8.666782</td>\n",
       "      <td>0.009029</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.017566</td>\n",
       "      <td>46.278904</td>\n",
       "      <td>46.249683</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009808</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>0.004121</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>0.003240</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.003479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>12.080000</td>\n",
       "      <td>12.360000</td>\n",
       "      <td>-0.022914</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.30</td>\n",
       "      <td>-0.016413</td>\n",
       "      <td>37.669998</td>\n",
       "      <td>38.820000</td>\n",
       "      <td>-0.030072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008768</td>\n",
       "      <td>0.006547</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.003862</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>-0.022635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>11.780000</td>\n",
       "      <td>12.080000</td>\n",
       "      <td>-0.025148</td>\n",
       "      <td>4.24</td>\n",
       "      <td>4.23</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>36.869999</td>\n",
       "      <td>37.669998</td>\n",
       "      <td>-0.021466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008639</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.006589</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.004901</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>-0.009134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>11.380000</td>\n",
       "      <td>11.780000</td>\n",
       "      <td>-0.034546</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.24</td>\n",
       "      <td>-0.045846</td>\n",
       "      <td>35.709999</td>\n",
       "      <td>36.869999</td>\n",
       "      <td>-0.031967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008270</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.006872</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>-0.035186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>11.330000</td>\n",
       "      <td>11.380000</td>\n",
       "      <td>-0.004403</td>\n",
       "      <td>3.35</td>\n",
       "      <td>4.05</td>\n",
       "      <td>-0.189757</td>\n",
       "      <td>35.689999</td>\n",
       "      <td>35.709999</td>\n",
       "      <td>-0.000560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008182</td>\n",
       "      <td>0.006144</td>\n",
       "      <td>0.006857</td>\n",
       "      <td>0.004509</td>\n",
       "      <td>0.007018</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>0.002832</td>\n",
       "      <td>-0.009610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>11.210000</td>\n",
       "      <td>11.330000</td>\n",
       "      <td>-0.010648</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>35.900002</td>\n",
       "      <td>35.689999</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.005194</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>-0.008035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  ERIC adj_close  ERIC prev_close  ERIC log_returns  \\\n",
       "0   2020-01-02        8.853482         8.627477          0.025859   \n",
       "1   2020-01-03        8.696262         8.853482         -0.017918   \n",
       "2   2020-01-06        8.755219         8.696262          0.006757   \n",
       "3   2020-01-07        8.666782         8.755219         -0.010152   \n",
       "4   2020-01-08        8.745392         8.666782          0.009029   \n",
       "..         ...             ...              ...               ...   \n",
       "202 2020-10-26       12.080000        12.360000         -0.022914   \n",
       "203 2020-10-27       11.780000        12.080000         -0.025148   \n",
       "204 2020-10-28       11.380000        11.780000         -0.034546   \n",
       "205 2020-10-29       11.330000        11.380000         -0.004403   \n",
       "206 2020-10-30       11.210000        11.330000         -0.010648   \n",
       "\n",
       "     NOK adj_close  NOK prev_close  NOK log_returns  CSCO adj_close  \\\n",
       "0             3.87            3.71         0.042223       47.155396   \n",
       "1             3.81            3.87        -0.015625       46.386028   \n",
       "2             3.94            3.81         0.033552       46.551586   \n",
       "3             3.95            3.94         0.002535       46.249683   \n",
       "4             4.02            3.95         0.017566       46.278904   \n",
       "..             ...             ...              ...             ...   \n",
       "202           4.23            4.30        -0.016413       37.669998   \n",
       "203           4.24            4.23         0.002361       36.869999   \n",
       "204           4.05            4.24        -0.045846       35.709999   \n",
       "205           3.35            4.05        -0.189757       35.689999   \n",
       "206           3.37            3.35         0.005952       35.900002   \n",
       "\n",
       "     CSCO prev_close  CSCO log_returns  ...  HLIT_weight  ADTN_weight  \\\n",
       "0          46.366550          0.016870  ...     0.009959     0.005229   \n",
       "1          47.155396         -0.016450  ...     0.009731     0.005211   \n",
       "2          46.386028          0.003563  ...     0.009826     0.005242   \n",
       "3          46.551586         -0.006506  ...     0.009754     0.005228   \n",
       "4          46.249683          0.000632  ...     0.009808     0.005196   \n",
       "..               ...               ...  ...          ...          ...   \n",
       "202        38.820000         -0.030072  ...     0.008768     0.006547   \n",
       "203        37.669998         -0.021466  ...     0.008639     0.006476   \n",
       "204        36.869999         -0.031967  ...     0.008270     0.006274   \n",
       "205        35.709999         -0.000560  ...     0.008182     0.006144   \n",
       "206        35.689999          0.005867  ...     0.008181     0.006249   \n",
       "\n",
       "     EXTR_weight  INSG_weight  RPD_weight  SW.TO_weight  CVLT_weight  \\\n",
       "0       0.010578     0.003485    0.005923      0.004118     0.005796   \n",
       "1       0.010374     0.003479    0.006008      0.004173     0.005780   \n",
       "2       0.010474     0.003508    0.006179      0.004137     0.005841   \n",
       "3       0.010311     0.003906    0.006347      0.004084     0.005921   \n",
       "4       0.010441     0.004121    0.006389      0.004033     0.005927   \n",
       "..           ...          ...         ...           ...          ...   \n",
       "202     0.006483     0.004508    0.006749      0.004862     0.005338   \n",
       "203     0.006589     0.004474    0.006844      0.004901     0.005308   \n",
       "204     0.006793     0.004439    0.006872      0.004923     0.005528   \n",
       "205     0.006857     0.004509    0.007018      0.005033     0.005395   \n",
       "206     0.006743     0.004553    0.007082      0.005194     0.005470   \n",
       "\n",
       "     GLW_weight  RBBN_weight  portfolio return  \n",
       "0      0.003174     0.002242          0.015365  \n",
       "1      0.003220     0.002165         -0.010961  \n",
       "2      0.003213     0.002268          0.004729  \n",
       "3      0.003207     0.002286         -0.002909  \n",
       "4      0.003240     0.002293          0.003479  \n",
       "..          ...          ...               ...  \n",
       "202    0.003862     0.002824         -0.022635  \n",
       "203    0.003805     0.002832         -0.009134  \n",
       "204    0.003683     0.002770         -0.035186  \n",
       "205    0.003684     0.002832         -0.009610  \n",
       "206    0.003763     0.002928         -0.008035  \n",
       "\n",
       "[207 rows x 123 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_worst_daily[\"portfolio return\"]=0\n",
    "for i in range(len(tickers_worst)):\n",
    "    returns_df_worst_daily[\"portfolio return\"]+=returns_df_worst_daily[tickers_worst[i]+\"_weight\"]*(np.exp(returns_df_worst_daily[tickers_worst[i]+\" log_returns\"]) - 1)\n",
    "\n",
    "returns_df_worst_daily[\"portfolio return\"]=np.log(1+returns_df_worst_daily[\"portfolio return\"])\n",
    "returns_df_worst_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01089015371960872,\n",
       " 0.016001957713076415,\n",
       " 0.0541767869396271,\n",
       " 0.02576328862966948,\n",
       " 0.01477515920425737,\n",
       " 0.019804621752699078,\n",
       " 0.01722072646112422,\n",
       " 0.0076062250377751765,\n",
       " 0.018009349110716222,\n",
       " 0.014052881547247448]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = [\"2019-12-31\",\"2020-01-31\",\"2020-02-28\",\"2020-03-31\",\"2020-04-30\",\"2020-05-31\",\"2020-06-30\",\"2020-07-31\",\"2020-08-31\", \n",
    "         \"2020-09-30\", \"2020-10-31\"]\n",
    "sd_worst_monthly = []\n",
    "for i in range(len(dates)-1):\n",
    "    sd_worst_monthly.append(np.std(np.exp(returns_df_worst_daily.loc[(returns_df_worst_daily['Date'] > dates[i]) & \n",
    "                                                      (returns_df_worst_daily['Date'] <= dates[i+1])]['portfolio return'])-1))\n",
    "sd_worst_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Annualised SD for Worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan</td>\n",
       "      <td>17.287583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feb</td>\n",
       "      <td>25.402320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mar</td>\n",
       "      <td>86.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr</td>\n",
       "      <td>40.897953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May</td>\n",
       "      <td>23.454838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jun</td>\n",
       "      <td>31.438862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jul</td>\n",
       "      <td>27.337056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aug</td>\n",
       "      <td>12.074508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sept</td>\n",
       "      <td>28.588955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oct</td>\n",
       "      <td>22.308258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month  Annualised SD for Worst\n",
       "0   Jan                17.287583\n",
       "1   Feb                25.402320\n",
       "2   Mar                86.002983\n",
       "3   Apr                40.897953\n",
       "4   May                23.454838\n",
       "5   Jun                31.438862\n",
       "6   Jul                27.337056\n",
       "7   Aug                12.074508\n",
       "8  Sept                28.588955\n",
       "9   Oct                22.308258"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_worst = pd.Series(sd_worst_monthly)*np.sqrt(252)*100\n",
    "months=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sept','Oct']\n",
    "monthly_sd_worst = pd.DataFrame({'Month':months,'Annualised SD for Worst':sd_worst })\n",
    "monthly_sd_worst "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annualised SD for Optimal Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_optimal = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]\n",
    "returns_df_optimal_daily = get_data_for_multiple_stocks_daily(tickers_optimal,\n",
    "                                          start_date = \"2020-01-01\", end_date = \"2020-10-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>MA adj_close</th>\n",
       "      <th>MA prev_close</th>\n",
       "      <th>MA log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>MELI log_returns</th>\n",
       "      <th>G adj_close</th>\n",
       "      <th>G prev_close</th>\n",
       "      <th>G log_returns</th>\n",
       "      <th>MDB adj_close</th>\n",
       "      <th>MDB prev_close</th>\n",
       "      <th>MDB log_returns</th>\n",
       "      <th>NXPI adj_close</th>\n",
       "      <th>NXPI prev_close</th>\n",
       "      <th>NXPI log_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>73.840042</td>\n",
       "      <td>72.192863</td>\n",
       "      <td>0.022560</td>\n",
       "      <td>159.352386</td>\n",
       "      <td>156.455429</td>\n",
       "      <td>0.018347</td>\n",
       "      <td>301.763092</td>\n",
       "      <td>296.988831</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064736</td>\n",
       "      <td>42.332726</td>\n",
       "      <td>41.846481</td>\n",
       "      <td>0.011553</td>\n",
       "      <td>134.330002</td>\n",
       "      <td>131.610001</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>127.163986</td>\n",
       "      <td>125.897690</td>\n",
       "      <td>0.010008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>73.122154</td>\n",
       "      <td>73.840042</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>157.368179</td>\n",
       "      <td>159.352386</td>\n",
       "      <td>-0.012530</td>\n",
       "      <td>298.818970</td>\n",
       "      <td>301.763092</td>\n",
       "      <td>-0.009804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003925</td>\n",
       "      <td>42.134258</td>\n",
       "      <td>42.332726</td>\n",
       "      <td>-0.004699</td>\n",
       "      <td>135.289993</td>\n",
       "      <td>134.330002</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>125.937263</td>\n",
       "      <td>127.163986</td>\n",
       "      <td>-0.009694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>73.704819</td>\n",
       "      <td>73.122154</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>157.774948</td>\n",
       "      <td>157.368179</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>299.614655</td>\n",
       "      <td>298.818970</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002059</td>\n",
       "      <td>42.293030</td>\n",
       "      <td>42.134258</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>135.289993</td>\n",
       "      <td>0.037787</td>\n",
       "      <td>125.046890</td>\n",
       "      <td>125.937263</td>\n",
       "      <td>-0.007095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>73.358185</td>\n",
       "      <td>73.704819</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>156.336395</td>\n",
       "      <td>157.774948</td>\n",
       "      <td>-0.009160</td>\n",
       "      <td>298.600159</td>\n",
       "      <td>299.614655</td>\n",
       "      <td>-0.003392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029965</td>\n",
       "      <td>42.283112</td>\n",
       "      <td>42.293030</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>138.860001</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>126.669334</td>\n",
       "      <td>125.046890</td>\n",
       "      <td>0.012891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>74.538239</td>\n",
       "      <td>73.358185</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>158.826569</td>\n",
       "      <td>156.336395</td>\n",
       "      <td>0.015803</td>\n",
       "      <td>303.868805</td>\n",
       "      <td>298.600159</td>\n",
       "      <td>0.017491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013414</td>\n",
       "      <td>42.412109</td>\n",
       "      <td>42.283112</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>140.270004</td>\n",
       "      <td>138.860001</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>126.985916</td>\n",
       "      <td>126.669334</td>\n",
       "      <td>0.002496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>114.841873</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>216.229996</td>\n",
       "      <td>-0.028854</td>\n",
       "      <td>318.059998</td>\n",
       "      <td>329.609985</td>\n",
       "      <td>-0.035670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023690</td>\n",
       "      <td>35.549999</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>240.100006</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>-0.032373</td>\n",
       "      <td>134.889999</td>\n",
       "      <td>137.179993</td>\n",
       "      <td>-0.016834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>0.013382</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>317.109985</td>\n",
       "      <td>318.059998</td>\n",
       "      <td>-0.002991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>35.549999</td>\n",
       "      <td>-0.007057</td>\n",
       "      <td>244.009995</td>\n",
       "      <td>240.100006</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>133.229996</td>\n",
       "      <td>134.889999</td>\n",
       "      <td>-0.012383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>-0.047419</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>-0.050837</td>\n",
       "      <td>291.380005</td>\n",
       "      <td>317.109985</td>\n",
       "      <td>-0.084620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006948</td>\n",
       "      <td>34.009998</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>-0.037228</td>\n",
       "      <td>240.039993</td>\n",
       "      <td>244.009995</td>\n",
       "      <td>-0.016404</td>\n",
       "      <td>129.770004</td>\n",
       "      <td>133.229996</td>\n",
       "      <td>-0.026313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>0.036381</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>293.179993</td>\n",
       "      <td>291.380005</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021278</td>\n",
       "      <td>34.230000</td>\n",
       "      <td>34.009998</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>235.690002</td>\n",
       "      <td>240.039993</td>\n",
       "      <td>-0.018288</td>\n",
       "      <td>136.169998</td>\n",
       "      <td>129.770004</td>\n",
       "      <td>0.048140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>-0.057648</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>-0.011051</td>\n",
       "      <td>288.640015</td>\n",
       "      <td>293.179993</td>\n",
       "      <td>-0.015606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069156</td>\n",
       "      <td>34.369999</td>\n",
       "      <td>34.230000</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>228.470001</td>\n",
       "      <td>235.690002</td>\n",
       "      <td>-0.031112</td>\n",
       "      <td>135.119995</td>\n",
       "      <td>136.169998</td>\n",
       "      <td>-0.007741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AAPL adj_close  AAPL prev_close  AAPL log_returns  \\\n",
       "0   2020-01-02       73.840042        72.192863          0.022560   \n",
       "1   2020-01-03       73.122154        73.840042         -0.009770   \n",
       "2   2020-01-06       73.704819        73.122154          0.007937   \n",
       "3   2020-01-07       73.358185        73.704819         -0.004714   \n",
       "4   2020-01-08       74.538239        73.358185          0.015958   \n",
       "..         ...             ...              ...               ...   \n",
       "206 2020-10-26      114.851852       114.841873          0.000087   \n",
       "207 2020-10-27      116.399178       114.851852          0.013382   \n",
       "208 2020-10-28      111.008476       116.399178         -0.047419   \n",
       "209 2020-10-29      115.121384       111.008476          0.036381   \n",
       "210 2020-10-30      108.672516       115.121384         -0.057648   \n",
       "\n",
       "     MSFT adj_close  MSFT prev_close  MSFT log_returns  MA adj_close  \\\n",
       "0        159.352386       156.455429          0.018347    301.763092   \n",
       "1        157.368179       159.352386         -0.012530    298.818970   \n",
       "2        157.774948       157.368179          0.002581    299.614655   \n",
       "3        156.336395       157.774948         -0.009160    298.600159   \n",
       "4        158.826569       156.336395          0.015803    303.868805   \n",
       "..              ...              ...               ...           ...   \n",
       "206      210.080002       216.229996         -0.028854    318.059998   \n",
       "207      213.250000       210.080002          0.014977    317.109985   \n",
       "208      202.679993       213.250000         -0.050837    291.380005   \n",
       "209      204.720001       202.679993          0.010015    293.179993   \n",
       "210      202.470001       204.720001         -0.011051    288.640015   \n",
       "\n",
       "     MA prev_close  MA log_returns  ...  MELI log_returns  G adj_close  \\\n",
       "0       296.988831        0.015948  ...          0.064736    42.332726   \n",
       "1       301.763092       -0.009804  ...         -0.003925    42.134258   \n",
       "2       298.818970        0.002659  ...         -0.002059    42.293030   \n",
       "3       299.614655       -0.003392  ...          0.029965    42.283112   \n",
       "4       298.600159        0.017491  ...          0.013414    42.412109   \n",
       "..             ...             ...  ...               ...          ...   \n",
       "206     329.609985       -0.035670  ...         -0.023690    35.549999   \n",
       "207     318.059998       -0.002991  ...          0.000803    35.299999   \n",
       "208     317.109985       -0.084620  ...         -0.006948    34.009998   \n",
       "209     291.380005        0.006158  ...          0.021278    34.230000   \n",
       "210     293.179993       -0.015606  ...         -0.069156    34.369999   \n",
       "\n",
       "     G prev_close  G log_returns  MDB adj_close  MDB prev_close  \\\n",
       "0       41.846481       0.011553     134.330002      131.610001   \n",
       "1       42.332726      -0.004699     135.289993      134.330002   \n",
       "2       42.134258       0.003761     140.500000      135.289993   \n",
       "3       42.293030      -0.000235     138.860001      140.500000   \n",
       "4       42.283112       0.003046     140.270004      138.860001   \n",
       "..            ...            ...            ...             ...   \n",
       "206     37.000000      -0.039978     240.100006      248.000000   \n",
       "207     35.549999      -0.007057     244.009995      240.100006   \n",
       "208     35.299999      -0.037228     240.039993      244.009995   \n",
       "209     34.009998       0.006448     235.690002      240.039993   \n",
       "210     34.230000       0.004082     228.470001      235.690002   \n",
       "\n",
       "     MDB log_returns  NXPI adj_close  NXPI prev_close  NXPI log_returns  \n",
       "0           0.020456      127.163986       125.897690          0.010008  \n",
       "1           0.007121      125.937263       127.163986         -0.009694  \n",
       "2           0.037787      125.046890       125.937263         -0.007095  \n",
       "3          -0.011741      126.669334       125.046890          0.012891  \n",
       "4           0.010103      126.985916       126.669334          0.002496  \n",
       "..               ...             ...              ...               ...  \n",
       "206        -0.032373      134.889999       137.179993         -0.016834  \n",
       "207         0.016154      133.229996       134.889999         -0.012383  \n",
       "208        -0.016404      129.770004       133.229996         -0.026313  \n",
       "209        -0.018288      136.169998       129.770004          0.048140  \n",
       "210        -0.031112      135.119995       136.169998         -0.007741  \n",
       "\n",
       "[211 rows x 43 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_optimal_daily.dropna(inplace = True)\n",
    "returns_df_optimal_daily.reset_index(inplace=True)\n",
    "returns_df_optimal_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>MA adj_close</th>\n",
       "      <th>MA prev_close</th>\n",
       "      <th>MA log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>G adj_close</th>\n",
       "      <th>G prev_close</th>\n",
       "      <th>G log_returns</th>\n",
       "      <th>MDB adj_close</th>\n",
       "      <th>MDB prev_close</th>\n",
       "      <th>MDB log_returns</th>\n",
       "      <th>NXPI adj_close</th>\n",
       "      <th>NXPI prev_close</th>\n",
       "      <th>NXPI log_returns</th>\n",
       "      <th>portfolio return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>73.840042</td>\n",
       "      <td>72.192863</td>\n",
       "      <td>0.022560</td>\n",
       "      <td>159.352386</td>\n",
       "      <td>156.455429</td>\n",
       "      <td>0.018347</td>\n",
       "      <td>301.763092</td>\n",
       "      <td>296.988831</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>...</td>\n",
       "      <td>42.332726</td>\n",
       "      <td>41.846481</td>\n",
       "      <td>0.011553</td>\n",
       "      <td>134.330002</td>\n",
       "      <td>131.610001</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>127.163986</td>\n",
       "      <td>125.897690</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>0.018309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>73.122154</td>\n",
       "      <td>73.840042</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>157.368179</td>\n",
       "      <td>159.352386</td>\n",
       "      <td>-0.012530</td>\n",
       "      <td>298.818970</td>\n",
       "      <td>301.763092</td>\n",
       "      <td>-0.009804</td>\n",
       "      <td>...</td>\n",
       "      <td>42.134258</td>\n",
       "      <td>42.332726</td>\n",
       "      <td>-0.004699</td>\n",
       "      <td>135.289993</td>\n",
       "      <td>134.330002</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>125.937263</td>\n",
       "      <td>127.163986</td>\n",
       "      <td>-0.009694</td>\n",
       "      <td>-0.008768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>73.704819</td>\n",
       "      <td>73.122154</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>157.774948</td>\n",
       "      <td>157.368179</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>299.614655</td>\n",
       "      <td>298.818970</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>...</td>\n",
       "      <td>42.293030</td>\n",
       "      <td>42.134258</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>135.289993</td>\n",
       "      <td>0.037787</td>\n",
       "      <td>125.046890</td>\n",
       "      <td>125.937263</td>\n",
       "      <td>-0.007095</td>\n",
       "      <td>0.001885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>73.358185</td>\n",
       "      <td>73.704819</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>156.336395</td>\n",
       "      <td>157.774948</td>\n",
       "      <td>-0.009160</td>\n",
       "      <td>298.600159</td>\n",
       "      <td>299.614655</td>\n",
       "      <td>-0.003392</td>\n",
       "      <td>...</td>\n",
       "      <td>42.283112</td>\n",
       "      <td>42.293030</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>138.860001</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>126.669334</td>\n",
       "      <td>125.046890</td>\n",
       "      <td>0.012891</td>\n",
       "      <td>0.000403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>74.538239</td>\n",
       "      <td>73.358185</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>158.826569</td>\n",
       "      <td>156.336395</td>\n",
       "      <td>0.015803</td>\n",
       "      <td>303.868805</td>\n",
       "      <td>298.600159</td>\n",
       "      <td>0.017491</td>\n",
       "      <td>...</td>\n",
       "      <td>42.412109</td>\n",
       "      <td>42.283112</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>140.270004</td>\n",
       "      <td>138.860001</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>126.985916</td>\n",
       "      <td>126.669334</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.014076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>114.841873</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>216.229996</td>\n",
       "      <td>-0.028854</td>\n",
       "      <td>318.059998</td>\n",
       "      <td>329.609985</td>\n",
       "      <td>-0.035670</td>\n",
       "      <td>...</td>\n",
       "      <td>35.549999</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>240.100006</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>-0.032373</td>\n",
       "      <td>134.889999</td>\n",
       "      <td>137.179993</td>\n",
       "      <td>-0.016834</td>\n",
       "      <td>-0.023630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>0.013382</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>317.109985</td>\n",
       "      <td>318.059998</td>\n",
       "      <td>-0.002991</td>\n",
       "      <td>...</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>35.549999</td>\n",
       "      <td>-0.007057</td>\n",
       "      <td>244.009995</td>\n",
       "      <td>240.100006</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>133.229996</td>\n",
       "      <td>134.889999</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>-0.003424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>-0.047419</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>-0.050837</td>\n",
       "      <td>291.380005</td>\n",
       "      <td>317.109985</td>\n",
       "      <td>-0.084620</td>\n",
       "      <td>...</td>\n",
       "      <td>34.009998</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>-0.037228</td>\n",
       "      <td>240.039993</td>\n",
       "      <td>244.009995</td>\n",
       "      <td>-0.016404</td>\n",
       "      <td>129.770004</td>\n",
       "      <td>133.229996</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>-0.044885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>0.036381</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>293.179993</td>\n",
       "      <td>291.380005</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>...</td>\n",
       "      <td>34.230000</td>\n",
       "      <td>34.009998</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>235.690002</td>\n",
       "      <td>240.039993</td>\n",
       "      <td>-0.018288</td>\n",
       "      <td>136.169998</td>\n",
       "      <td>129.770004</td>\n",
       "      <td>0.048140</td>\n",
       "      <td>0.015694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>-0.057648</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>-0.011051</td>\n",
       "      <td>288.640015</td>\n",
       "      <td>293.179993</td>\n",
       "      <td>-0.015606</td>\n",
       "      <td>...</td>\n",
       "      <td>34.369999</td>\n",
       "      <td>34.230000</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>228.470001</td>\n",
       "      <td>235.690002</td>\n",
       "      <td>-0.031112</td>\n",
       "      <td>135.119995</td>\n",
       "      <td>136.169998</td>\n",
       "      <td>-0.007741</td>\n",
       "      <td>-0.022121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AAPL adj_close  AAPL prev_close  AAPL log_returns  \\\n",
       "0   2020-01-02       73.840042        72.192863          0.022560   \n",
       "1   2020-01-03       73.122154        73.840042         -0.009770   \n",
       "2   2020-01-06       73.704819        73.122154          0.007937   \n",
       "3   2020-01-07       73.358185        73.704819         -0.004714   \n",
       "4   2020-01-08       74.538239        73.358185          0.015958   \n",
       "..         ...             ...              ...               ...   \n",
       "206 2020-10-26      114.851852       114.841873          0.000087   \n",
       "207 2020-10-27      116.399178       114.851852          0.013382   \n",
       "208 2020-10-28      111.008476       116.399178         -0.047419   \n",
       "209 2020-10-29      115.121384       111.008476          0.036381   \n",
       "210 2020-10-30      108.672516       115.121384         -0.057648   \n",
       "\n",
       "     MSFT adj_close  MSFT prev_close  MSFT log_returns  MA adj_close  \\\n",
       "0        159.352386       156.455429          0.018347    301.763092   \n",
       "1        157.368179       159.352386         -0.012530    298.818970   \n",
       "2        157.774948       157.368179          0.002581    299.614655   \n",
       "3        156.336395       157.774948         -0.009160    298.600159   \n",
       "4        158.826569       156.336395          0.015803    303.868805   \n",
       "..              ...              ...               ...           ...   \n",
       "206      210.080002       216.229996         -0.028854    318.059998   \n",
       "207      213.250000       210.080002          0.014977    317.109985   \n",
       "208      202.679993       213.250000         -0.050837    291.380005   \n",
       "209      204.720001       202.679993          0.010015    293.179993   \n",
       "210      202.470001       204.720001         -0.011051    288.640015   \n",
       "\n",
       "     MA prev_close  MA log_returns  ...  G adj_close  G prev_close  \\\n",
       "0       296.988831        0.015948  ...    42.332726     41.846481   \n",
       "1       301.763092       -0.009804  ...    42.134258     42.332726   \n",
       "2       298.818970        0.002659  ...    42.293030     42.134258   \n",
       "3       299.614655       -0.003392  ...    42.283112     42.293030   \n",
       "4       298.600159        0.017491  ...    42.412109     42.283112   \n",
       "..             ...             ...  ...          ...           ...   \n",
       "206     329.609985       -0.035670  ...    35.549999     37.000000   \n",
       "207     318.059998       -0.002991  ...    35.299999     35.549999   \n",
       "208     317.109985       -0.084620  ...    34.009998     35.299999   \n",
       "209     291.380005        0.006158  ...    34.230000     34.009998   \n",
       "210     293.179993       -0.015606  ...    34.369999     34.230000   \n",
       "\n",
       "     G log_returns  MDB adj_close  MDB prev_close  MDB log_returns  \\\n",
       "0         0.011553     134.330002      131.610001         0.020456   \n",
       "1        -0.004699     135.289993      134.330002         0.007121   \n",
       "2         0.003761     140.500000      135.289993         0.037787   \n",
       "3        -0.000235     138.860001      140.500000        -0.011741   \n",
       "4         0.003046     140.270004      138.860001         0.010103   \n",
       "..             ...            ...             ...              ...   \n",
       "206      -0.039978     240.100006      248.000000        -0.032373   \n",
       "207      -0.007057     244.009995      240.100006         0.016154   \n",
       "208      -0.037228     240.039993      244.009995        -0.016404   \n",
       "209       0.006448     235.690002      240.039993        -0.018288   \n",
       "210       0.004082     228.470001      235.690002        -0.031112   \n",
       "\n",
       "     NXPI adj_close  NXPI prev_close  NXPI log_returns  portfolio return  \n",
       "0        127.163986       125.897690          0.010008          0.018309  \n",
       "1        125.937263       127.163986         -0.009694         -0.008768  \n",
       "2        125.046890       125.937263         -0.007095          0.001885  \n",
       "3        126.669334       125.046890          0.012891          0.000403  \n",
       "4        126.985916       126.669334          0.002496          0.014076  \n",
       "..              ...              ...               ...               ...  \n",
       "206      134.889999       137.179993         -0.016834         -0.023630  \n",
       "207      133.229996       134.889999         -0.012383         -0.003424  \n",
       "208      129.770004       133.229996         -0.026313         -0.044885  \n",
       "209      136.169998       129.770004          0.048140          0.015694  \n",
       "210      135.119995       136.169998         -0.007741         -0.022121  \n",
       "\n",
       "[211 rows x 44 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_optimal_daily[\"portfolio return\"]=0\n",
    "optimal_weights = [0.052990, 0.092569, 0.156987, 0.137560, 0.074765,\n",
    "                   0.050595, 0.000872,  0.040578, 0.199530,0.045174,\n",
    "                    0.016148, 0.044405, 0.015470, 0.072358]\n",
    "for i in range(len(tickers_optimal)):\n",
    "    returns_df_optimal_daily[\"portfolio return\"]+=optimal_weights[i]*(np.exp(returns_df_optimal_daily[tickers_optimal[i]+\" log_returns\"]) - 1)\n",
    "\n",
    "returns_df_optimal_daily[\"portfolio return\"]=np.log(1+returns_df_optimal_daily[\"portfolio return\"])\n",
    "returns_df_optimal_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0118599803853805,\n",
       " 0.019410020657894708,\n",
       " 0.06731942180098724,\n",
       " 0.03618410342099887,\n",
       " 0.015836784137754256,\n",
       " 0.01953495633820203,\n",
       " 0.012396305610493345,\n",
       " 0.008963798762385577,\n",
       " 0.020080921411513793,\n",
       " 0.01664766168926076]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = [\"2019-12-31\",\"2020-01-31\",\"2020-02-28\",\"2020-03-31\",\"2020-04-30\",\"2020-05-31\",\"2020-06-30\",\"2020-07-31\",\"2020-08-31\", \n",
    "         \"2020-09-30\", \"2020-10-31\"]\n",
    "sd_optimal_monthly = []\n",
    "for i in range(len(dates)-1):\n",
    "    sd_optimal_monthly.append(np.std(np.exp(returns_df_optimal_daily.loc[(returns_df_optimal_daily['Date'] > dates[i]) & \n",
    "                                                      (returns_df_optimal_daily['Date'] <= dates[i+1])]['portfolio return'])-1))\n",
    "sd_optimal_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Annualised SD for Optimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan</td>\n",
       "      <td>18.827135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feb</td>\n",
       "      <td>30.812453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mar</td>\n",
       "      <td>106.866269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr</td>\n",
       "      <td>57.440483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May</td>\n",
       "      <td>25.140115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jun</td>\n",
       "      <td>31.010782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jul</td>\n",
       "      <td>19.678525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aug</td>\n",
       "      <td>14.229589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sept</td>\n",
       "      <td>31.877474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oct</td>\n",
       "      <td>26.427344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month  Annualised SD for Optimal\n",
       "0   Jan                  18.827135\n",
       "1   Feb                  30.812453\n",
       "2   Mar                 106.866269\n",
       "3   Apr                  57.440483\n",
       "4   May                  25.140115\n",
       "5   Jun                  31.010782\n",
       "6   Jul                  19.678525\n",
       "7   Aug                  14.229589\n",
       "8  Sept                  31.877474\n",
       "9   Oct                  26.427344"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_optimal = pd.Series(sd_optimal_monthly)*np.sqrt(252)*100\n",
    "months=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sept','Oct']\n",
    "monthly_sd_optimal = pd.DataFrame({'Month':months,'Annualised SD for Optimal':sd_optimal })\n",
    "monthly_sd_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd_optimal = np.std(np.exp(returns_df_optimal_daily['portfolio return']) - 1)*np.sqrt(252)*100\n",
    "# print(f'Annualised Standard Deviation for Optimal Portfolio is {sd_optimal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Annualised SD for Best</th>\n",
       "      <th>Annualised SD for Worst</th>\n",
       "      <th>Annualised SD for Optimal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan</td>\n",
       "      <td>19.296237</td>\n",
       "      <td>17.287583</td>\n",
       "      <td>18.827135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feb</td>\n",
       "      <td>32.603260</td>\n",
       "      <td>25.402320</td>\n",
       "      <td>30.812453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mar</td>\n",
       "      <td>102.566284</td>\n",
       "      <td>86.002983</td>\n",
       "      <td>106.866269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apr</td>\n",
       "      <td>49.920156</td>\n",
       "      <td>40.897953</td>\n",
       "      <td>57.440483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>May</td>\n",
       "      <td>22.537973</td>\n",
       "      <td>23.454838</td>\n",
       "      <td>25.140115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jun</td>\n",
       "      <td>28.840704</td>\n",
       "      <td>31.438862</td>\n",
       "      <td>31.010782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jul</td>\n",
       "      <td>25.994535</td>\n",
       "      <td>27.337056</td>\n",
       "      <td>19.678525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Aug</td>\n",
       "      <td>19.827732</td>\n",
       "      <td>12.074508</td>\n",
       "      <td>14.229589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sept</td>\n",
       "      <td>39.144225</td>\n",
       "      <td>28.588955</td>\n",
       "      <td>31.877474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oct</td>\n",
       "      <td>29.210523</td>\n",
       "      <td>22.308258</td>\n",
       "      <td>26.427344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month  Annualised SD for Best  Annualised SD for Worst  \\\n",
       "0   Jan               19.296237                17.287583   \n",
       "1   Feb               32.603260                25.402320   \n",
       "2   Mar              102.566284                86.002983   \n",
       "3   Apr               49.920156                40.897953   \n",
       "4   May               22.537973                23.454838   \n",
       "5   Jun               28.840704                31.438862   \n",
       "6   Jul               25.994535                27.337056   \n",
       "7   Aug               19.827732                12.074508   \n",
       "8  Sept               39.144225                28.588955   \n",
       "9   Oct               29.210523                22.308258   \n",
       "\n",
       "   Annualised SD for Optimal  \n",
       "0                  18.827135  \n",
       "1                  30.812453  \n",
       "2                 106.866269  \n",
       "3                  57.440483  \n",
       "4                  25.140115  \n",
       "5                  31.010782  \n",
       "6                  19.678525  \n",
       "7                  14.229589  \n",
       "8                  31.877474  \n",
       "9                  26.427344  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_sd = pd.DataFrame({'Month':months,'Annualised SD for Best':sd_best, 'Annualised SD for Worst':sd_worst, 'Annualised SD for Optimal':sd_optimal })\n",
    "combined_df_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SD graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(returns_df_best['Date'], combined_df_sd['Annualised SD for Best'], 'g', label='Annualised SD for Best Portfolio (FSPTX) in 2020')\n",
    "plt.plot(returns_df_worst['Date'], combined_df_sd['Annualised SD for Worst'], 'r', label='Annualised SD for Worst Portfolio (FDMAX) in 2020')\n",
    "plt.plot(returns_df_optimal['Date'], combined_df_sd['Annualised SD for Optimal'], 'b', label='Annualised SD for our Optimal Portfolio in 2020')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Date')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=45)\n",
    "plt.title('Annualised Standard Deviation for Best, Worst and Optimal Portfolio in 2020')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SD of optimal portfolio (after adjustment) for Oct 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_optimal = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]\n",
    "returns_df_optimal_daily = get_data_for_multiple_stocks_daily(tickers_optimal,\n",
    "                                          start_date = \"2020-09-30\", end_date = \"2020-10-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df_optimal_daily.dropna(inplace = True)\n",
    "returns_df_optimal_daily.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df_optimal_daily[\"portfolio return\"]=0\n",
    "\n",
    "optimal_weights_after = [0.0609385, 0.1295965999999999998, 0.1334389499999999997, 0.137560,0.074765,\n",
    "                   0.070833, 0.0556545, 0.040578, 0.119718, 0.0383979,\n",
    "                   0.016148, 0.044405,0.015470, 0.072358]\n",
    "for i in range(len(tickers_optimal)):\n",
    "    returns_df_optimal_daily[\"portfolio return\"]+=optimal_weights_after[i]*(np.exp(returns_df_optimal_daily[tickers_optimal[i]+\" log_returns\"]) - 1)\n",
    "\n",
    "returns_df_optimal_daily[\"portfolio return\"]=np.log(1+returns_df_optimal_daily[\"portfolio return\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.017000509109897404]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = [\"2020-09-30\", \"2020-10-31\"]\n",
    "sd_optimal_monthly = []\n",
    "for i in range(len(dates)-1):\n",
    "    sd_optimal_monthly.append(np.std(np.exp(returns_df_optimal_daily.loc[(returns_df_optimal_daily['Date'] > dates[i]) & \n",
    "                                                      (returns_df_optimal_daily['Date'] <= dates[i+1])]['portfolio return'])-1))\n",
    "sd_optimal_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_optimal = pd.Series(sd_optimal_monthly)*np.sqrt(252)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26.987472\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_optimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_best_sept=[\"MSFT\" ,\"AAPL\", \"MA\" ,\"NVDA\",  \"CRM\" , \"PYPL\" , \"FIS\" , \"UBER\", \"MRVL\", \"NLOK\" ,\"JBL\" , \"FLEX\", \"FB\",\"ADSK\",\"G\" ,\"WDAY\", \"MU\",\"ADBE\",\"ESTC\",\"ZEN\" ,\"ORCL\", \"SVMK\",\"AMD\" ,\"EXPE\" ,\"RUN\" ,\"NXPI\" ,\"QCOM\",\"AAXN\" ,\"LPSN\"]\n",
    "\n",
    "array_of_values_best_sept=[1780998721 ,936611985 ,461039335 ,341915735 ,277303472  ,235332632 ,201563907 ,182742766 ,170271474 \n",
    ",155197689 ,152718712 ,143081280 ,138545100 ,135672173 ,135133130 ,126272705 ,116315224 ,113504629,110101745 \n",
    ",108405636 ,105555570 ,104330457 ,101315043,99841241 ,99840948,96667217 ,95697376,94690800 \n",
    ",90612227]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##VSLR have NA values for nov so we use 31st stock to replace which is ON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MA adj_close</th>\n",
       "      <th>MA prev_close</th>\n",
       "      <th>MA log_returns</th>\n",
       "      <th>NVDA adj_close</th>\n",
       "      <th>...</th>\n",
       "      <th>NXPI log_returns</th>\n",
       "      <th>QCOM adj_close</th>\n",
       "      <th>QCOM prev_close</th>\n",
       "      <th>QCOM log_returns</th>\n",
       "      <th>AAXN adj_close</th>\n",
       "      <th>AAXN prev_close</th>\n",
       "      <th>AAXN log_returns</th>\n",
       "      <th>LPSN adj_close</th>\n",
       "      <th>LPSN prev_close</th>\n",
       "      <th>LPSN log_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-01</th>\n",
       "      <td>210.330002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337.776672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>541.058105</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.053070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.699997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.990002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>202.470001</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>-0.061888</td>\n",
       "      <td>288.304291</td>\n",
       "      <td>337.776672</td>\n",
       "      <td>-0.158368</td>\n",
       "      <td>501.359985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082381</td>\n",
       "      <td>123.360001</td>\n",
       "      <td>117.053070</td>\n",
       "      <td>0.052479</td>\n",
       "      <td>98.900002</td>\n",
       "      <td>90.699997</td>\n",
       "      <td>0.086552</td>\n",
       "      <td>53.459999</td>\n",
       "      <td>51.990002</td>\n",
       "      <td>0.027882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01</th>\n",
       "      <td>211.009995</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>0.041314</td>\n",
       "      <td>115.770271</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>0.063269</td>\n",
       "      <td>334.779999</td>\n",
       "      <td>288.304291</td>\n",
       "      <td>0.149457</td>\n",
       "      <td>510.799988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037192</td>\n",
       "      <td>140.110001</td>\n",
       "      <td>123.360001</td>\n",
       "      <td>0.127321</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>98.900002</td>\n",
       "      <td>0.185014</td>\n",
       "      <td>50.230000</td>\n",
       "      <td>53.459999</td>\n",
       "      <td>-0.062321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MSFT adj_close  MSFT prev_close  MSFT log_returns  AAPL adj_close  \\\n",
       "Date                                                                            \n",
       "2020-09-01      210.330002              NaN               NaN      115.610542   \n",
       "2020-10-01      202.470001       210.330002         -0.038086      108.672516   \n",
       "2020-11-01      211.009995       202.470001          0.041314      115.770271   \n",
       "\n",
       "            AAPL prev_close  AAPL log_returns  MA adj_close  MA prev_close  \\\n",
       "Date                                                                         \n",
       "2020-09-01              NaN               NaN    337.776672            NaN   \n",
       "2020-10-01       115.610542         -0.061888    288.304291     337.776672   \n",
       "2020-11-01       108.672516          0.063269    334.779999     288.304291   \n",
       "\n",
       "            MA log_returns  NVDA adj_close  ...  NXPI log_returns  \\\n",
       "Date                                        ...                     \n",
       "2020-09-01             NaN      541.058105  ...               NaN   \n",
       "2020-10-01       -0.158368      501.359985  ...          0.082381   \n",
       "2020-11-01        0.149457      510.799988  ...          0.037192   \n",
       "\n",
       "            QCOM adj_close  QCOM prev_close  QCOM log_returns  AAXN adj_close  \\\n",
       "Date                                                                            \n",
       "2020-09-01      117.053070              NaN               NaN       90.699997   \n",
       "2020-10-01      123.360001       117.053070          0.052479       98.900002   \n",
       "2020-11-01      140.110001       123.360001          0.127321      119.000000   \n",
       "\n",
       "            AAXN prev_close  AAXN log_returns  LPSN adj_close  \\\n",
       "Date                                                            \n",
       "2020-09-01              NaN               NaN       51.990002   \n",
       "2020-10-01        90.699997          0.086552       53.459999   \n",
       "2020-11-01        98.900002          0.185014       50.230000   \n",
       "\n",
       "            LPSN prev_close  LPSN log_returns  \n",
       "Date                                           \n",
       "2020-09-01              NaN               NaN  \n",
       "2020-10-01        51.990002          0.027882  \n",
       "2020-11-01        53.459999         -0.062321  \n",
       "\n",
       "[3 rows x 87 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_best_sept = get_data_for_multiple_stocks_monthly(tickers_best_sept,\n",
    "                                          start_date = \"2020-09-01\", end_date = \"2020-11-08\")\n",
    "returns_df_best_sept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns_df_best_sept.dropna(inplace = True)\n",
    "returns_df_best_sept.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8467640.0, 8101441.0, 1364924.0, 631939.0, 1103388.0, 1194400.0, 1372462.0, 5009396.0, 4295000.0, 7447106.0, 4457639.0, 12843921.0, 529000.0, 587300.0, 3478133.0, 586960.0, 2476900.0, 231439.0, 1020500.0, 1053300.0, 1775259.0, 4718700.0, 1235700.0, 1088900.0, 1295458.0, 776850.0, 817555.0, 1044000.0, 1742878.0]\n"
     ]
    }
   ],
   "source": [
    "array_price=[]\n",
    "for i in range(len(tickers_best_sept)):\n",
    "    x=returns_df_best_sept.loc[returns_df_best_sept['Date']=='2020-10-01'][tickers_best_sept[i]+' prev_close'].values\n",
    "    array_price.append(x)\n",
    "shares=[]\n",
    "for i in range(len(array_price)):\n",
    "    shares.append(np.round(array_of_values_best_sept[i]/array_price[i],0)[0])\n",
    "\n",
    "print(shares)\n",
    "#values = total=sum of adj close price*num of shares  for all stocks\n",
    "\n",
    "\n",
    "total=0\n",
    "for y in range(len(shares)):\n",
    "    total+=(returns_df_best_sept[tickers_best_sept[y]+\" prev_close\"]*shares[y])\n",
    "    \n",
    "for y in range(len(shares)):\n",
    "    returns_df_best_sept[\"value\"]=total\n",
    "    \n",
    "#weigts is the weights of stocks in portfolio for each day\n",
    "\n",
    "for x in range(len(shares)):\n",
    "    returns_df_best_sept[tickers_best_sept[x]+\"_weight\"]=(returns_df_best_sept[tickers_best_sept[x]+\" prev_close\"]*shares[x])/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MA adj_close</th>\n",
       "      <th>MA prev_close</th>\n",
       "      <th>MA log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>ORCL_weight</th>\n",
       "      <th>SVMK_weight</th>\n",
       "      <th>AMD_weight</th>\n",
       "      <th>EXPE_weight</th>\n",
       "      <th>RUN_weight</th>\n",
       "      <th>NXPI_weight</th>\n",
       "      <th>QCOM_weight</th>\n",
       "      <th>AAXN_weight</th>\n",
       "      <th>LPSN_weight</th>\n",
       "      <th>portfolio return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337.776672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>210.330002</td>\n",
       "      <td>-0.038086</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.610542</td>\n",
       "      <td>-0.061888</td>\n",
       "      <td>288.304291</td>\n",
       "      <td>337.776672</td>\n",
       "      <td>-0.158368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015273</td>\n",
       "      <td>0.015096</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.014446</td>\n",
       "      <td>0.014446</td>\n",
       "      <td>0.013987</td>\n",
       "      <td>0.013847</td>\n",
       "      <td>0.013701</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>-0.046427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-01</td>\n",
       "      <td>211.009995</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>0.041314</td>\n",
       "      <td>115.770271</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>0.063269</td>\n",
       "      <td>334.779999</td>\n",
       "      <td>288.304291</td>\n",
       "      <td>0.149457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015037</td>\n",
       "      <td>0.014969</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>0.015539</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>0.015910</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.015650</td>\n",
       "      <td>0.014122</td>\n",
       "      <td>0.069467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  MSFT adj_close  MSFT prev_close  MSFT log_returns  \\\n",
       "0 2020-09-01      210.330002              NaN               NaN   \n",
       "1 2020-10-01      202.470001       210.330002         -0.038086   \n",
       "2 2020-11-01      211.009995       202.470001          0.041314   \n",
       "\n",
       "   AAPL adj_close  AAPL prev_close  AAPL log_returns  MA adj_close  \\\n",
       "0      115.610542              NaN               NaN    337.776672   \n",
       "1      108.672516       115.610542         -0.061888    288.304291   \n",
       "2      115.770271       108.672516          0.063269    334.779999   \n",
       "\n",
       "   MA prev_close  MA log_returns  ...  ORCL_weight  SVMK_weight  AMD_weight  \\\n",
       "0            NaN             NaN  ...          NaN          NaN         NaN   \n",
       "1     337.776672       -0.158368  ...     0.015273     0.015096    0.014659   \n",
       "2     288.304291        0.149457  ...     0.015037     0.014969    0.014101   \n",
       "\n",
       "   EXPE_weight  RUN_weight  NXPI_weight  QCOM_weight  AAXN_weight  \\\n",
       "0          NaN         NaN          NaN          NaN          NaN   \n",
       "1     0.014446    0.014446     0.013987     0.013847     0.013701   \n",
       "2     0.015539    0.010214     0.015910     0.015286     0.015650   \n",
       "\n",
       "   LPSN_weight  portfolio return  \n",
       "0          NaN               NaN  \n",
       "1     0.013111         -0.046427  \n",
       "2     0.014122          0.069467  \n",
       "\n",
       "[3 rows x 119 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_best_sept[\"portfolio return\"]=0\n",
    "for i in range(len(tickers_best_sept)):\n",
    "    returns_df_best_sept[\"portfolio return\"]+=returns_df_best_sept[tickers_best_sept[i]+\"_weight\"]*(np.exp(returns_df_best_sept[tickers_best_sept[i]+\" log_returns\"]) - 1)\n",
    "\n",
    "returns_df_best_sept[\"portfolio return\"]=np.log(1+returns_df_best_sept[\"portfolio return\"])\n",
    "\n",
    "returns_df_best_sept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worst portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df_worst_qn3 = get_data_for_multiple_stocks_monthly(tickers_worst,\n",
    "                                          start_date = \"2020-07-01\", end_date = \"2020-10-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_df_worst_qn3.dropna(inplace = True)\n",
    "returns_df_worst_qn3.reset_index(inplace=True)\n",
    "returns_df_worst_qn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ERIC adj_close</th>\n",
       "      <th>ERIC prev_close</th>\n",
       "      <th>ERIC log_returns</th>\n",
       "      <th>NOK adj_close</th>\n",
       "      <th>NOK prev_close</th>\n",
       "      <th>NOK log_returns</th>\n",
       "      <th>CSCO adj_close</th>\n",
       "      <th>CSCO prev_close</th>\n",
       "      <th>CSCO log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>HLIT_weight</th>\n",
       "      <th>ADTN_weight</th>\n",
       "      <th>EXTR_weight</th>\n",
       "      <th>INSG_weight</th>\n",
       "      <th>RPD_weight</th>\n",
       "      <th>SW.TO_weight</th>\n",
       "      <th>CVLT_weight</th>\n",
       "      <th>GLW_weight</th>\n",
       "      <th>RBBN_weight</th>\n",
       "      <th>portfolio return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>11.559068</td>\n",
       "      <td>11.459848</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>4.90</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>41.834137</td>\n",
       "      <td>46.304768</td>\n",
       "      <td>-0.101532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.011153</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.020852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>10.805000</td>\n",
       "      <td>11.559068</td>\n",
       "      <td>-0.067461</td>\n",
       "      <td>3.91</td>\n",
       "      <td>4.90</td>\n",
       "      <td>-0.225698</td>\n",
       "      <td>39.029999</td>\n",
       "      <td>41.834137</td>\n",
       "      <td>-0.069382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.006559</td>\n",
       "      <td>0.006521</td>\n",
       "      <td>0.009698</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.096210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>11.122502</td>\n",
       "      <td>10.805000</td>\n",
       "      <td>0.028961</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.91</td>\n",
       "      <td>-0.148625</td>\n",
       "      <td>35.571899</td>\n",
       "      <td>39.029999</td>\n",
       "      <td>-0.092775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.006604</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.006425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005697</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  ERIC adj_close  ERIC prev_close  ERIC log_returns  \\\n",
       "0 2020-08-01       11.559068        11.459848          0.008621   \n",
       "1 2020-09-01       10.805000        11.559068         -0.067461   \n",
       "2 2020-10-01       11.122502        10.805000          0.028961   \n",
       "\n",
       "   NOK adj_close  NOK prev_close  NOK log_returns  CSCO adj_close  \\\n",
       "0           4.90            4.78         0.024795       41.834137   \n",
       "1           3.91            4.90        -0.225698       39.029999   \n",
       "2           3.37            3.91        -0.148625       35.571899   \n",
       "\n",
       "   CSCO prev_close  CSCO log_returns  ...  HLIT_weight  ADTN_weight  \\\n",
       "0        46.304768         -0.101532  ...     0.006551     0.007195   \n",
       "1        41.834137         -0.069382  ...     0.007072     0.006559   \n",
       "2        39.029999         -0.092775  ...     0.007364     0.006731   \n",
       "\n",
       "   EXTR_weight  INSG_weight  RPD_weight  SW.TO_weight  CVLT_weight  \\\n",
       "0     0.006649     0.011153    0.005559           0.0     0.005475   \n",
       "1     0.006521     0.009698    0.006153           0.0     0.005483   \n",
       "2     0.006604     0.009599    0.006425           0.0     0.005697   \n",
       "\n",
       "   GLW_weight  RBBN_weight  portfolio return  \n",
       "0    0.003063          0.0         -0.020852  \n",
       "1    0.003275          0.0         -0.096210  \n",
       "2    0.003624          0.0         -0.000708  \n",
       "\n",
       "[3 rows x 123 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shares = [361221, 114105, 64490, 6323, 15611, 35750, 5253, 7575, 21379, 41553, 8007, 2212, 29260, 6749, 15481, 15542,\n",
    "         38703, 5611, 0, 0, 4258, 20454, 10168, 25461, 14415, 1626, 0, 2164, 1733, 0]\n",
    "\n",
    "# values = sum of adj close price*num of shares for all stocks\n",
    "\n",
    "total=0\n",
    "for y in range(len(shares)):\n",
    "    total+=(returns_df_worst_qn3[tickers_worst[y]+\" prev_close\"]*shares[y])\n",
    "    \n",
    "for y in range(len(shares)):\n",
    "    returns_df_worst_qn3[\"value\"]=total\n",
    "\n",
    "for x in range(len(shares)):\n",
    "    returns_df_worst_qn3[tickers_worst[x]+\"_weight\"]=(returns_df_worst_qn3[tickers_worst[x]+\" prev_close\"]*shares[x])/total\n",
    "    \n",
    "#returns monthly returns from july 2020 to oct 2020\n",
    "returns_df_worst_qn3[\"portfolio return\"]=0\n",
    "for i in range(len(tickers_worst)):\n",
    "    returns_df_worst_qn3[\"portfolio return\"]+=returns_df_worst_qn3[tickers_worst[i]+\"_weight\"]*(np.exp(returns_df_worst_qn3[tickers_worst[i]+\" log_returns\"]) - 1)\n",
    "\n",
    "returns_df_worst_qn3[\"portfolio return\"]=np.log(1+returns_df_worst_qn3[\"portfolio return\"])\n",
    "returns_df_worst_qn3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_multiple_stocks_price(tickers, start_date, end_date):\n",
    "    \n",
    "    stocks = dict()\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        \n",
    "        # get the data for the specific ticker\n",
    "        s = DataReader(ticker, 'yahoo', start_date, end_date)\n",
    "        \n",
    "        s['Adj Close'] = s['Adj Close']\n",
    "        # s['log_return'] = np.log(s['Adj Close']/s['Prev Close'])\n",
    "        # s['perc_return'] = (s['Adj Close']/s['Prev Close'])\n",
    "        \n",
    "        # add to the dictionary\n",
    "        stocks[ticker] = s[['Adj Close']]\n",
    "    \n",
    "    # return the dictionary\n",
    "    return stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL':             Adj Close\n",
       " Date                 \n",
       " 2019-12-30  71.669212\n",
       " 2019-12-31  72.192863,\n",
       " 'MSFT':              Adj Close\n",
       " Date                  \n",
       " 2019-12-30  156.346298\n",
       " 2019-12-31  156.455429,\n",
       " 'MA':              Adj Close\n",
       " Date                  \n",
       " 2019-12-30  296.123474\n",
       " 2019-12-31  296.988831,\n",
       " 'V':              Adj Close\n",
       " Date                  \n",
       " 2019-12-30  186.962204\n",
       " 2019-12-31  187.031860,\n",
       " 'FIS':              Adj Close\n",
       " Date                  \n",
       " 2019-12-30  137.567566\n",
       " 2019-12-31  138.053894,\n",
       " 'LRCX':              Adj Close\n",
       " Date                  \n",
       " 2019-12-30  288.528290\n",
       " 2019-12-31  288.390167,\n",
       " 'FB':              Adj Close\n",
       " Date                  \n",
       " 2019-12-30  204.410004\n",
       " 2019-12-31  205.250000,\n",
       " 'QCOM':             Adj Close\n",
       " Date                 \n",
       " 2019-12-30  86.594490\n",
       " 2019-12-31  86.398636,\n",
       " 'INTU':              Adj Close\n",
       " Date                  \n",
       " 2019-12-30  260.856781\n",
       " 2019-12-31  259.953674,\n",
       " 'AMD':             Adj Close\n",
       " Date                 \n",
       " 2019-12-30  45.520000\n",
       " 2019-12-31  45.860001,\n",
       " 'MELI':              Adj Close\n",
       " Date                  \n",
       " 2019-12-30  583.849976\n",
       " 2019-12-31  571.940002,\n",
       " 'G':             Adj Close\n",
       " Date                 \n",
       " 2019-12-30  41.797405\n",
       " 2019-12-31  41.847019,\n",
       " 'MDB':              Adj Close\n",
       " Date                  \n",
       " 2019-12-30  128.929993\n",
       " 2019-12-31  131.610001,\n",
       " 'NXPI':              Adj Close\n",
       " Date                  \n",
       " 2019-12-30  126.184578\n",
       " 2019-12-31  125.897690}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_optimal = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]\n",
    "price_optimal_df = get_data_for_multiple_stocks_price(tickers_optimal, \"2019-12-30\", \"2019-12-31\")\n",
    "price_optimal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tickers_optimal)):\n",
    "    price_optimal_df[tickers_optimal[i]].reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.19286346435547"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for one stock\n",
    "price_optimal_df\n",
    "price_optimal_df['AAPL']['Adj Close'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28421601.83898336,\n",
       " 10382279.110295517,\n",
       " 738629.8992512122,\n",
       " 995713.9903861529,\n",
       " 1299029.7611176567,\n",
       " 573344.5962618502,\n",
       " 790115.6199756395,\n",
       " 1681719.121448633,\n",
       " 433826.5165766981,\n",
       " 2358525.197568043,\n",
       " 174330.4867195658,\n",
       " 2122457.267145824,\n",
       " 565520.0338487498,\n",
       " 555920.566139338]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dollarValueOfStock = [2051836821, 1624363933, 329525040, 291785537, 238343597, 219364830, 212343810, 186230240, 185088374, 179336117, 165346944, 162171231, 161982940, 145298238, 121981574, 119200951,116143756, 112774797, 108946944,108161967, 105879493, 99706579, 98161895, 88818510, 83373164, 76143081, 74428092, 69989115, 66668202, 61789443]\n",
    "arrOfStocks = [\"AAPL\", \"MSFT\", \"ADBE\", \"CRM\", \"NVDA\", \"MA\", \"PYPL\", \"V\", \"MU\", \"FIS\", \"LRCX\", \"FB\", \"AMAT\", \"QCOM\", \"TWLO\", \"WDAY\", \"AMZN\", \"INTU\", \"ADSK\", \"AMD\",\"HUBS\", \"MELI\", \"ESTC\", \"G\", \"GDDY\", \"FLEX\", \"MDB\", \"NXPI\", \"FISV\", \"MRVL\"]\n",
    "stock_adj_close = [106.06875610351562,204.51560974121094, 444.32000732421875,194.85000610351562,424.4630126953125,308.171142578125,196.07000732421875,\n",
    " 190.1125946044922,50.060001373291016,145.9651641845703,375.7033996582031,253.6699981689453,64.11695861816406,105.04737091064453,\n",
    " 277.4200134277344,180.9199981689453,3164.679931640625,305.83026123046875,236.42999267578125,77.43000030517578,234.61000061035156,1124.6199951171875,\n",
    " 96.19000244140625,39.71950149536133,70.27999877929688,11.489999771118164,229.0800018310547,117.17669677734375,\n",
    " 99.79000091552734,36.41865921020508]\n",
    "tickers_optimal = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]\n",
    "\n",
    "\n",
    "shares = []\n",
    "for j in tickers_optimal:\n",
    "    for i in range(len(dollarValueOfStock)):\n",
    "        if j == arrOfStocks[i]:\n",
    "            share = dollarValueOfStock[i]/price_optimal_df[j]['Adj Close'][1]\n",
    "            shares.append(share)\n",
    "shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5287827414.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers_optimal = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]\n",
    "value = 0\n",
    "for i in range(len(tickers_optimal)):\n",
    "    value += shares[i]*price_optimal_df[tickers_optimal[i]]['Adj Close'][1]\n",
    "portfolio_value_dec19 = value\n",
    "portfolio_value_dec19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_multiple_stocks2(tickers, start_date, end_date):\n",
    "    \n",
    "    stocks = dict()\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        \n",
    "        # get the data for the specific ticker\n",
    "        s = DataReader(ticker, 'yahoo', start_date, end_date)\n",
    "      \n",
    "        s['Prev Close'] = s['Adj Close'].shift(1)\n",
    "        s['log_return'] = np.log(s['Adj Close']/s['Prev Close'])\n",
    "        s['perc_return'] = (s['Adj Close']/s['Prev Close'])\n",
    "        \n",
    "        # add to the dictionary\n",
    "        stocks[ticker] = s\n",
    "    \n",
    "    # return the dictionary\n",
    "    return stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_opt_string = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]\n",
    "stocks = get_data_for_multiple_stocks2(tickers_opt_string, start_date = \"2019-01-01\", end_date = \"2020-11-01\")\n",
    "\n",
    "AAPL = stocks['AAPL'].reset_index()\n",
    "MSFT = stocks['MSFT'].reset_index()\n",
    "MA = stocks['MA'].reset_index()\n",
    "V = stocks['V'].reset_index()\n",
    "FIS = stocks['FIS'].reset_index()\n",
    "LRCX = stocks['LRCX'].reset_index()\n",
    "FB = stocks['FB'].reset_index()\n",
    "QCOM = stocks['QCOM'].reset_index()\n",
    "INTU = stocks['INTU'].reset_index()\n",
    "AMD = stocks['AMD'].reset_index()\n",
    "MELI = stocks['MELI'].reset_index()\n",
    "G = stocks['G'].reset_index()\n",
    "MDB = stocks['MDB'].reset_index()\n",
    "NXPI = stocks['NXPI'].reset_index()\n",
    "\n",
    "# Transform Date from integer to date type\n",
    "AAPL['Date'] = AAPL['Date'].apply(str)\n",
    "AAPL['Date'] = pd.to_datetime(AAPL['Date'], infer_datetime_format=True)\n",
    "\n",
    "MSFT['Date'] = MSFT['Date'].apply(str)\n",
    "MSFT['Date'] = pd.to_datetime(MSFT['Date'], infer_datetime_format=True)\n",
    "\n",
    "MA['Date'] = MA['Date'].apply(str)\n",
    "MA['Date'] = pd.to_datetime(MA['Date'], infer_datetime_format=True)\n",
    "\n",
    "V['Date'] = V['Date'].apply(str)\n",
    "V['Date'] = pd.to_datetime(V['Date'], infer_datetime_format=True)\n",
    "\n",
    "FIS['Date'] = FIS['Date'].apply(str)\n",
    "FIS['Date'] = pd.to_datetime(FIS['Date'], infer_datetime_format=True)\n",
    "\n",
    "LRCX['Date'] = LRCX['Date'].apply(str)\n",
    "LRCX['Date'] = pd.to_datetime(LRCX['Date'], infer_datetime_format=True)\n",
    "\n",
    "FB['Date'] = FB['Date'].apply(str)\n",
    "FB['Date'] = pd.to_datetime(FB['Date'], infer_datetime_format=True)\n",
    "\n",
    "QCOM['Date'] = QCOM['Date'].apply(str)\n",
    "QCOM['Date'] = pd.to_datetime(QCOM['Date'], infer_datetime_format=True)\n",
    "\n",
    "INTU['Date'] = INTU['Date'].apply(str)\n",
    "INTU['Date'] = pd.to_datetime(INTU['Date'], infer_datetime_format=True)\n",
    "\n",
    "AMD['Date'] = AMD['Date'].apply(str)\n",
    "AMD['Date'] = pd.to_datetime(AMD['Date'], infer_datetime_format=True)\n",
    "\n",
    "MELI['Date'] = MELI['Date'].apply(str)\n",
    "MELI['Date'] = pd.to_datetime(MELI['Date'], infer_datetime_format=True)\n",
    "\n",
    "G['Date'] = G['Date'].apply(str)\n",
    "G['Date'] = pd.to_datetime(G['Date'], infer_datetime_format=True)\n",
    "\n",
    "MDB['Date'] = MDB['Date'].apply(str)\n",
    "MDB['Date'] = pd.to_datetime(MDB['Date'], infer_datetime_format=True)\n",
    "\n",
    "NXPI['Date'] = NXPI['Date'].apply(str)\n",
    "NXPI['Date'] = pd.to_datetime(NXPI['Date'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming adj_close column\n",
    "AAPL.rename(columns={'Adj Close':'AAPL_Adj Close'}, inplace=True)\n",
    "MSFT.rename(columns={'Adj Close':'MSFT_Adj Close'}, inplace=True)\n",
    "MA.rename(columns={'Adj Close':'MA_Adj Close'}, inplace=True)\n",
    "V.rename(columns={'Adj Close':'V_Adj Close'}, inplace=True)\n",
    "FIS.rename(columns={'Adj Close':'FIS_Adj Close'}, inplace=True)\n",
    "LRCX.rename(columns={'Adj Close':'LRCX_Adj Close'}, inplace=True)\n",
    "FB.rename(columns={'Adj Close':'FB_Adj Close'}, inplace=True)\n",
    "QCOM.rename(columns={'Adj Close':'QCOM_Adj Close'}, inplace=True)\n",
    "INTU.rename(columns={'Adj Close':'INTU_Adj Close'}, inplace=True)\n",
    "AMD.rename(columns={'Adj Close':'AMD_Adj Close'}, inplace=True)\n",
    "MELI.rename(columns={'Adj Close':'MELI_Adj Close'}, inplace=True)\n",
    "G.rename(columns={'Adj Close':'G_Adj Close'}, inplace=True)\n",
    "MDB.rename(columns={'Adj Close':'MDB_Adj Close'}, inplace=True)\n",
    "NXPI.rename(columns={'Adj Close':'NXPI_Adj Close'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming log_return column\n",
    "AAPL.rename(columns={'log_return':'AAPL_log_return'}, inplace=True)\n",
    "MSFT.rename(columns={'log_return':'MSFT_log_return'}, inplace=True)\n",
    "MA.rename(columns={'log_return':'MA_log_return'}, inplace=True)\n",
    "V.rename(columns={'log_return':'V_log_return'}, inplace=True)\n",
    "FIS.rename(columns={'log_return':'FIS_log_return'}, inplace=True)\n",
    "LRCX.rename(columns={'log_return':'LRCX_log_return'}, inplace=True)\n",
    "FB.rename(columns={'log_return':'FB_log_return'}, inplace=True)\n",
    "QCOM.rename(columns={'log_return':'QCOM_log_return'}, inplace=True)\n",
    "INTU.rename(columns={'log_return':'INTU_log_return'}, inplace=True)\n",
    "AMD.rename(columns={'log_return':'AMD_log_return'}, inplace=True)\n",
    "MELI.rename(columns={'log_return':'MELI_log_return'}, inplace=True)\n",
    "G.rename(columns={'log_return':'G_log_return'}, inplace=True)\n",
    "MDB.rename(columns={'log_return':'MDB_log_return'}, inplace=True)\n",
    "NXPI.rename(columns={'log_return':'NXPI_log_return'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataset for portfolio\n",
    "dfs = [AAPL, MSFT, MA, V, FIS, LRCX, FB, QCOM, INTU, AMD, MELI, G, MDB, NXPI]\n",
    "portfolio_opt = reduce(lambda left,right: pd.merge(left,right,on='Date'), dfs)\n",
    "portfolio_opt = portfolio_opt[['Date', 'AAPL_Adj Close', 'MSFT_Adj Close','MA_Adj Close','V_Adj Close','FIS_Adj Close','LRCX_Adj Close','FB_Adj Close','QCOM_Adj Close','INTU_Adj Close','AMD_Adj Close','MELI_Adj Close','G_Adj Close','MDB_Adj Close','NXPI_Adj Close','AAPL_log_return','MSFT_log_return','MA_log_return','V_log_return','FIS_log_return','LRCX_log_return','FB_log_return','QCOM_log_return','INTU_log_return','AMD_log_return','MELI_log_return','G_log_return','MDB_log_return','NXPI_log_return']]\n",
    "\n",
    "portfolio_opt.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL_Adj Close</th>\n",
       "      <th>MSFT_Adj Close</th>\n",
       "      <th>MA_Adj Close</th>\n",
       "      <th>V_Adj Close</th>\n",
       "      <th>FIS_Adj Close</th>\n",
       "      <th>LRCX_Adj Close</th>\n",
       "      <th>FB_Adj Close</th>\n",
       "      <th>QCOM_Adj Close</th>\n",
       "      <th>INTU_Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th>FIS_log_return</th>\n",
       "      <th>LRCX_log_return</th>\n",
       "      <th>FB_log_return</th>\n",
       "      <th>QCOM_log_return</th>\n",
       "      <th>INTU_log_return</th>\n",
       "      <th>AMD_log_return</th>\n",
       "      <th>MELI_log_return</th>\n",
       "      <th>G_log_return</th>\n",
       "      <th>MDB_log_return</th>\n",
       "      <th>NXPI_log_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>38.249401</td>\n",
       "      <td>98.860214</td>\n",
       "      <td>187.678177</td>\n",
       "      <td>131.462326</td>\n",
       "      <td>99.532082</td>\n",
       "      <td>133.541534</td>\n",
       "      <td>135.679993</td>\n",
       "      <td>54.205219</td>\n",
       "      <td>191.487595</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010982</td>\n",
       "      <td>0.015521</td>\n",
       "      <td>0.034415</td>\n",
       "      <td>0.008573</td>\n",
       "      <td>-0.012164</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>-0.007438</td>\n",
       "      <td>-0.046315</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>34.439476</td>\n",
       "      <td>95.223351</td>\n",
       "      <td>179.211197</td>\n",
       "      <td>126.724884</td>\n",
       "      <td>96.470459</td>\n",
       "      <td>127.101006</td>\n",
       "      <td>131.740005</td>\n",
       "      <td>52.599842</td>\n",
       "      <td>185.628830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031243</td>\n",
       "      <td>-0.049430</td>\n",
       "      <td>-0.029469</td>\n",
       "      <td>-0.030064</td>\n",
       "      <td>-0.031074</td>\n",
       "      <td>-0.099301</td>\n",
       "      <td>-0.004776</td>\n",
       "      <td>-0.013529</td>\n",
       "      <td>-0.052116</td>\n",
       "      <td>-0.041638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>35.909672</td>\n",
       "      <td>99.652115</td>\n",
       "      <td>187.697968</td>\n",
       "      <td>132.184341</td>\n",
       "      <td>99.875542</td>\n",
       "      <td>133.309784</td>\n",
       "      <td>137.949997</td>\n",
       "      <td>53.449738</td>\n",
       "      <td>192.994125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034688</td>\n",
       "      <td>0.047694</td>\n",
       "      <td>0.046061</td>\n",
       "      <td>0.016029</td>\n",
       "      <td>0.038911</td>\n",
       "      <td>0.108289</td>\n",
       "      <td>0.061269</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.074136</td>\n",
       "      <td>0.047221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>35.829746</td>\n",
       "      <td>99.779205</td>\n",
       "      <td>189.142090</td>\n",
       "      <td>134.567917</td>\n",
       "      <td>100.503555</td>\n",
       "      <td>134.497452</td>\n",
       "      <td>138.050003</td>\n",
       "      <td>53.298649</td>\n",
       "      <td>195.938248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>-0.002831</td>\n",
       "      <td>0.015140</td>\n",
       "      <td>0.079395</td>\n",
       "      <td>0.042256</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.047432</td>\n",
       "      <td>0.007395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>36.512772</td>\n",
       "      <td>100.502670</td>\n",
       "      <td>190.519348</td>\n",
       "      <td>135.299805</td>\n",
       "      <td>101.259148</td>\n",
       "      <td>132.218643</td>\n",
       "      <td>142.529999</td>\n",
       "      <td>52.835922</td>\n",
       "      <td>200.635086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>-0.017088</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>-0.008720</td>\n",
       "      <td>0.023688</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>-0.001369</td>\n",
       "      <td>0.017057</td>\n",
       "      <td>0.048846</td>\n",
       "      <td>0.005641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>318.059998</td>\n",
       "      <td>193.070007</td>\n",
       "      <td>139.419998</td>\n",
       "      <td>347.630005</td>\n",
       "      <td>277.109985</td>\n",
       "      <td>126.199997</td>\n",
       "      <td>328.089996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035096</td>\n",
       "      <td>-0.017932</td>\n",
       "      <td>-0.027338</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.019110</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>-0.023690</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>-0.032373</td>\n",
       "      <td>-0.016834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>317.109985</td>\n",
       "      <td>190.059998</td>\n",
       "      <td>137.860001</td>\n",
       "      <td>343.829987</td>\n",
       "      <td>283.290009</td>\n",
       "      <td>125.910004</td>\n",
       "      <td>330.269989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011252</td>\n",
       "      <td>-0.010991</td>\n",
       "      <td>0.022057</td>\n",
       "      <td>-0.002301</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>-0.041593</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>-0.007057</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>-0.012383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>291.380005</td>\n",
       "      <td>180.869995</td>\n",
       "      <td>132.509995</td>\n",
       "      <td>338.899994</td>\n",
       "      <td>267.670013</td>\n",
       "      <td>121.580002</td>\n",
       "      <td>318.510010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039581</td>\n",
       "      <td>-0.014442</td>\n",
       "      <td>-0.056716</td>\n",
       "      <td>-0.034995</td>\n",
       "      <td>-0.036257</td>\n",
       "      <td>-0.031945</td>\n",
       "      <td>-0.006948</td>\n",
       "      <td>-0.037228</td>\n",
       "      <td>-0.016404</td>\n",
       "      <td>-0.026313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>293.179993</td>\n",
       "      <td>184.869995</td>\n",
       "      <td>125.019997</td>\n",
       "      <td>353.260010</td>\n",
       "      <td>280.829987</td>\n",
       "      <td>126.440002</td>\n",
       "      <td>325.609985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058184</td>\n",
       "      <td>0.041499</td>\n",
       "      <td>0.047995</td>\n",
       "      <td>0.039195</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.021278</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>-0.018288</td>\n",
       "      <td>0.048140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>288.640015</td>\n",
       "      <td>181.710007</td>\n",
       "      <td>124.589996</td>\n",
       "      <td>342.079987</td>\n",
       "      <td>263.109985</td>\n",
       "      <td>123.360001</td>\n",
       "      <td>314.679993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003445</td>\n",
       "      <td>-0.032160</td>\n",
       "      <td>-0.065177</td>\n",
       "      <td>-0.024661</td>\n",
       "      <td>-0.034144</td>\n",
       "      <td>-0.035618</td>\n",
       "      <td>-0.069156</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>-0.031112</td>\n",
       "      <td>-0.007741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AAPL_Adj Close  MSFT_Adj Close  MA_Adj Close  V_Adj Close  \\\n",
       "1   2019-01-02       38.249401       98.860214    187.678177   131.462326   \n",
       "2   2019-01-03       34.439476       95.223351    179.211197   126.724884   \n",
       "3   2019-01-04       35.909672       99.652115    187.697968   132.184341   \n",
       "4   2019-01-07       35.829746       99.779205    189.142090   134.567917   \n",
       "5   2019-01-08       36.512772      100.502670    190.519348   135.299805   \n",
       "..         ...             ...             ...           ...          ...   \n",
       "459 2020-10-26      114.851852      210.080002    318.059998   193.070007   \n",
       "460 2020-10-27      116.399178      213.250000    317.109985   190.059998   \n",
       "461 2020-10-28      111.008476      202.679993    291.380005   180.869995   \n",
       "462 2020-10-29      115.121384      204.720001    293.179993   184.869995   \n",
       "463 2020-10-30      108.672516      202.470001    288.640015   181.710007   \n",
       "\n",
       "     FIS_Adj Close  LRCX_Adj Close  FB_Adj Close  QCOM_Adj Close  \\\n",
       "1        99.532082      133.541534    135.679993       54.205219   \n",
       "2        96.470459      127.101006    131.740005       52.599842   \n",
       "3        99.875542      133.309784    137.949997       53.449738   \n",
       "4       100.503555      134.497452    138.050003       53.298649   \n",
       "5       101.259148      132.218643    142.529999       52.835922   \n",
       "..             ...             ...           ...             ...   \n",
       "459     139.419998      347.630005    277.109985      126.199997   \n",
       "460     137.860001      343.829987    283.290009      125.910004   \n",
       "461     132.509995      338.899994    267.670013      121.580002   \n",
       "462     125.019997      353.260010    280.829987      126.440002   \n",
       "463     124.589996      342.079987    263.109985      123.360001   \n",
       "\n",
       "     INTU_Adj Close  ...  FIS_log_return  LRCX_log_return  FB_log_return  \\\n",
       "1        191.487595  ...       -0.010982         0.015521       0.034415   \n",
       "2        185.628830  ...       -0.031243        -0.049430      -0.029469   \n",
       "3        192.994125  ...        0.034688         0.047694       0.046061   \n",
       "4        195.938248  ...        0.006268         0.008870       0.000725   \n",
       "5        200.635086  ...        0.007490        -0.017088       0.031937   \n",
       "..              ...  ...             ...              ...            ...   \n",
       "459      328.089996  ...       -0.035096        -0.017932      -0.027338   \n",
       "460      330.269989  ...       -0.011252        -0.010991       0.022057   \n",
       "461      318.510010  ...       -0.039581        -0.014442      -0.056716   \n",
       "462      325.609985  ...       -0.058184         0.041499       0.047995   \n",
       "463      314.679993  ...       -0.003445        -0.032160      -0.065177   \n",
       "\n",
       "     QCOM_log_return  INTU_log_return  AMD_log_return  MELI_log_return  \\\n",
       "1           0.008573        -0.012164        0.019845         0.017467   \n",
       "2          -0.030064        -0.031074       -0.099301        -0.004776   \n",
       "3           0.016029         0.038911        0.108289         0.061269   \n",
       "4          -0.002831         0.015140        0.079395         0.042256   \n",
       "5          -0.008720         0.023688        0.008713        -0.001369   \n",
       "..               ...              ...             ...              ...   \n",
       "459        -0.021014        -0.019110        0.003289        -0.023690   \n",
       "460        -0.002301         0.006623       -0.041593         0.000803   \n",
       "461        -0.034995        -0.036257       -0.031945        -0.006948   \n",
       "462         0.039195         0.022046        0.020982         0.021278   \n",
       "463        -0.024661        -0.034144       -0.035618        -0.069156   \n",
       "\n",
       "     G_log_return  MDB_log_return  NXPI_log_return  \n",
       "1       -0.007438       -0.046315         0.023600  \n",
       "2       -0.013529       -0.052116        -0.041638  \n",
       "3        0.025403        0.074136         0.047221  \n",
       "4        0.007716        0.047432         0.007395  \n",
       "5        0.017057        0.048846         0.005641  \n",
       "..            ...             ...              ...  \n",
       "459     -0.039978       -0.032373        -0.016834  \n",
       "460     -0.007057        0.016154        -0.012383  \n",
       "461     -0.037228       -0.016404        -0.026313  \n",
       "462      0.006448       -0.018288         0.048140  \n",
       "463      0.004082       -0.031112        -0.007741  \n",
       "\n",
       "[463 rows x 29 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL_Adj Close</th>\n",
       "      <th>MSFT_Adj Close</th>\n",
       "      <th>MA_Adj Close</th>\n",
       "      <th>V_Adj Close</th>\n",
       "      <th>FIS_Adj Close</th>\n",
       "      <th>LRCX_Adj Close</th>\n",
       "      <th>FB_Adj Close</th>\n",
       "      <th>QCOM_Adj Close</th>\n",
       "      <th>INTU_Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th>FB_log_return</th>\n",
       "      <th>QCOM_log_return</th>\n",
       "      <th>INTU_log_return</th>\n",
       "      <th>AMD_log_return</th>\n",
       "      <th>MELI_log_return</th>\n",
       "      <th>G_log_return</th>\n",
       "      <th>MDB_log_return</th>\n",
       "      <th>NXPI_log_return</th>\n",
       "      <th>Portfolio_Value</th>\n",
       "      <th>log_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>38.249401</td>\n",
       "      <td>98.860214</td>\n",
       "      <td>187.678177</td>\n",
       "      <td>131.462326</td>\n",
       "      <td>99.532082</td>\n",
       "      <td>133.541534</td>\n",
       "      <td>135.679993</td>\n",
       "      <td>54.205219</td>\n",
       "      <td>191.487595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034415</td>\n",
       "      <td>0.008573</td>\n",
       "      <td>-0.012164</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>0.017467</td>\n",
       "      <td>-0.007438</td>\n",
       "      <td>-0.046315</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>3.108594e+09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>34.439476</td>\n",
       "      <td>95.223351</td>\n",
       "      <td>179.211197</td>\n",
       "      <td>126.724884</td>\n",
       "      <td>96.470459</td>\n",
       "      <td>127.101006</td>\n",
       "      <td>131.740005</td>\n",
       "      <td>52.599842</td>\n",
       "      <td>185.628830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029469</td>\n",
       "      <td>-0.030064</td>\n",
       "      <td>-0.031074</td>\n",
       "      <td>-0.099301</td>\n",
       "      <td>-0.004776</td>\n",
       "      <td>-0.013529</td>\n",
       "      <td>-0.052116</td>\n",
       "      <td>-0.041638</td>\n",
       "      <td>2.926400e+09</td>\n",
       "      <td>-0.060398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>35.909672</td>\n",
       "      <td>99.652115</td>\n",
       "      <td>187.697968</td>\n",
       "      <td>132.184341</td>\n",
       "      <td>99.875542</td>\n",
       "      <td>133.309784</td>\n",
       "      <td>137.949997</td>\n",
       "      <td>53.449738</td>\n",
       "      <td>192.994125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046061</td>\n",
       "      <td>0.016029</td>\n",
       "      <td>0.038911</td>\n",
       "      <td>0.108289</td>\n",
       "      <td>0.061269</td>\n",
       "      <td>0.025403</td>\n",
       "      <td>0.074136</td>\n",
       "      <td>0.047221</td>\n",
       "      <td>3.057864e+09</td>\n",
       "      <td>0.043944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>35.829746</td>\n",
       "      <td>99.779205</td>\n",
       "      <td>189.142090</td>\n",
       "      <td>134.567917</td>\n",
       "      <td>100.503555</td>\n",
       "      <td>134.497452</td>\n",
       "      <td>138.050003</td>\n",
       "      <td>53.298649</td>\n",
       "      <td>195.938248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>-0.002831</td>\n",
       "      <td>0.015140</td>\n",
       "      <td>0.079395</td>\n",
       "      <td>0.042256</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>0.047432</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>3.072014e+09</td>\n",
       "      <td>0.004617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>36.512772</td>\n",
       "      <td>100.502670</td>\n",
       "      <td>190.519348</td>\n",
       "      <td>135.299805</td>\n",
       "      <td>101.259148</td>\n",
       "      <td>132.218643</td>\n",
       "      <td>142.529999</td>\n",
       "      <td>52.835922</td>\n",
       "      <td>200.635086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>-0.008720</td>\n",
       "      <td>0.023688</td>\n",
       "      <td>0.008713</td>\n",
       "      <td>-0.001369</td>\n",
       "      <td>0.017057</td>\n",
       "      <td>0.048846</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>3.109145e+09</td>\n",
       "      <td>0.012014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>318.059998</td>\n",
       "      <td>193.070007</td>\n",
       "      <td>139.419998</td>\n",
       "      <td>347.630005</td>\n",
       "      <td>277.109985</td>\n",
       "      <td>126.199997</td>\n",
       "      <td>328.089996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027338</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.019110</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>-0.023690</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>-0.032373</td>\n",
       "      <td>-0.016834</td>\n",
       "      <td>7.530051e+09</td>\n",
       "      <td>-0.015019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>317.109985</td>\n",
       "      <td>190.059998</td>\n",
       "      <td>137.860001</td>\n",
       "      <td>343.829987</td>\n",
       "      <td>283.290009</td>\n",
       "      <td>125.910004</td>\n",
       "      <td>330.269989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022057</td>\n",
       "      <td>-0.002301</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>-0.041593</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>-0.007057</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>7.597413e+09</td>\n",
       "      <td>0.008906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>291.380005</td>\n",
       "      <td>180.869995</td>\n",
       "      <td>132.509995</td>\n",
       "      <td>338.899994</td>\n",
       "      <td>267.670013</td>\n",
       "      <td>121.580002</td>\n",
       "      <td>318.510010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056716</td>\n",
       "      <td>-0.034995</td>\n",
       "      <td>-0.036257</td>\n",
       "      <td>-0.031945</td>\n",
       "      <td>-0.006948</td>\n",
       "      <td>-0.037228</td>\n",
       "      <td>-0.016404</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>7.257499e+09</td>\n",
       "      <td>-0.045773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>293.179993</td>\n",
       "      <td>184.869995</td>\n",
       "      <td>125.019997</td>\n",
       "      <td>353.260010</td>\n",
       "      <td>280.829987</td>\n",
       "      <td>126.440002</td>\n",
       "      <td>325.609985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047995</td>\n",
       "      <td>0.039195</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.021278</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>-0.018288</td>\n",
       "      <td>0.048140</td>\n",
       "      <td>7.431202e+09</td>\n",
       "      <td>0.023652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>288.640015</td>\n",
       "      <td>181.710007</td>\n",
       "      <td>124.589996</td>\n",
       "      <td>342.079987</td>\n",
       "      <td>263.109985</td>\n",
       "      <td>123.360001</td>\n",
       "      <td>314.679993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065177</td>\n",
       "      <td>-0.024661</td>\n",
       "      <td>-0.034144</td>\n",
       "      <td>-0.035618</td>\n",
       "      <td>-0.069156</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>-0.031112</td>\n",
       "      <td>-0.007741</td>\n",
       "      <td>7.161201e+09</td>\n",
       "      <td>-0.037010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>463 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AAPL_Adj Close  MSFT_Adj Close  MA_Adj Close  V_Adj Close  \\\n",
       "1   2019-01-02       38.249401       98.860214    187.678177   131.462326   \n",
       "2   2019-01-03       34.439476       95.223351    179.211197   126.724884   \n",
       "3   2019-01-04       35.909672       99.652115    187.697968   132.184341   \n",
       "4   2019-01-07       35.829746       99.779205    189.142090   134.567917   \n",
       "5   2019-01-08       36.512772      100.502670    190.519348   135.299805   \n",
       "..         ...             ...             ...           ...          ...   \n",
       "459 2020-10-26      114.851852      210.080002    318.059998   193.070007   \n",
       "460 2020-10-27      116.399178      213.250000    317.109985   190.059998   \n",
       "461 2020-10-28      111.008476      202.679993    291.380005   180.869995   \n",
       "462 2020-10-29      115.121384      204.720001    293.179993   184.869995   \n",
       "463 2020-10-30      108.672516      202.470001    288.640015   181.710007   \n",
       "\n",
       "     FIS_Adj Close  LRCX_Adj Close  FB_Adj Close  QCOM_Adj Close  \\\n",
       "1        99.532082      133.541534    135.679993       54.205219   \n",
       "2        96.470459      127.101006    131.740005       52.599842   \n",
       "3        99.875542      133.309784    137.949997       53.449738   \n",
       "4       100.503555      134.497452    138.050003       53.298649   \n",
       "5       101.259148      132.218643    142.529999       52.835922   \n",
       "..             ...             ...           ...             ...   \n",
       "459     139.419998      347.630005    277.109985      126.199997   \n",
       "460     137.860001      343.829987    283.290009      125.910004   \n",
       "461     132.509995      338.899994    267.670013      121.580002   \n",
       "462     125.019997      353.260010    280.829987      126.440002   \n",
       "463     124.589996      342.079987    263.109985      123.360001   \n",
       "\n",
       "     INTU_Adj Close  ...  FB_log_return  QCOM_log_return  INTU_log_return  \\\n",
       "1        191.487595  ...       0.034415         0.008573        -0.012164   \n",
       "2        185.628830  ...      -0.029469        -0.030064        -0.031074   \n",
       "3        192.994125  ...       0.046061         0.016029         0.038911   \n",
       "4        195.938248  ...       0.000725        -0.002831         0.015140   \n",
       "5        200.635086  ...       0.031937        -0.008720         0.023688   \n",
       "..              ...  ...            ...              ...              ...   \n",
       "459      328.089996  ...      -0.027338        -0.021014        -0.019110   \n",
       "460      330.269989  ...       0.022057        -0.002301         0.006623   \n",
       "461      318.510010  ...      -0.056716        -0.034995        -0.036257   \n",
       "462      325.609985  ...       0.047995         0.039195         0.022046   \n",
       "463      314.679993  ...      -0.065177        -0.024661        -0.034144   \n",
       "\n",
       "     AMD_log_return  MELI_log_return  G_log_return  MDB_log_return  \\\n",
       "1          0.019845         0.017467     -0.007438       -0.046315   \n",
       "2         -0.099301        -0.004776     -0.013529       -0.052116   \n",
       "3          0.108289         0.061269      0.025403        0.074136   \n",
       "4          0.079395         0.042256      0.007716        0.047432   \n",
       "5          0.008713        -0.001369      0.017057        0.048846   \n",
       "..              ...              ...           ...             ...   \n",
       "459        0.003289        -0.023690     -0.039978       -0.032373   \n",
       "460       -0.041593         0.000803     -0.007057        0.016154   \n",
       "461       -0.031945        -0.006948     -0.037228       -0.016404   \n",
       "462        0.020982         0.021278      0.006448       -0.018288   \n",
       "463       -0.035618        -0.069156      0.004082       -0.031112   \n",
       "\n",
       "     NXPI_log_return  Portfolio_Value  log_return  \n",
       "1           0.023600     3.108594e+09         NaN  \n",
       "2          -0.041638     2.926400e+09   -0.060398  \n",
       "3           0.047221     3.057864e+09    0.043944  \n",
       "4           0.007395     3.072014e+09    0.004617  \n",
       "5           0.005641     3.109145e+09    0.012014  \n",
       "..               ...              ...         ...  \n",
       "459        -0.016834     7.530051e+09   -0.015019  \n",
       "460        -0.012383     7.597413e+09    0.008906  \n",
       "461        -0.026313     7.257499e+09   -0.045773  \n",
       "462         0.048140     7.431202e+09    0.023652  \n",
       "463        -0.007741     7.161201e+09   -0.037010  \n",
       "\n",
       "[463 rows x 31 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " portfolio_opt['Portfolio_Value']=0\n",
    "for i in range(len(shares)):\n",
    "    portfolio_opt['Portfolio_Value'] += portfolio_opt[tickers_optimal[i]+'_Adj Close']*np.round(shares[i],0) \n",
    "    \n",
    "    #portfolio_opt['MSFT_Adj Close']*0.092569 + portfolio_opt['MA_Adj Close']*0.156987 + portfolio_opt['V_Adj Close']*0.137560 + portfolio_opt['FIS_Adj Close']*0.074765 + portfolio_opt['LRCX_Adj Close']*0.050595 + portfolio_opt['FB_Adj Close']*0.000872 + portfolio_opt['QCOM_Adj Close']*0.040578 + portfolio_opt['INTU_Adj Close']*0.199530 + portfolio_opt['AMD_Adj Close']*0.045174 + portfolio_opt['MELI_Adj Close']*0.016148 + portfolio_opt['G_Adj Close']*0.044405 + portfolio_opt['MDB_Adj Close']*0.015470 + portfolio_opt['NXPI_Adj Close']*0.072358\n",
    "portfolio_opt['log_return'] = np.log(portfolio_opt['Portfolio_Value']/portfolio_opt['Portfolio_Value'].shift(1))\n",
    "portfolio_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL_log_return    0.002258\n",
       "MSFT_log_return    0.001539\n",
       "MA_log_return      0.000942\n",
       "V_log_return       0.000715\n",
       "FIS_log_return     0.000461\n",
       "LRCX_log_return    0.002065\n",
       "FB_log_return      0.001505\n",
       "QCOM_log_return    0.001795\n",
       "INTU_log_return    0.001047\n",
       "AMD_log_return     0.003036\n",
       "MELI_log_return    0.003071\n",
       "G_log_return       0.000558\n",
       "MDB_log_return     0.002168\n",
       "NXPI_log_return    0.001370\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_log_returns = portfolio_opt[['AAPL_log_return','MSFT_log_return','MA_log_return','V_log_return','FIS_log_return','LRCX_log_return','FB_log_return','QCOM_log_return','INTU_log_return','AMD_log_return','MELI_log_return','G_log_return','MDB_log_return','NXPI_log_return']].mean()\n",
    "mean_log_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized weights\n",
    "weights = np.array([0.052990, 0.092569, 0.156987, 0.137560, 0.074765, 0.050595, 0.000872, 0.040578, 0.199530, 0.045174, 0.016148, 0.044405, 0.015470, 0.072358])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_2019=portfolio_opt[portfolio_opt['Date']<\"2020-01-01\"]\n",
    "portfolio_2020=portfolio_opt[portfolio_opt['Date']>\"2020-01-01\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017727528412736726\n",
      "93740110.72333317\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "z_alpha = norm.ppf(alpha, loc=0, scale=1) # z-score\n",
    "\n",
    "mean_log_returns = portfolio_2019[['AAPL_log_return','MSFT_log_return','MA_log_return','V_log_return','FIS_log_return','LRCX_log_return','FB_log_return','QCOM_log_return','INTU_log_return','AMD_log_return','MELI_log_return','G_log_return','MDB_log_return','NXPI_log_return']].mean()\n",
    "mean_arith_returns =  np.exp(mean_log_returns.values) - 1 # convert to arithmetic to find weighted returns\n",
    "weighted_arith_returns = np.dot(weights, mean_arith_returns)\n",
    "weighted_log_returns = np.log(1 + weighted_arith_returns) # convert back to log\n",
    "mu = weighted_log_returns\n",
    "\n",
    "mat_df = portfolio_2019[['AAPL_log_return','MSFT_log_return','MA_log_return','V_log_return','FIS_log_return','LRCX_log_return','FB_log_return','QCOM_log_return','INTU_log_return','AMD_log_return','MELI_log_return','G_log_return','MDB_log_return','NXPI_log_return']].values\n",
    "vcv = np.cov(mat_df.T)\n",
    "variance = np.dot(weights, np.dot(vcv, weights))\n",
    "sigma = sqrt(variance)       \n",
    "\n",
    "\n",
    "VaR_95 = mu + sigma*z_alpha\n",
    "VaR_95_arith = 1-np.exp(VaR_95)\n",
    "VaR_95_dollar = VaR_95_arith*portfolio_value_dec19\n",
    "print(VaR_95_arith)\n",
    "print(VaR_95_dollar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Prev Close</th>\n",
       "      <th>log_return</th>\n",
       "      <th>perc_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-29</th>\n",
       "      <td>236.869995</td>\n",
       "      <td>236.080002</td>\n",
       "      <td>236.479996</td>\n",
       "      <td>236.149994</td>\n",
       "      <td>189500.0</td>\n",
       "      <td>233.468948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>236.490005</td>\n",
       "      <td>231.729996</td>\n",
       "      <td>236.419998</td>\n",
       "      <td>232.789993</td>\n",
       "      <td>515600.0</td>\n",
       "      <td>230.147095</td>\n",
       "      <td>233.468948</td>\n",
       "      <td>-0.014330</td>\n",
       "      <td>0.985772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>231.009995</td>\n",
       "      <td>228.009995</td>\n",
       "      <td>228.990005</td>\n",
       "      <td>230.940002</td>\n",
       "      <td>578900.0</td>\n",
       "      <td>228.318100</td>\n",
       "      <td>230.147095</td>\n",
       "      <td>-0.007979</td>\n",
       "      <td>0.992053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>232.500000</td>\n",
       "      <td>231.410004</td>\n",
       "      <td>232.320007</td>\n",
       "      <td>231.720001</td>\n",
       "      <td>522700.0</td>\n",
       "      <td>229.089249</td>\n",
       "      <td>228.318100</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>1.003378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>232.759995</td>\n",
       "      <td>231.399994</td>\n",
       "      <td>232.520004</td>\n",
       "      <td>232.360001</td>\n",
       "      <td>354000.0</td>\n",
       "      <td>229.721985</td>\n",
       "      <td>229.089249</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>1.002762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06</th>\n",
       "      <td>235.070007</td>\n",
       "      <td>233.990005</td>\n",
       "      <td>234.199997</td>\n",
       "      <td>234.910004</td>\n",
       "      <td>390100.0</td>\n",
       "      <td>232.243042</td>\n",
       "      <td>229.721985</td>\n",
       "      <td>0.010915</td>\n",
       "      <td>1.010974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09</th>\n",
       "      <td>235.149994</td>\n",
       "      <td>233.580002</td>\n",
       "      <td>234.550003</td>\n",
       "      <td>233.699997</td>\n",
       "      <td>305000.0</td>\n",
       "      <td>231.046768</td>\n",
       "      <td>232.243042</td>\n",
       "      <td>-0.005164</td>\n",
       "      <td>0.994849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10</th>\n",
       "      <td>234.770004</td>\n",
       "      <td>233.210007</td>\n",
       "      <td>233.949997</td>\n",
       "      <td>233.600006</td>\n",
       "      <td>730300.0</td>\n",
       "      <td>230.947906</td>\n",
       "      <td>231.046768</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>0.999572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11</th>\n",
       "      <td>235.250000</td>\n",
       "      <td>233.639999</td>\n",
       "      <td>234.199997</td>\n",
       "      <td>235.139999</td>\n",
       "      <td>342100.0</td>\n",
       "      <td>232.470413</td>\n",
       "      <td>230.947906</td>\n",
       "      <td>0.006571</td>\n",
       "      <td>1.006592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12</th>\n",
       "      <td>237.759995</td>\n",
       "      <td>233.880005</td>\n",
       "      <td>234.639999</td>\n",
       "      <td>237.429993</td>\n",
       "      <td>613900.0</td>\n",
       "      <td>234.734421</td>\n",
       "      <td>232.470413</td>\n",
       "      <td>0.009692</td>\n",
       "      <td>1.009739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13</th>\n",
       "      <td>239.500000</td>\n",
       "      <td>236.850006</td>\n",
       "      <td>237.639999</td>\n",
       "      <td>238.970001</td>\n",
       "      <td>540400.0</td>\n",
       "      <td>236.256943</td>\n",
       "      <td>234.734421</td>\n",
       "      <td>0.006465</td>\n",
       "      <td>1.006486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16</th>\n",
       "      <td>241.350006</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.009995</td>\n",
       "      <td>240.460007</td>\n",
       "      <td>529300.0</td>\n",
       "      <td>238.379425</td>\n",
       "      <td>236.256943</td>\n",
       "      <td>0.008944</td>\n",
       "      <td>1.008984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17</th>\n",
       "      <td>240.990005</td>\n",
       "      <td>239.570007</td>\n",
       "      <td>240.940002</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>497800.0</td>\n",
       "      <td>237.923401</td>\n",
       "      <td>238.379425</td>\n",
       "      <td>-0.001915</td>\n",
       "      <td>0.998087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18</th>\n",
       "      <td>240.929993</td>\n",
       "      <td>239.889999</td>\n",
       "      <td>240.369995</td>\n",
       "      <td>240.080002</td>\n",
       "      <td>406000.0</td>\n",
       "      <td>238.002701</td>\n",
       "      <td>237.923401</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>1.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19</th>\n",
       "      <td>241.699997</td>\n",
       "      <td>240.199997</td>\n",
       "      <td>240.320007</td>\n",
       "      <td>241.660004</td>\n",
       "      <td>524600.0</td>\n",
       "      <td>239.569031</td>\n",
       "      <td>238.002701</td>\n",
       "      <td>0.006560</td>\n",
       "      <td>1.006581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20</th>\n",
       "      <td>243.339996</td>\n",
       "      <td>242.470001</td>\n",
       "      <td>243.110001</td>\n",
       "      <td>243.009995</td>\n",
       "      <td>519500.0</td>\n",
       "      <td>240.907333</td>\n",
       "      <td>239.569031</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>1.005586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>244.320007</td>\n",
       "      <td>243.350006</td>\n",
       "      <td>243.919998</td>\n",
       "      <td>243.830002</td>\n",
       "      <td>430700.0</td>\n",
       "      <td>241.720261</td>\n",
       "      <td>240.907333</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>1.003374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>244.240005</td>\n",
       "      <td>243.270004</td>\n",
       "      <td>244.100006</td>\n",
       "      <td>243.850006</td>\n",
       "      <td>234600.0</td>\n",
       "      <td>241.740097</td>\n",
       "      <td>241.720261</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>1.000082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>245.729996</td>\n",
       "      <td>244.320007</td>\n",
       "      <td>244.320007</td>\n",
       "      <td>245.729996</td>\n",
       "      <td>301500.0</td>\n",
       "      <td>243.603821</td>\n",
       "      <td>241.740097</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>1.007710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>246.750000</td>\n",
       "      <td>244.929993</td>\n",
       "      <td>246.710007</td>\n",
       "      <td>245.639999</td>\n",
       "      <td>349500.0</td>\n",
       "      <td>243.514587</td>\n",
       "      <td>243.603821</td>\n",
       "      <td>-0.000366</td>\n",
       "      <td>0.999634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>245.630005</td>\n",
       "      <td>242.100006</td>\n",
       "      <td>245.500000</td>\n",
       "      <td>244.179993</td>\n",
       "      <td>507000.0</td>\n",
       "      <td>242.067215</td>\n",
       "      <td>243.514587</td>\n",
       "      <td>-0.005961</td>\n",
       "      <td>0.994056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>245.050003</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>243.309998</td>\n",
       "      <td>244.850006</td>\n",
       "      <td>374300.0</td>\n",
       "      <td>242.731445</td>\n",
       "      <td>242.067215</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>1.002744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close    Volume  \\\n",
       "Date                                                                   \n",
       "2019-11-29  236.869995  236.080002  236.479996  236.149994  189500.0   \n",
       "2019-12-02  236.490005  231.729996  236.419998  232.789993  515600.0   \n",
       "2019-12-03  231.009995  228.009995  228.990005  230.940002  578900.0   \n",
       "2019-12-04  232.500000  231.410004  232.320007  231.720001  522700.0   \n",
       "2019-12-05  232.759995  231.399994  232.520004  232.360001  354000.0   \n",
       "2019-12-06  235.070007  233.990005  234.199997  234.910004  390100.0   \n",
       "2019-12-09  235.149994  233.580002  234.550003  233.699997  305000.0   \n",
       "2019-12-10  234.770004  233.210007  233.949997  233.600006  730300.0   \n",
       "2019-12-11  235.250000  233.639999  234.199997  235.139999  342100.0   \n",
       "2019-12-12  237.759995  233.880005  234.639999  237.429993  613900.0   \n",
       "2019-12-13  239.500000  236.850006  237.639999  238.970001  540400.0   \n",
       "2019-12-16  241.350006  240.000000  240.009995  240.460007  529300.0   \n",
       "2019-12-17  240.990005  239.570007  240.940002  240.000000  497800.0   \n",
       "2019-12-18  240.929993  239.889999  240.369995  240.080002  406000.0   \n",
       "2019-12-19  241.699997  240.199997  240.320007  241.660004  524600.0   \n",
       "2019-12-20  243.339996  242.470001  243.110001  243.009995  519500.0   \n",
       "2019-12-23  244.320007  243.350006  243.919998  243.830002  430700.0   \n",
       "2019-12-24  244.240005  243.270004  244.100006  243.850006  234600.0   \n",
       "2019-12-26  245.729996  244.320007  244.320007  245.729996  301500.0   \n",
       "2019-12-27  246.750000  244.929993  246.710007  245.639999  349500.0   \n",
       "2019-12-30  245.630005  242.100006  245.500000  244.179993  507000.0   \n",
       "2019-12-31  245.050003  243.000000  243.309998  244.850006  374300.0   \n",
       "\n",
       "             Adj Close  Prev Close  log_return  perc_return  \n",
       "Date                                                         \n",
       "2019-11-29  233.468948         NaN         NaN          NaN  \n",
       "2019-12-02  230.147095  233.468948   -0.014330     0.985772  \n",
       "2019-12-03  228.318100  230.147095   -0.007979     0.992053  \n",
       "2019-12-04  229.089249  228.318100    0.003372     1.003378  \n",
       "2019-12-05  229.721985  229.089249    0.002758     1.002762  \n",
       "2019-12-06  232.243042  229.721985    0.010915     1.010974  \n",
       "2019-12-09  231.046768  232.243042   -0.005164     0.994849  \n",
       "2019-12-10  230.947906  231.046768   -0.000428     0.999572  \n",
       "2019-12-11  232.470413  230.947906    0.006571     1.006592  \n",
       "2019-12-12  234.734421  232.470413    0.009692     1.009739  \n",
       "2019-12-13  236.256943  234.734421    0.006465     1.006486  \n",
       "2019-12-16  238.379425  236.256943    0.008944     1.008984  \n",
       "2019-12-17  237.923401  238.379425   -0.001915     0.998087  \n",
       "2019-12-18  238.002701  237.923401    0.000333     1.000333  \n",
       "2019-12-19  239.569031  238.002701    0.006560     1.006581  \n",
       "2019-12-20  240.907333  239.569031    0.005571     1.005586  \n",
       "2019-12-23  241.720261  240.907333    0.003369     1.003374  \n",
       "2019-12-24  241.740097  241.720261    0.000082     1.000082  \n",
       "2019-12-26  243.603821  241.740097    0.007680     1.007710  \n",
       "2019-12-27  243.514587  243.603821   -0.000366     0.999634  \n",
       "2019-12-30  242.067215  243.514587   -0.005961     0.994056  \n",
       "2019-12-31  242.731445  242.067215    0.002740     1.002744  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_index_VGT= get_data_for_multiple_stocks2([\"VGT\"],\"2019-11-30\", \"2019-12-31\")\n",
    "returns_index_VGT = returns_index_VGT[\"VGT\"]\n",
    "returns_index_VGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Prev Close</th>\n",
       "      <th>log_return</th>\n",
       "      <th>perc_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-29</th>\n",
       "      <td>3150.300049</td>\n",
       "      <td>3139.340088</td>\n",
       "      <td>3147.179932</td>\n",
       "      <td>3140.979980</td>\n",
       "      <td>1743020000</td>\n",
       "      <td>3140.979980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>3144.310059</td>\n",
       "      <td>3110.780029</td>\n",
       "      <td>3143.850098</td>\n",
       "      <td>3113.870117</td>\n",
       "      <td>3268740000</td>\n",
       "      <td>3113.870117</td>\n",
       "      <td>3140.979980</td>\n",
       "      <td>-0.008668</td>\n",
       "      <td>0.991369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>3094.969971</td>\n",
       "      <td>3070.330078</td>\n",
       "      <td>3087.409912</td>\n",
       "      <td>3093.199951</td>\n",
       "      <td>3653390000</td>\n",
       "      <td>3093.199951</td>\n",
       "      <td>3113.870117</td>\n",
       "      <td>-0.006660</td>\n",
       "      <td>0.993362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>3119.379883</td>\n",
       "      <td>3102.530029</td>\n",
       "      <td>3103.500000</td>\n",
       "      <td>3112.760010</td>\n",
       "      <td>3695030000</td>\n",
       "      <td>3112.760010</td>\n",
       "      <td>3093.199951</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>1.006324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>3119.449951</td>\n",
       "      <td>3103.760010</td>\n",
       "      <td>3119.209961</td>\n",
       "      <td>3117.429932</td>\n",
       "      <td>3355750000</td>\n",
       "      <td>3117.429932</td>\n",
       "      <td>3112.760010</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>1.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06</th>\n",
       "      <td>3150.600098</td>\n",
       "      <td>3134.620117</td>\n",
       "      <td>3134.620117</td>\n",
       "      <td>3145.909912</td>\n",
       "      <td>3479480000</td>\n",
       "      <td>3145.909912</td>\n",
       "      <td>3117.429932</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>1.009136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09</th>\n",
       "      <td>3148.870117</td>\n",
       "      <td>3135.459961</td>\n",
       "      <td>3141.860107</td>\n",
       "      <td>3135.959961</td>\n",
       "      <td>3345990000</td>\n",
       "      <td>3135.959961</td>\n",
       "      <td>3145.909912</td>\n",
       "      <td>-0.003168</td>\n",
       "      <td>0.996837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10</th>\n",
       "      <td>3142.120117</td>\n",
       "      <td>3126.090088</td>\n",
       "      <td>3135.360107</td>\n",
       "      <td>3132.520020</td>\n",
       "      <td>3343790000</td>\n",
       "      <td>3132.520020</td>\n",
       "      <td>3135.959961</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>0.998903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11</th>\n",
       "      <td>3143.979980</td>\n",
       "      <td>3133.209961</td>\n",
       "      <td>3135.750000</td>\n",
       "      <td>3141.629883</td>\n",
       "      <td>3252540000</td>\n",
       "      <td>3141.629883</td>\n",
       "      <td>3132.520020</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>1.002908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12</th>\n",
       "      <td>3176.280029</td>\n",
       "      <td>3138.469971</td>\n",
       "      <td>3141.229980</td>\n",
       "      <td>3168.570068</td>\n",
       "      <td>3990690000</td>\n",
       "      <td>3168.570068</td>\n",
       "      <td>3141.629883</td>\n",
       "      <td>0.008539</td>\n",
       "      <td>1.008575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13</th>\n",
       "      <td>3182.679932</td>\n",
       "      <td>3156.510010</td>\n",
       "      <td>3166.649902</td>\n",
       "      <td>3168.800049</td>\n",
       "      <td>3736870000</td>\n",
       "      <td>3168.800049</td>\n",
       "      <td>3168.570068</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>1.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16</th>\n",
       "      <td>3197.709961</td>\n",
       "      <td>3183.629883</td>\n",
       "      <td>3183.629883</td>\n",
       "      <td>3191.449951</td>\n",
       "      <td>4051790000</td>\n",
       "      <td>3191.449951</td>\n",
       "      <td>3168.800049</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>1.007148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17</th>\n",
       "      <td>3198.219971</td>\n",
       "      <td>3191.030029</td>\n",
       "      <td>3195.399902</td>\n",
       "      <td>3192.520020</td>\n",
       "      <td>3837540000</td>\n",
       "      <td>3192.520020</td>\n",
       "      <td>3191.449951</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>1.000335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18</th>\n",
       "      <td>3198.479980</td>\n",
       "      <td>3191.139893</td>\n",
       "      <td>3195.209961</td>\n",
       "      <td>3191.139893</td>\n",
       "      <td>4014080000</td>\n",
       "      <td>3191.139893</td>\n",
       "      <td>3192.520020</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>0.999568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19</th>\n",
       "      <td>3205.479980</td>\n",
       "      <td>3192.320068</td>\n",
       "      <td>3192.320068</td>\n",
       "      <td>3205.370117</td>\n",
       "      <td>3720450000</td>\n",
       "      <td>3205.370117</td>\n",
       "      <td>3191.139893</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>1.004459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20</th>\n",
       "      <td>3225.649902</td>\n",
       "      <td>3216.030029</td>\n",
       "      <td>3223.330078</td>\n",
       "      <td>3221.219971</td>\n",
       "      <td>6454270000</td>\n",
       "      <td>3221.219971</td>\n",
       "      <td>3205.370117</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>1.004945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>3227.780029</td>\n",
       "      <td>3222.300049</td>\n",
       "      <td>3226.050049</td>\n",
       "      <td>3224.010010</td>\n",
       "      <td>3060610000</td>\n",
       "      <td>3224.010010</td>\n",
       "      <td>3221.219971</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>1.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>3226.429932</td>\n",
       "      <td>3220.510010</td>\n",
       "      <td>3225.449951</td>\n",
       "      <td>3223.379883</td>\n",
       "      <td>1296540000</td>\n",
       "      <td>3223.379883</td>\n",
       "      <td>3224.010010</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>0.999805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>3240.080078</td>\n",
       "      <td>3227.199951</td>\n",
       "      <td>3227.199951</td>\n",
       "      <td>3239.909912</td>\n",
       "      <td>2160680000</td>\n",
       "      <td>3239.909912</td>\n",
       "      <td>3223.379883</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>1.005128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>3247.929932</td>\n",
       "      <td>3234.370117</td>\n",
       "      <td>3247.229980</td>\n",
       "      <td>3240.020020</td>\n",
       "      <td>2428670000</td>\n",
       "      <td>3240.020020</td>\n",
       "      <td>3239.909912</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>1.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>3240.919922</td>\n",
       "      <td>3216.570068</td>\n",
       "      <td>3240.090088</td>\n",
       "      <td>3221.290039</td>\n",
       "      <td>3013290000</td>\n",
       "      <td>3221.290039</td>\n",
       "      <td>3240.020020</td>\n",
       "      <td>-0.005798</td>\n",
       "      <td>0.994219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>3231.719971</td>\n",
       "      <td>3212.030029</td>\n",
       "      <td>3215.179932</td>\n",
       "      <td>3230.780029</td>\n",
       "      <td>2893810000</td>\n",
       "      <td>3230.780029</td>\n",
       "      <td>3221.290039</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>1.002946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   High          Low         Open        Close      Volume  \\\n",
       "Date                                                                         \n",
       "2019-11-29  3150.300049  3139.340088  3147.179932  3140.979980  1743020000   \n",
       "2019-12-02  3144.310059  3110.780029  3143.850098  3113.870117  3268740000   \n",
       "2019-12-03  3094.969971  3070.330078  3087.409912  3093.199951  3653390000   \n",
       "2019-12-04  3119.379883  3102.530029  3103.500000  3112.760010  3695030000   \n",
       "2019-12-05  3119.449951  3103.760010  3119.209961  3117.429932  3355750000   \n",
       "2019-12-06  3150.600098  3134.620117  3134.620117  3145.909912  3479480000   \n",
       "2019-12-09  3148.870117  3135.459961  3141.860107  3135.959961  3345990000   \n",
       "2019-12-10  3142.120117  3126.090088  3135.360107  3132.520020  3343790000   \n",
       "2019-12-11  3143.979980  3133.209961  3135.750000  3141.629883  3252540000   \n",
       "2019-12-12  3176.280029  3138.469971  3141.229980  3168.570068  3990690000   \n",
       "2019-12-13  3182.679932  3156.510010  3166.649902  3168.800049  3736870000   \n",
       "2019-12-16  3197.709961  3183.629883  3183.629883  3191.449951  4051790000   \n",
       "2019-12-17  3198.219971  3191.030029  3195.399902  3192.520020  3837540000   \n",
       "2019-12-18  3198.479980  3191.139893  3195.209961  3191.139893  4014080000   \n",
       "2019-12-19  3205.479980  3192.320068  3192.320068  3205.370117  3720450000   \n",
       "2019-12-20  3225.649902  3216.030029  3223.330078  3221.219971  6454270000   \n",
       "2019-12-23  3227.780029  3222.300049  3226.050049  3224.010010  3060610000   \n",
       "2019-12-24  3226.429932  3220.510010  3225.449951  3223.379883  1296540000   \n",
       "2019-12-26  3240.080078  3227.199951  3227.199951  3239.909912  2160680000   \n",
       "2019-12-27  3247.929932  3234.370117  3247.229980  3240.020020  2428670000   \n",
       "2019-12-30  3240.919922  3216.570068  3240.090088  3221.290039  3013290000   \n",
       "2019-12-31  3231.719971  3212.030029  3215.179932  3230.780029  2893810000   \n",
       "\n",
       "              Adj Close   Prev Close  log_return  perc_return  \n",
       "Date                                                           \n",
       "2019-11-29  3140.979980          NaN         NaN          NaN  \n",
       "2019-12-02  3113.870117  3140.979980   -0.008668     0.991369  \n",
       "2019-12-03  3093.199951  3113.870117   -0.006660     0.993362  \n",
       "2019-12-04  3112.760010  3093.199951    0.006304     1.006324  \n",
       "2019-12-05  3117.429932  3112.760010    0.001499     1.001500  \n",
       "2019-12-06  3145.909912  3117.429932    0.009094     1.009136  \n",
       "2019-12-09  3135.959961  3145.909912   -0.003168     0.996837  \n",
       "2019-12-10  3132.520020  3135.959961   -0.001098     0.998903  \n",
       "2019-12-11  3141.629883  3132.520020    0.002904     1.002908  \n",
       "2019-12-12  3168.570068  3141.629883    0.008539     1.008575  \n",
       "2019-12-13  3168.800049  3168.570068    0.000073     1.000073  \n",
       "2019-12-16  3191.449951  3168.800049    0.007122     1.007148  \n",
       "2019-12-17  3192.520020  3191.449951    0.000335     1.000335  \n",
       "2019-12-18  3191.139893  3192.520020   -0.000432     0.999568  \n",
       "2019-12-19  3205.370117  3191.139893    0.004449     1.004459  \n",
       "2019-12-20  3221.219971  3205.370117    0.004933     1.004945  \n",
       "2019-12-23  3224.010010  3221.219971    0.000866     1.000866  \n",
       "2019-12-24  3223.379883  3224.010010   -0.000195     0.999805  \n",
       "2019-12-26  3239.909912  3223.379883    0.005115     1.005128  \n",
       "2019-12-27  3240.020020  3239.909912    0.000034     1.000034  \n",
       "2019-12-30  3221.290039  3240.020020   -0.005798     0.994219  \n",
       "2019-12-31  3230.780029  3221.290039    0.002942     1.002946  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_index_SP = get_data_for_multiple_stocks2([\"^GSPC\"],\"2019-11-30\", \"2019-12-31\")\n",
    "returns_index_SP  = returns_index_SP[\"^GSPC\"]\n",
    "returns_index_SP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Prev Close</th>\n",
       "      <th>log_return</th>\n",
       "      <th>perc_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-29</th>\n",
       "      <td>224.460007</td>\n",
       "      <td>223.679993</td>\n",
       "      <td>224.089996</td>\n",
       "      <td>223.679993</td>\n",
       "      <td>19900.0</td>\n",
       "      <td>221.800751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02</th>\n",
       "      <td>223.970001</td>\n",
       "      <td>219.619995</td>\n",
       "      <td>223.970001</td>\n",
       "      <td>220.539993</td>\n",
       "      <td>138200.0</td>\n",
       "      <td>218.687134</td>\n",
       "      <td>221.800751</td>\n",
       "      <td>-0.014137</td>\n",
       "      <td>0.985962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03</th>\n",
       "      <td>219.020004</td>\n",
       "      <td>216.199997</td>\n",
       "      <td>216.880005</td>\n",
       "      <td>219.020004</td>\n",
       "      <td>119400.0</td>\n",
       "      <td>217.179932</td>\n",
       "      <td>218.687134</td>\n",
       "      <td>-0.006916</td>\n",
       "      <td>0.993108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04</th>\n",
       "      <td>220.740005</td>\n",
       "      <td>219.979996</td>\n",
       "      <td>220.229996</td>\n",
       "      <td>220.139999</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>218.290497</td>\n",
       "      <td>217.179932</td>\n",
       "      <td>0.005101</td>\n",
       "      <td>1.005114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>221.320007</td>\n",
       "      <td>219.960007</td>\n",
       "      <td>221.160004</td>\n",
       "      <td>220.839996</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>218.984619</td>\n",
       "      <td>218.290497</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>1.003180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06</th>\n",
       "      <td>223.570007</td>\n",
       "      <td>222.389999</td>\n",
       "      <td>222.440002</td>\n",
       "      <td>223.360001</td>\n",
       "      <td>122400.0</td>\n",
       "      <td>221.483459</td>\n",
       "      <td>218.984619</td>\n",
       "      <td>0.011346</td>\n",
       "      <td>1.011411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09</th>\n",
       "      <td>223.960007</td>\n",
       "      <td>222.360001</td>\n",
       "      <td>222.740005</td>\n",
       "      <td>222.369995</td>\n",
       "      <td>53700.0</td>\n",
       "      <td>220.501755</td>\n",
       "      <td>221.483459</td>\n",
       "      <td>-0.004442</td>\n",
       "      <td>0.995568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10</th>\n",
       "      <td>223.639999</td>\n",
       "      <td>222.050003</td>\n",
       "      <td>222.580002</td>\n",
       "      <td>222.610001</td>\n",
       "      <td>67200.0</td>\n",
       "      <td>220.739746</td>\n",
       "      <td>220.501755</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>1.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11</th>\n",
       "      <td>224.029999</td>\n",
       "      <td>222.669998</td>\n",
       "      <td>222.990005</td>\n",
       "      <td>223.839996</td>\n",
       "      <td>41100.0</td>\n",
       "      <td>221.959412</td>\n",
       "      <td>220.739746</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>1.005525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12</th>\n",
       "      <td>226.320007</td>\n",
       "      <td>223.149994</td>\n",
       "      <td>223.509995</td>\n",
       "      <td>225.699997</td>\n",
       "      <td>113400.0</td>\n",
       "      <td>223.803787</td>\n",
       "      <td>221.959412</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>1.008310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13</th>\n",
       "      <td>227.320007</td>\n",
       "      <td>225.429993</td>\n",
       "      <td>225.770004</td>\n",
       "      <td>226.669998</td>\n",
       "      <td>70300.0</td>\n",
       "      <td>224.765640</td>\n",
       "      <td>223.803787</td>\n",
       "      <td>0.004289</td>\n",
       "      <td>1.004298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16</th>\n",
       "      <td>229.389999</td>\n",
       "      <td>227.869995</td>\n",
       "      <td>227.899994</td>\n",
       "      <td>228.649994</td>\n",
       "      <td>111500.0</td>\n",
       "      <td>227.095688</td>\n",
       "      <td>224.765640</td>\n",
       "      <td>0.010313</td>\n",
       "      <td>1.010367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17</th>\n",
       "      <td>229.059998</td>\n",
       "      <td>227.880005</td>\n",
       "      <td>229.020004</td>\n",
       "      <td>228.089996</td>\n",
       "      <td>164200.0</td>\n",
       "      <td>226.539490</td>\n",
       "      <td>227.095688</td>\n",
       "      <td>-0.002452</td>\n",
       "      <td>0.997551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18</th>\n",
       "      <td>229.270004</td>\n",
       "      <td>228.270004</td>\n",
       "      <td>228.550003</td>\n",
       "      <td>228.500000</td>\n",
       "      <td>57100.0</td>\n",
       "      <td>226.946716</td>\n",
       "      <td>226.539490</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>1.001798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19</th>\n",
       "      <td>230.169998</td>\n",
       "      <td>228.639999</td>\n",
       "      <td>228.639999</td>\n",
       "      <td>230.160004</td>\n",
       "      <td>105500.0</td>\n",
       "      <td>228.595444</td>\n",
       "      <td>226.946716</td>\n",
       "      <td>0.007239</td>\n",
       "      <td>1.007265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20</th>\n",
       "      <td>231.460007</td>\n",
       "      <td>230.589996</td>\n",
       "      <td>231.440002</td>\n",
       "      <td>231.210007</td>\n",
       "      <td>76700.0</td>\n",
       "      <td>229.638290</td>\n",
       "      <td>228.595444</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>1.004562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>232.429993</td>\n",
       "      <td>231.729996</td>\n",
       "      <td>232.020004</td>\n",
       "      <td>232.070007</td>\n",
       "      <td>86200.0</td>\n",
       "      <td>230.492462</td>\n",
       "      <td>229.638290</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>1.003720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>232.449997</td>\n",
       "      <td>231.509995</td>\n",
       "      <td>232.449997</td>\n",
       "      <td>232.020004</td>\n",
       "      <td>80100.0</td>\n",
       "      <td>230.442795</td>\n",
       "      <td>230.492462</td>\n",
       "      <td>-0.000216</td>\n",
       "      <td>0.999785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>233.990005</td>\n",
       "      <td>232.020004</td>\n",
       "      <td>232.429993</td>\n",
       "      <td>233.990005</td>\n",
       "      <td>62400.0</td>\n",
       "      <td>232.399399</td>\n",
       "      <td>230.442795</td>\n",
       "      <td>0.008455</td>\n",
       "      <td>1.008491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>234.929993</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>234.929993</td>\n",
       "      <td>233.690002</td>\n",
       "      <td>44200.0</td>\n",
       "      <td>232.101440</td>\n",
       "      <td>232.399399</td>\n",
       "      <td>-0.001283</td>\n",
       "      <td>0.998718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>233.500000</td>\n",
       "      <td>230.410004</td>\n",
       "      <td>233.500000</td>\n",
       "      <td>232.059998</td>\n",
       "      <td>79700.0</td>\n",
       "      <td>230.482513</td>\n",
       "      <td>232.101440</td>\n",
       "      <td>-0.007000</td>\n",
       "      <td>0.993025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>232.779999</td>\n",
       "      <td>231.160004</td>\n",
       "      <td>231.240005</td>\n",
       "      <td>232.600006</td>\n",
       "      <td>50900.0</td>\n",
       "      <td>231.018845</td>\n",
       "      <td>230.482513</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>1.002327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close    Volume  \\\n",
       "Date                                                                   \n",
       "2019-11-29  224.460007  223.679993  224.089996  223.679993   19900.0   \n",
       "2019-12-02  223.970001  219.619995  223.970001  220.539993  138200.0   \n",
       "2019-12-03  219.020004  216.199997  216.880005  219.020004  119400.0   \n",
       "2019-12-04  220.740005  219.979996  220.229996  220.139999   79000.0   \n",
       "2019-12-05  221.320007  219.960007  221.160004  220.839996   95000.0   \n",
       "2019-12-06  223.570007  222.389999  222.440002  223.360001  122400.0   \n",
       "2019-12-09  223.960007  222.360001  222.740005  222.369995   53700.0   \n",
       "2019-12-10  223.639999  222.050003  222.580002  222.610001   67200.0   \n",
       "2019-12-11  224.029999  222.669998  222.990005  223.839996   41100.0   \n",
       "2019-12-12  226.320007  223.149994  223.509995  225.699997  113400.0   \n",
       "2019-12-13  227.320007  225.429993  225.770004  226.669998   70300.0   \n",
       "2019-12-16  229.389999  227.869995  227.899994  228.649994  111500.0   \n",
       "2019-12-17  229.059998  227.880005  229.020004  228.089996  164200.0   \n",
       "2019-12-18  229.270004  228.270004  228.550003  228.500000   57100.0   \n",
       "2019-12-19  230.169998  228.639999  228.639999  230.160004  105500.0   \n",
       "2019-12-20  231.460007  230.589996  231.440002  231.210007   76700.0   \n",
       "2019-12-23  232.429993  231.729996  232.020004  232.070007   86200.0   \n",
       "2019-12-24  232.449997  231.509995  232.449997  232.020004   80100.0   \n",
       "2019-12-26  233.990005  232.020004  232.429993  233.990005   62400.0   \n",
       "2019-12-27  234.929993  233.000000  234.929993  233.690002   44200.0   \n",
       "2019-12-30  233.500000  230.410004  233.500000  232.059998   79700.0   \n",
       "2019-12-31  232.779999  231.160004  231.240005  232.600006   50900.0   \n",
       "\n",
       "             Adj Close  Prev Close  log_return  perc_return  \n",
       "Date                                                         \n",
       "2019-11-29  221.800751         NaN         NaN          NaN  \n",
       "2019-12-02  218.687134  221.800751   -0.014137     0.985962  \n",
       "2019-12-03  217.179932  218.687134   -0.006916     0.993108  \n",
       "2019-12-04  218.290497  217.179932    0.005101     1.005114  \n",
       "2019-12-05  218.984619  218.290497    0.003175     1.003180  \n",
       "2019-12-06  221.483459  218.984619    0.011346     1.011411  \n",
       "2019-12-09  220.501755  221.483459   -0.004442     0.995568  \n",
       "2019-12-10  220.739746  220.501755    0.001079     1.001079  \n",
       "2019-12-11  221.959412  220.739746    0.005510     1.005525  \n",
       "2019-12-12  223.803787  221.959412    0.008275     1.008310  \n",
       "2019-12-13  224.765640  223.803787    0.004289     1.004298  \n",
       "2019-12-16  227.095688  224.765640    0.010313     1.010367  \n",
       "2019-12-17  226.539490  227.095688   -0.002452     0.997551  \n",
       "2019-12-18  226.946716  226.539490    0.001796     1.001798  \n",
       "2019-12-19  228.595444  226.946716    0.007239     1.007265  \n",
       "2019-12-20  229.638290  228.595444    0.004552     1.004562  \n",
       "2019-12-23  230.492462  229.638290    0.003713     1.003720  \n",
       "2019-12-24  230.442795  230.492462   -0.000216     0.999785  \n",
       "2019-12-26  232.399399  230.442795    0.008455     1.008491  \n",
       "2019-12-27  232.101440  232.399399   -0.001283     0.998718  \n",
       "2019-12-30  230.482513  232.101440   -0.007000     0.993025  \n",
       "2019-12-31  231.018845  230.482513    0.002324     1.002327  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_index_IYW = get_data_for_multiple_stocks2([\"IYW\"],\"2019-11-30\", \"2019-12-31\")\n",
    "returns_index_IYW  = returns_index_IYW[\"IYW\"]\n",
    "returns_index_IYW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_index_IYW.reset_index(inplace=True)\n",
    "returns_index_SP.reset_index(inplace=True)\n",
    "returns_index_VGT.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS(returns_index):\n",
    "    date = returns_index[returns_index['Date'] >= \"2019-12-01\"]['Date']\n",
    "    port_return = portfolio_2019[portfolio_2019['Date'] >= \"2019-12-01\"]['log_return']\n",
    "    mkt_return =returns_index[returns_index['Date'] >= \"2019-12-01\"]['log_return']\n",
    "\n",
    "    #assume annual rF is 2% log return \n",
    "    df = pd.DataFrame({'Date': date, 'Portfolio Returns': port_return.values, 'Index Returns': mkt_return.values, 'Risk Free Rate': (0.02/252)})\n",
    "    df['Ri - Rf'] = df['Portfolio Returns'] - df['Risk Free Rate']\n",
    "    df['Rm - Rf'] = df['Index Returns'] - df['Risk Free Rate']\n",
    "    df['const'] = 1.0\n",
    "    \n",
    "    print(sm.OLS(df['Ri - Rf'], df[['const','Rm - Rf']]).fit().summary())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Ri - Rf   R-squared:                       0.934\n",
      "Model:                            OLS   Adj. R-squared:                  0.930\n",
      "Method:                 Least Squares   F-statistic:                     268.3\n",
      "Date:                Thu, 12 Nov 2020   Prob (F-statistic):           1.16e-12\n",
      "Time:                        00:09:45   Log-Likelihood:                 103.83\n",
      "No. Observations:                  21   AIC:                            -203.7\n",
      "Df Residuals:                      19   BIC:                            -201.6\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0009      0.000      2.121      0.047    1.15e-05       0.002\n",
      "Rm - Rf        1.0417      0.064     16.380      0.000       0.909       1.175\n",
      "==============================================================================\n",
      "Omnibus:                        0.686   Durbin-Watson:                   1.723\n",
      "Prob(Omnibus):                  0.710   Jarque-Bera (JB):                0.627\n",
      "Skew:                          -0.367   Prob(JB):                        0.731\n",
      "Kurtosis:                       2.577   Cond. No.                         161.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "VGT=OLS(returns_index_VGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Ri - Rf   R-squared:                       0.805\n",
      "Model:                            OLS   Adj. R-squared:                  0.795\n",
      "Method:                 Least Squares   F-statistic:                     78.32\n",
      "Date:                Thu, 12 Nov 2020   Prob (F-statistic):           3.62e-08\n",
      "Time:                        00:09:45   Log-Likelihood:                 92.462\n",
      "No. Observations:                  21   AIC:                            -180.9\n",
      "Df Residuals:                      19   BIC:                            -178.8\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0011      0.001      1.567      0.134      -0.000       0.003\n",
      "Rm - Rf        1.2803      0.145      8.850      0.000       0.978       1.583\n",
      "==============================================================================\n",
      "Omnibus:                        0.976   Durbin-Watson:                   2.482\n",
      "Prob(Omnibus):                  0.614   Jarque-Bera (JB):                0.857\n",
      "Skew:                           0.440   Prob(JB):                        0.651\n",
      "Kurtosis:                       2.546   Cond. No.                         213.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "SP=OLS(returns_index_SP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                Ri - Rf   R-squared:                       0.919\n",
      "Model:                            OLS   Adj. R-squared:                  0.915\n",
      "Method:                 Least Squares   F-statistic:                     216.0\n",
      "Date:                Thu, 12 Nov 2020   Prob (F-statistic):           7.87e-12\n",
      "Time:                        00:09:46   Log-Likelihood:                 101.72\n",
      "No. Observations:                  21   AIC:                            -199.4\n",
      "Df Residuals:                      19   BIC:                            -197.3\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0008      0.000      1.719      0.102      -0.000       0.002\n",
      "Rm - Rf        1.0401      0.071     14.697      0.000       0.892       1.188\n",
      "==============================================================================\n",
      "Omnibus:                        1.455   Durbin-Watson:                   1.822\n",
      "Prob(Omnibus):                  0.483   Jarque-Bera (JB):                1.072\n",
      "Skew:                          -0.534   Prob(JB):                        0.585\n",
      "Kurtosis:                       2.710   Cond. No.                         162.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "IYW=OLS(returns_index_IYW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since VGT gave the highest r-square, we chose VGT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta =1.0417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006708554105523655"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_portfolio = np.std(np.exp(VGT[\"Portfolio Returns\"])-1)\n",
    "sd_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006215395718860327"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_index = np.std(np.exp(VGT[\"Index Returns\"]) - 1)\n",
    "sd_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9651226804604286"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = (beta*(sd_index))/sd_portfolio\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01701788270398073"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percentage arith VaR for index\n",
    "index_VaR = VaR_95_arith/beta\n",
    "index_VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238.60066974042226"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#price on 31 dec 2019 of index = 242.731445\n",
    "est_strike_price = (1-index_VaR)*242.731445\n",
    "est_strike_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>symbol_flag</th>\n",
       "      <th>exdate</th>\n",
       "      <th>last_date</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>...</th>\n",
       "      <th>sic</th>\n",
       "      <th>index_flag</th>\n",
       "      <th>exchange_d</th>\n",
       "      <th>class</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>industry_group</th>\n",
       "      <th>issuer</th>\n",
       "      <th>div_convention</th>\n",
       "      <th>exercise_style</th>\n",
       "      <th>am_set_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200117C225000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/01/17</td>\n",
       "      <td>2019/12/18</td>\n",
       "      <td>C</td>\n",
       "      <td>225000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>22.3</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200117C230000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/01/17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>230000</td>\n",
       "      <td>11.10</td>\n",
       "      <td>17.1</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200117C235000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/01/17</td>\n",
       "      <td>2019/12/02</td>\n",
       "      <td>C</td>\n",
       "      <td>235000</td>\n",
       "      <td>6.50</td>\n",
       "      <td>11.6</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200117C240000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/01/17</td>\n",
       "      <td>2019/12/23</td>\n",
       "      <td>C</td>\n",
       "      <td>240000</td>\n",
       "      <td>2.30</td>\n",
       "      <td>9.6</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200117C245000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/01/17</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>C</td>\n",
       "      <td>245000</td>\n",
       "      <td>2.55</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200821P235000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/08/21</td>\n",
       "      <td>2019/12/27</td>\n",
       "      <td>P</td>\n",
       "      <td>235000</td>\n",
       "      <td>4.50</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200821P240000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/08/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>240000</td>\n",
       "      <td>6.00</td>\n",
       "      <td>14.3</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200821P245000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/08/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>245000</td>\n",
       "      <td>8.00</td>\n",
       "      <td>16.4</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200821P250000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/08/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>250000</td>\n",
       "      <td>10.50</td>\n",
       "      <td>18.7</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200821P255000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/08/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>255000</td>\n",
       "      <td>13.50</td>\n",
       "      <td>21.5</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     secid        date             symbol  symbol_flag      exdate  \\\n",
       "0   120145  2019/12/31  VGT 200117C225000            1  2020/01/17   \n",
       "1   120145  2019/12/31  VGT 200117C230000            1  2020/01/17   \n",
       "2   120145  2019/12/31  VGT 200117C235000            1  2020/01/17   \n",
       "3   120145  2019/12/31  VGT 200117C240000            1  2020/01/17   \n",
       "4   120145  2019/12/31  VGT 200117C245000            1  2020/01/17   \n",
       "..     ...         ...                ...          ...         ...   \n",
       "85  120145  2019/12/31  VGT 200821P235000            1  2020/08/21   \n",
       "86  120145  2019/12/31  VGT 200821P240000            1  2020/08/21   \n",
       "87  120145  2019/12/31  VGT 200821P245000            1  2020/08/21   \n",
       "88  120145  2019/12/31  VGT 200821P250000            1  2020/08/21   \n",
       "89  120145  2019/12/31  VGT 200821P255000            1  2020/08/21   \n",
       "\n",
       "     last_date cp_flag  strike_price  best_bid  best_offer  ...   sic  \\\n",
       "0   2019/12/18       C        225000     16.00        22.3  ...  6722   \n",
       "1          NaN       C        230000     11.10        17.1  ...  6722   \n",
       "2   2019/12/02       C        235000      6.50        11.6  ...  6722   \n",
       "3   2019/12/23       C        240000      2.30         9.6  ...  6722   \n",
       "4   2019/12/31       C        245000      2.55         3.8  ...  6722   \n",
       "..         ...     ...           ...       ...         ...  ...   ...   \n",
       "85  2019/12/27       P        235000      4.50        12.5  ...  6722   \n",
       "86         NaN       P        240000      6.00        14.3  ...  6722   \n",
       "87         NaN       P        245000      8.00        16.4  ...  6722   \n",
       "88         NaN       P        250000     10.50        18.7  ...  6722   \n",
       "89         NaN       P        255000     13.50        21.5  ...  6722   \n",
       "\n",
       "    index_flag  exchange_d  class  issue_type  industry_group  \\\n",
       "0            0           1    NaN           %             426   \n",
       "1            0           1    NaN           %             426   \n",
       "2            0           1    NaN           %             426   \n",
       "3            0           1    NaN           %             426   \n",
       "4            0           1    NaN           %             426   \n",
       "..         ...         ...    ...         ...             ...   \n",
       "85           0           1    NaN           %             426   \n",
       "86           0           1    NaN           %             426   \n",
       "87           0           1    NaN           %             426   \n",
       "88           0           1    NaN           %             426   \n",
       "89           0           1    NaN           %             426   \n",
       "\n",
       "                issuer  div_convention  exercise_style  am_set_flag  \n",
       "0   VANGUARD WORLD FDS             NaN               A            0  \n",
       "1   VANGUARD WORLD FDS             NaN               A            0  \n",
       "2   VANGUARD WORLD FDS             NaN               A            0  \n",
       "3   VANGUARD WORLD FDS             NaN               A            0  \n",
       "4   VANGUARD WORLD FDS             NaN               A            0  \n",
       "..                 ...             ...             ...          ...  \n",
       "85  VANGUARD WORLD FDS             NaN               A            0  \n",
       "86  VANGUARD WORLD FDS             NaN               A            0  \n",
       "87  VANGUARD WORLD FDS             NaN               A            0  \n",
       "88  VANGUARD WORLD FDS             NaN               A            0  \n",
       "89  VANGUARD WORLD FDS             NaN               A            0  \n",
       "\n",
       "[90 rows x 38 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_options_VGT = pd.read_csv(\"VGT_Vanguard Information Technology ETF.csv\")\n",
    "index_options_VGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_options_VGT = index_options_VGT[index_options_VGT['cp_flag']==\"P\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-91-24390becbfe7>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  index_options_VGT['strike_price'] = index_options_VGT['strike_price']/1000\n"
     ]
    }
   ],
   "source": [
    "index_options_VGT['strike_price'] = index_options_VGT['strike_price']/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expiration date: feb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>symbol_flag</th>\n",
       "      <th>exdate</th>\n",
       "      <th>last_date</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>...</th>\n",
       "      <th>sic</th>\n",
       "      <th>index_flag</th>\n",
       "      <th>exchange_d</th>\n",
       "      <th>class</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>industry_group</th>\n",
       "      <th>issuer</th>\n",
       "      <th>div_convention</th>\n",
       "      <th>exercise_style</th>\n",
       "      <th>am_set_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P200000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2019/12/27</td>\n",
       "      <td>P</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P205000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2019/12/12</td>\n",
       "      <td>P</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P210000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2019/12/03</td>\n",
       "      <td>P</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P215000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2019/11/20</td>\n",
       "      <td>P</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.40</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P220000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2019/11/27</td>\n",
       "      <td>P</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.25</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P225000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2019/12/30</td>\n",
       "      <td>P</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.70</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P230000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2019/12/27</td>\n",
       "      <td>P</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.10</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P240000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2019/12/30</td>\n",
       "      <td>P</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>4.60</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P250000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>250.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>11.50</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P260000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>260.0</td>\n",
       "      <td>11.90</td>\n",
       "      <td>19.30</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P270000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>270.0</td>\n",
       "      <td>21.70</td>\n",
       "      <td>29.80</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P280000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>280.0</td>\n",
       "      <td>31.70</td>\n",
       "      <td>39.80</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P290000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>290.0</td>\n",
       "      <td>41.60</td>\n",
       "      <td>49.80</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P300000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>300.0</td>\n",
       "      <td>51.60</td>\n",
       "      <td>59.80</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     secid        date             symbol  symbol_flag      exdate  \\\n",
       "26  120145  2019/12/31  VGT 200221P200000            1  2020/02/21   \n",
       "27  120145  2019/12/31  VGT 200221P205000            1  2020/02/21   \n",
       "28  120145  2019/12/31  VGT 200221P210000            1  2020/02/21   \n",
       "29  120145  2019/12/31  VGT 200221P215000            1  2020/02/21   \n",
       "30  120145  2019/12/31  VGT 200221P220000            1  2020/02/21   \n",
       "31  120145  2019/12/31  VGT 200221P225000            1  2020/02/21   \n",
       "32  120145  2019/12/31  VGT 200221P230000            1  2020/02/21   \n",
       "33  120145  2019/12/31  VGT 200221P240000            1  2020/02/21   \n",
       "34  120145  2019/12/31  VGT 200221P250000            1  2020/02/21   \n",
       "35  120145  2019/12/31  VGT 200221P260000            1  2020/02/21   \n",
       "36  120145  2019/12/31  VGT 200221P270000            1  2020/02/21   \n",
       "37  120145  2019/12/31  VGT 200221P280000            1  2020/02/21   \n",
       "38  120145  2019/12/31  VGT 200221P290000            1  2020/02/21   \n",
       "39  120145  2019/12/31  VGT 200221P300000            1  2020/02/21   \n",
       "\n",
       "     last_date cp_flag  strike_price  best_bid  best_offer  ...   sic  \\\n",
       "26  2019/12/27       P         200.0      0.00        1.20  ...  6722   \n",
       "27  2019/12/12       P         205.0      0.00        1.00  ...  6722   \n",
       "28  2019/12/03       P         210.0      0.20        1.15  ...  6722   \n",
       "29  2019/11/20       P         215.0      0.00        5.40  ...  6722   \n",
       "30  2019/11/27       P         220.0      0.95        2.25  ...  6722   \n",
       "31  2019/12/30       P         225.0      1.15        1.70  ...  6722   \n",
       "32  2019/12/27       P         230.0      0.05        6.10  ...  6722   \n",
       "33  2019/12/30       P         240.0      3.30        4.60  ...  6722   \n",
       "34         NaN       P         250.0      4.20       11.50  ...  6722   \n",
       "35         NaN       P         260.0     11.90       19.30  ...  6722   \n",
       "36         NaN       P         270.0     21.70       29.80  ...  6722   \n",
       "37         NaN       P         280.0     31.70       39.80  ...  6722   \n",
       "38         NaN       P         290.0     41.60       49.80  ...  6722   \n",
       "39         NaN       P         300.0     51.60       59.80  ...  6722   \n",
       "\n",
       "    index_flag  exchange_d  class  issue_type  industry_group  \\\n",
       "26           0           1    NaN           %             426   \n",
       "27           0           1    NaN           %             426   \n",
       "28           0           1    NaN           %             426   \n",
       "29           0           1    NaN           %             426   \n",
       "30           0           1    NaN           %             426   \n",
       "31           0           1    NaN           %             426   \n",
       "32           0           1    NaN           %             426   \n",
       "33           0           1    NaN           %             426   \n",
       "34           0           1    NaN           %             426   \n",
       "35           0           1    NaN           %             426   \n",
       "36           0           1    NaN           %             426   \n",
       "37           0           1    NaN           %             426   \n",
       "38           0           1    NaN           %             426   \n",
       "39           0           1    NaN           %             426   \n",
       "\n",
       "                issuer  div_convention  exercise_style  am_set_flag  \n",
       "26  VANGUARD WORLD FDS             NaN               A            0  \n",
       "27  VANGUARD WORLD FDS             NaN               A            0  \n",
       "28  VANGUARD WORLD FDS             NaN               A            0  \n",
       "29  VANGUARD WORLD FDS             NaN               A            0  \n",
       "30  VANGUARD WORLD FDS             NaN               A            0  \n",
       "31  VANGUARD WORLD FDS             NaN               A            0  \n",
       "32  VANGUARD WORLD FDS             NaN               A            0  \n",
       "33  VANGUARD WORLD FDS             NaN               A            0  \n",
       "34  VANGUARD WORLD FDS             NaN               A            0  \n",
       "35  VANGUARD WORLD FDS             NaN               A            0  \n",
       "36  VANGUARD WORLD FDS             NaN               A            0  \n",
       "37  VANGUARD WORLD FDS             NaN               A            0  \n",
       "38  VANGUARD WORLD FDS             NaN               A            0  \n",
       "39  VANGUARD WORLD FDS             NaN               A            0  \n",
       "\n",
       "[14 rows x 38 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_options_VGT_feb= index_options_VGT[index_options_VGT['exdate']==\"2020/02/21\"]\n",
    "index_options_VGT_feb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>symbol_flag</th>\n",
       "      <th>exdate</th>\n",
       "      <th>last_date</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>...</th>\n",
       "      <th>sic</th>\n",
       "      <th>index_flag</th>\n",
       "      <th>exchange_d</th>\n",
       "      <th>class</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>industry_group</th>\n",
       "      <th>issuer</th>\n",
       "      <th>div_convention</th>\n",
       "      <th>exercise_style</th>\n",
       "      <th>am_set_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200221P240000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/02/21</td>\n",
       "      <td>2019/12/30</td>\n",
       "      <td>P</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     secid        date             symbol  symbol_flag      exdate  \\\n",
       "33  120145  2019/12/31  VGT 200221P240000            1  2020/02/21   \n",
       "\n",
       "     last_date cp_flag  strike_price  best_bid  best_offer  ...   sic  \\\n",
       "33  2019/12/30       P         240.0       3.3         4.6  ...  6722   \n",
       "\n",
       "    index_flag  exchange_d  class  issue_type  industry_group  \\\n",
       "33           0           1    NaN           %             426   \n",
       "\n",
       "                issuer  div_convention  exercise_style  am_set_flag  \n",
       "33  VANGUARD WORLD FDS             NaN               A            0  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_options_VGT_feb[index_options_VGT_feb['strike_price']==240.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5287827414.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_value_dec19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_value_dec19 = 242.731445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "amt_put = (portfolio_value_dec19*beta)/index_value_dec19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22693103"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amt_put = int(amt_put)\n",
    "amt_put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104388273.8"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_puts = amt_put*4.6\n",
    "cost_puts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_money = portfolio_value_dec19*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_money > cost_puts #can buy amt_puts amount of puts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Prev Close</th>\n",
       "      <th>log_return</th>\n",
       "      <th>perc_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-20</th>\n",
       "      <td>273.51001</td>\n",
       "      <td>266.839996</td>\n",
       "      <td>272.890015</td>\n",
       "      <td>270.679993</td>\n",
       "      <td>856300</td>\n",
       "      <td>268.337952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-21</th>\n",
       "      <td>269.50000</td>\n",
       "      <td>262.940002</td>\n",
       "      <td>269.220001</td>\n",
       "      <td>264.679993</td>\n",
       "      <td>1140200</td>\n",
       "      <td>262.389832</td>\n",
       "      <td>268.337952</td>\n",
       "      <td>-0.022416</td>\n",
       "      <td>0.977833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 High         Low        Open       Close   Volume  \\\n",
       "Date                                                                 \n",
       "2020-02-20  273.51001  266.839996  272.890015  270.679993   856300   \n",
       "2020-02-21  269.50000  262.940002  269.220001  264.679993  1140200   \n",
       "\n",
       "             Adj Close  Prev Close  log_return  perc_return  \n",
       "Date                                                         \n",
       "2020-02-20  268.337952         NaN         NaN          NaN  \n",
       "2020-02-21  262.389832  268.337952   -0.022416     0.977833  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_index_VGT_feb20 = get_data_for_multiple_stocks2([\"VGT\"],\"2020-02-21\",\"2020-02-21\")\n",
    "returns_index_VGT_feb20 = returns_index_VGT_feb20[\"VGT\"]\n",
    "returns_index_VGT_feb20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage returns without hedge: 10.098966005835134\n",
      "percentage returns with hedge: 8.124841935075514\n"
     ]
    }
   ],
   "source": [
    "portfolio_value_feb= portfolio_2020[portfolio_2020['Date']==\"2020/02/21\"]\n",
    "portfolio_value_feb=portfolio_value_feb['Portfolio_Value']\n",
    "portfolio_returns_prehedge_feb  = (portfolio_value_feb - portfolio_value_dec19)/portfolio_value_dec19*100 # percentage change in returns\n",
    "portfolio_returns_posthedge_feb =  (portfolio_value_feb - portfolio_value_dec19-cost_puts)/portfolio_value_dec19*100\n",
    "print(f\"percentage returns without hedge: {portfolio_returns_prehedge_feb.values[0]}\")\n",
    "print(f\"percentage returns with hedge: {portfolio_returns_posthedge_feb.values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expiration date: may"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>symbol_flag</th>\n",
       "      <th>exdate</th>\n",
       "      <th>last_date</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>...</th>\n",
       "      <th>sic</th>\n",
       "      <th>index_flag</th>\n",
       "      <th>exchange_d</th>\n",
       "      <th>class</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>industry_group</th>\n",
       "      <th>issuer</th>\n",
       "      <th>div_convention</th>\n",
       "      <th>exercise_style</th>\n",
       "      <th>am_set_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P205000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>P</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.45</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P210000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>2019/12/16</td>\n",
       "      <td>P</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.80</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P215000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7.40</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P220000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>2019/12/24</td>\n",
       "      <td>P</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.10</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P225000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>225.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P230000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>2019/12/09</td>\n",
       "      <td>P</td>\n",
       "      <td>230.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P235000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>235.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>9.40</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P240000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>2019/12/12</td>\n",
       "      <td>P</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>11.10</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P245000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>2019/12/02</td>\n",
       "      <td>P</td>\n",
       "      <td>245.0</td>\n",
       "      <td>5.20</td>\n",
       "      <td>13.20</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P250000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>250.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>15.60</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P255000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>255.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>18.50</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P260000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>260.0</td>\n",
       "      <td>13.50</td>\n",
       "      <td>21.90</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P265000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>265.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>25.70</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P270000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>270.0</td>\n",
       "      <td>21.50</td>\n",
       "      <td>29.80</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P275000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>275.0</td>\n",
       "      <td>27.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P280000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>280.0</td>\n",
       "      <td>31.50</td>\n",
       "      <td>40.50</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P285000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>285.0</td>\n",
       "      <td>35.60</td>\n",
       "      <td>45.50</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P290000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>290.0</td>\n",
       "      <td>40.60</td>\n",
       "      <td>50.50</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P295000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>295.0</td>\n",
       "      <td>45.60</td>\n",
       "      <td>55.50</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P300000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>2019/12/20</td>\n",
       "      <td>P</td>\n",
       "      <td>300.0</td>\n",
       "      <td>50.60</td>\n",
       "      <td>60.50</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     secid        date             symbol  symbol_flag      exdate  \\\n",
       "60  120145  2019/12/31  VGT 200515P205000            1  2020/05/15   \n",
       "61  120145  2019/12/31  VGT 200515P210000            1  2020/05/15   \n",
       "62  120145  2019/12/31  VGT 200515P215000            1  2020/05/15   \n",
       "63  120145  2019/12/31  VGT 200515P220000            1  2020/05/15   \n",
       "64  120145  2019/12/31  VGT 200515P225000            1  2020/05/15   \n",
       "65  120145  2019/12/31  VGT 200515P230000            1  2020/05/15   \n",
       "66  120145  2019/12/31  VGT 200515P235000            1  2020/05/15   \n",
       "67  120145  2019/12/31  VGT 200515P240000            1  2020/05/15   \n",
       "68  120145  2019/12/31  VGT 200515P245000            1  2020/05/15   \n",
       "69  120145  2019/12/31  VGT 200515P250000            1  2020/05/15   \n",
       "70  120145  2019/12/31  VGT 200515P255000            1  2020/05/15   \n",
       "71  120145  2019/12/31  VGT 200515P260000            1  2020/05/15   \n",
       "72  120145  2019/12/31  VGT 200515P265000            1  2020/05/15   \n",
       "73  120145  2019/12/31  VGT 200515P270000            1  2020/05/15   \n",
       "74  120145  2019/12/31  VGT 200515P275000            1  2020/05/15   \n",
       "75  120145  2019/12/31  VGT 200515P280000            1  2020/05/15   \n",
       "76  120145  2019/12/31  VGT 200515P285000            1  2020/05/15   \n",
       "77  120145  2019/12/31  VGT 200515P290000            1  2020/05/15   \n",
       "78  120145  2019/12/31  VGT 200515P295000            1  2020/05/15   \n",
       "79  120145  2019/12/31  VGT 200515P300000            1  2020/05/15   \n",
       "\n",
       "     last_date cp_flag  strike_price  best_bid  best_offer  ...   sic  \\\n",
       "60  2019/12/31       P         205.0      1.75        2.45  ...  6722   \n",
       "61  2019/12/16       P         210.0      0.05        6.80  ...  6722   \n",
       "62         NaN       P         215.0      0.05        7.40  ...  6722   \n",
       "63  2019/12/24       P         220.0      0.05        8.10  ...  6722   \n",
       "64         NaN       P         225.0      0.05        9.00  ...  6722   \n",
       "65  2019/12/09       P         230.0      1.00       10.00  ...  6722   \n",
       "66         NaN       P         235.0      1.85        9.40  ...  6722   \n",
       "67  2019/12/12       P         240.0      3.30       11.10  ...  6722   \n",
       "68  2019/12/02       P         245.0      5.20       13.20  ...  6722   \n",
       "69         NaN       P         250.0      7.50       15.60  ...  6722   \n",
       "70         NaN       P         255.0     10.50       18.50  ...  6722   \n",
       "71         NaN       P         260.0     13.50       21.90  ...  6722   \n",
       "72         NaN       P         265.0     17.50       25.70  ...  6722   \n",
       "73         NaN       P         270.0     21.50       29.80  ...  6722   \n",
       "74         NaN       P         275.0     27.00       36.00  ...  6722   \n",
       "75         NaN       P         280.0     31.50       40.50  ...  6722   \n",
       "76         NaN       P         285.0     35.60       45.50  ...  6722   \n",
       "77         NaN       P         290.0     40.60       50.50  ...  6722   \n",
       "78         NaN       P         295.0     45.60       55.50  ...  6722   \n",
       "79  2019/12/20       P         300.0     50.60       60.50  ...  6722   \n",
       "\n",
       "    index_flag  exchange_d  class  issue_type  industry_group  \\\n",
       "60           0           1    NaN           %             426   \n",
       "61           0           1    NaN           %             426   \n",
       "62           0           1    NaN           %             426   \n",
       "63           0           1    NaN           %             426   \n",
       "64           0           1    NaN           %             426   \n",
       "65           0           1    NaN           %             426   \n",
       "66           0           1    NaN           %             426   \n",
       "67           0           1    NaN           %             426   \n",
       "68           0           1    NaN           %             426   \n",
       "69           0           1    NaN           %             426   \n",
       "70           0           1    NaN           %             426   \n",
       "71           0           1    NaN           %             426   \n",
       "72           0           1    NaN           %             426   \n",
       "73           0           1    NaN           %             426   \n",
       "74           0           1    NaN           %             426   \n",
       "75           0           1    NaN           %             426   \n",
       "76           0           1    NaN           %             426   \n",
       "77           0           1    NaN           %             426   \n",
       "78           0           1    NaN           %             426   \n",
       "79           0           1    NaN           %             426   \n",
       "\n",
       "                issuer  div_convention  exercise_style  am_set_flag  \n",
       "60  VANGUARD WORLD FDS             NaN               A            0  \n",
       "61  VANGUARD WORLD FDS             NaN               A            0  \n",
       "62  VANGUARD WORLD FDS             NaN               A            0  \n",
       "63  VANGUARD WORLD FDS             NaN               A            0  \n",
       "64  VANGUARD WORLD FDS             NaN               A            0  \n",
       "65  VANGUARD WORLD FDS             NaN               A            0  \n",
       "66  VANGUARD WORLD FDS             NaN               A            0  \n",
       "67  VANGUARD WORLD FDS             NaN               A            0  \n",
       "68  VANGUARD WORLD FDS             NaN               A            0  \n",
       "69  VANGUARD WORLD FDS             NaN               A            0  \n",
       "70  VANGUARD WORLD FDS             NaN               A            0  \n",
       "71  VANGUARD WORLD FDS             NaN               A            0  \n",
       "72  VANGUARD WORLD FDS             NaN               A            0  \n",
       "73  VANGUARD WORLD FDS             NaN               A            0  \n",
       "74  VANGUARD WORLD FDS             NaN               A            0  \n",
       "75  VANGUARD WORLD FDS             NaN               A            0  \n",
       "76  VANGUARD WORLD FDS             NaN               A            0  \n",
       "77  VANGUARD WORLD FDS             NaN               A            0  \n",
       "78  VANGUARD WORLD FDS             NaN               A            0  \n",
       "79  VANGUARD WORLD FDS             NaN               A            0  \n",
       "\n",
       "[20 rows x 38 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_options_VGT_may= index_options_VGT[index_options_VGT['exdate']==\"2020/05/15\"]\n",
    "index_options_VGT_may"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>symbol_flag</th>\n",
       "      <th>exdate</th>\n",
       "      <th>last_date</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>...</th>\n",
       "      <th>sic</th>\n",
       "      <th>index_flag</th>\n",
       "      <th>exchange_d</th>\n",
       "      <th>class</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>industry_group</th>\n",
       "      <th>issuer</th>\n",
       "      <th>div_convention</th>\n",
       "      <th>exercise_style</th>\n",
       "      <th>am_set_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200515P240000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/05/15</td>\n",
       "      <td>2019/12/12</td>\n",
       "      <td>P</td>\n",
       "      <td>240.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>11.1</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     secid        date             symbol  symbol_flag      exdate  \\\n",
       "67  120145  2019/12/31  VGT 200515P240000            1  2020/05/15   \n",
       "\n",
       "     last_date cp_flag  strike_price  best_bid  best_offer  ...   sic  \\\n",
       "67  2019/12/12       P         240.0       3.3        11.1  ...  6722   \n",
       "\n",
       "    index_flag  exchange_d  class  issue_type  industry_group  \\\n",
       "67           0           1    NaN           %             426   \n",
       "\n",
       "                issuer  div_convention  exercise_style  am_set_flag  \n",
       "67  VANGUARD WORLD FDS             NaN               A            0  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_options_VGT_may[index_options_VGT_may['strike_price']==240.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251893443.29999998"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_puts = amt_put*11.1\n",
    "cost_puts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Prev Close</th>\n",
       "      <th>log_return</th>\n",
       "      <th>perc_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>246.500000</td>\n",
       "      <td>238.580002</td>\n",
       "      <td>241.309998</td>\n",
       "      <td>246.229996</td>\n",
       "      <td>799800</td>\n",
       "      <td>245.046341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>247.679993</td>\n",
       "      <td>242.100006</td>\n",
       "      <td>242.770004</td>\n",
       "      <td>247.679993</td>\n",
       "      <td>665300</td>\n",
       "      <td>246.489365</td>\n",
       "      <td>245.046341</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>1.005889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close  Volume  \\\n",
       "Date                                                                 \n",
       "2020-05-14  246.500000  238.580002  241.309998  246.229996  799800   \n",
       "2020-05-15  247.679993  242.100006  242.770004  247.679993  665300   \n",
       "\n",
       "             Adj Close  Prev Close  log_return  perc_return  \n",
       "Date                                                         \n",
       "2020-05-14  245.046341         NaN         NaN          NaN  \n",
       "2020-05-15  246.489365  245.046341    0.005872     1.005889  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_index_VGT_may20 = get_data_for_multiple_stocks2([\"VGT\"],\"2020-05-15\",\"2020-05-15\")\n",
    "returns_index_VGT_may20 = returns_index_VGT_may20[\"VGT\"]\n",
    "returns_index_VGT_may20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage returns without hedge: 7.4338369894910885\n",
      "percentage returns with hedge: 2.6701897752667856\n"
     ]
    }
   ],
   "source": [
    "portfolio_value_may= portfolio_2020[portfolio_2020['Date']==\"2020/05/15\"]\n",
    "portfolio_value_may=portfolio_value_may['Portfolio_Value']\n",
    "portfolio_returns_prehedge_may  = (portfolio_value_may - portfolio_value_dec19)/portfolio_value_dec19*100 # percentage change in returns\n",
    "portfolio_returns_posthedge_may =  (portfolio_value_may - portfolio_value_dec19-cost_puts)/portfolio_value_dec19*100\n",
    "print(f\"percentage returns without hedge: {portfolio_returns_prehedge_may.values[0]}\")\n",
    "print(f\"percentage returns with hedge: {portfolio_returns_posthedge_may.values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### expiration date: aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>symbol_flag</th>\n",
       "      <th>exdate</th>\n",
       "      <th>last_date</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>...</th>\n",
       "      <th>sic</th>\n",
       "      <th>index_flag</th>\n",
       "      <th>exchange_d</th>\n",
       "      <th>class</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>industry_group</th>\n",
       "      <th>issuer</th>\n",
       "      <th>div_convention</th>\n",
       "      <th>exercise_style</th>\n",
       "      <th>am_set_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200821P235000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/08/21</td>\n",
       "      <td>2019/12/27</td>\n",
       "      <td>P</td>\n",
       "      <td>235.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200821P240000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/08/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>240.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200821P245000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/08/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>245.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200821P250000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/08/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>250.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>18.7</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200821P255000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/08/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>255.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>21.5</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     secid        date             symbol  symbol_flag      exdate  \\\n",
       "85  120145  2019/12/31  VGT 200821P235000            1  2020/08/21   \n",
       "86  120145  2019/12/31  VGT 200821P240000            1  2020/08/21   \n",
       "87  120145  2019/12/31  VGT 200821P245000            1  2020/08/21   \n",
       "88  120145  2019/12/31  VGT 200821P250000            1  2020/08/21   \n",
       "89  120145  2019/12/31  VGT 200821P255000            1  2020/08/21   \n",
       "\n",
       "     last_date cp_flag  strike_price  best_bid  best_offer  ...   sic  \\\n",
       "85  2019/12/27       P         235.0       4.5        12.5  ...  6722   \n",
       "86         NaN       P         240.0       6.0        14.3  ...  6722   \n",
       "87         NaN       P         245.0       8.0        16.4  ...  6722   \n",
       "88         NaN       P         250.0      10.5        18.7  ...  6722   \n",
       "89         NaN       P         255.0      13.5        21.5  ...  6722   \n",
       "\n",
       "    index_flag  exchange_d  class  issue_type  industry_group  \\\n",
       "85           0           1    NaN           %             426   \n",
       "86           0           1    NaN           %             426   \n",
       "87           0           1    NaN           %             426   \n",
       "88           0           1    NaN           %             426   \n",
       "89           0           1    NaN           %             426   \n",
       "\n",
       "                issuer  div_convention  exercise_style  am_set_flag  \n",
       "85  VANGUARD WORLD FDS             NaN               A            0  \n",
       "86  VANGUARD WORLD FDS             NaN               A            0  \n",
       "87  VANGUARD WORLD FDS             NaN               A            0  \n",
       "88  VANGUARD WORLD FDS             NaN               A            0  \n",
       "89  VANGUARD WORLD FDS             NaN               A            0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index_options_VGT_aug= index_options_VGT[index_options_VGT['exdate']==\"2020/08/21\"]\n",
    "index_options_VGT_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>secid</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>symbol_flag</th>\n",
       "      <th>exdate</th>\n",
       "      <th>last_date</th>\n",
       "      <th>cp_flag</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>best_bid</th>\n",
       "      <th>best_offer</th>\n",
       "      <th>...</th>\n",
       "      <th>sic</th>\n",
       "      <th>index_flag</th>\n",
       "      <th>exchange_d</th>\n",
       "      <th>class</th>\n",
       "      <th>issue_type</th>\n",
       "      <th>industry_group</th>\n",
       "      <th>issuer</th>\n",
       "      <th>div_convention</th>\n",
       "      <th>exercise_style</th>\n",
       "      <th>am_set_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>120145</td>\n",
       "      <td>2019/12/31</td>\n",
       "      <td>VGT 200821P240000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020/08/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>240.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>...</td>\n",
       "      <td>6722</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>%</td>\n",
       "      <td>426</td>\n",
       "      <td>VANGUARD WORLD FDS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     secid        date             symbol  symbol_flag      exdate last_date  \\\n",
       "86  120145  2019/12/31  VGT 200821P240000            1  2020/08/21       NaN   \n",
       "\n",
       "   cp_flag  strike_price  best_bid  best_offer  ...   sic  index_flag  \\\n",
       "86       P         240.0       6.0        14.3  ...  6722           0   \n",
       "\n",
       "    exchange_d  class  issue_type  industry_group              issuer  \\\n",
       "86           1    NaN           %             426  VANGUARD WORLD FDS   \n",
       "\n",
       "    div_convention  exercise_style  am_set_flag  \n",
       "86             NaN               A            0  \n",
       "\n",
       "[1 rows x 38 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_options_VGT_aug[index_options_VGT_aug['strike_price']==240.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324511372.90000004"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_puts = amt_put*14.3\n",
    "cost_puts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Prev Close</th>\n",
       "      <th>log_return</th>\n",
       "      <th>perc_return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-08-20</th>\n",
       "      <td>310.929993</td>\n",
       "      <td>304.820007</td>\n",
       "      <td>305.540009</td>\n",
       "      <td>310.359985</td>\n",
       "      <td>457800</td>\n",
       "      <td>309.634796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-21</th>\n",
       "      <td>314.040009</td>\n",
       "      <td>310.559998</td>\n",
       "      <td>310.769989</td>\n",
       "      <td>313.589996</td>\n",
       "      <td>645400</td>\n",
       "      <td>312.857269</td>\n",
       "      <td>309.634796</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>1.010407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close  Volume  \\\n",
       "Date                                                                 \n",
       "2020-08-20  310.929993  304.820007  305.540009  310.359985  457800   \n",
       "2020-08-21  314.040009  310.559998  310.769989  313.589996  645400   \n",
       "\n",
       "             Adj Close  Prev Close  log_return  perc_return  \n",
       "Date                                                         \n",
       "2020-08-20  309.634796         NaN         NaN          NaN  \n",
       "2020-08-21  312.857269  309.634796    0.010354     1.010407  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_index_VGT_aug20 = get_data_for_multiple_stocks2([\"VGT\"],\"2020-08-21\",\"2020-08-21\")\n",
    "returns_index_VGT_aug20 = returns_index_VGT_aug20[\"VGT\"]\n",
    "returns_index_VGT_aug20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage returns without hedge: 47.54135412594735\n",
      "percentage returns with hedge: 41.40440321032505\n"
     ]
    }
   ],
   "source": [
    "portfolio_value_aug= portfolio_2020[portfolio_2020['Date']==\"2020/08/21\"]\n",
    "portfolio_value_aug=portfolio_value_aug['Portfolio_Value']\n",
    "portfolio_returns_prehedge_aug  = (portfolio_value_aug - portfolio_value_dec19)/portfolio_value_dec19*100 # percentage change in returns\n",
    "portfolio_returns_posthedge_aug =  (portfolio_value_aug - portfolio_value_dec19-cost_puts)/portfolio_value_dec19*100\n",
    "print(f\"percentage returns without hedge: {portfolio_returns_prehedge_aug.values[0]}\")\n",
    "print(f\"percentage returns with hedge: {portfolio_returns_posthedge_aug.values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "from talib import RSI, BBANDS, MA\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL_Adj Close</th>\n",
       "      <th>MSFT_Adj Close</th>\n",
       "      <th>MA_Adj Close</th>\n",
       "      <th>V_Adj Close</th>\n",
       "      <th>FIS_Adj Close</th>\n",
       "      <th>LRCX_Adj Close</th>\n",
       "      <th>FB_Adj Close</th>\n",
       "      <th>QCOM_Adj Close</th>\n",
       "      <th>INTU_Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th>FB_log_return</th>\n",
       "      <th>QCOM_log_return</th>\n",
       "      <th>INTU_log_return</th>\n",
       "      <th>AMD_log_return</th>\n",
       "      <th>MELI_log_return</th>\n",
       "      <th>G_log_return</th>\n",
       "      <th>MDB_log_return</th>\n",
       "      <th>NXPI_log_return</th>\n",
       "      <th>Portfolio_Value</th>\n",
       "      <th>log_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>73.840042</td>\n",
       "      <td>159.352386</td>\n",
       "      <td>301.763092</td>\n",
       "      <td>190.237000</td>\n",
       "      <td>138.857864</td>\n",
       "      <td>293.804932</td>\n",
       "      <td>209.779999</td>\n",
       "      <td>86.849091</td>\n",
       "      <td>264.151794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021831</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.016020</td>\n",
       "      <td>0.068266</td>\n",
       "      <td>0.064736</td>\n",
       "      <td>0.011553</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>5.399329e+09</td>\n",
       "      <td>0.020867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>73.122154</td>\n",
       "      <td>157.368179</td>\n",
       "      <td>298.818970</td>\n",
       "      <td>188.724014</td>\n",
       "      <td>137.984436</td>\n",
       "      <td>290.648773</td>\n",
       "      <td>208.669998</td>\n",
       "      <td>85.213745</td>\n",
       "      <td>262.385193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005305</td>\n",
       "      <td>-0.019009</td>\n",
       "      <td>-0.006710</td>\n",
       "      <td>-0.010236</td>\n",
       "      <td>-0.003925</td>\n",
       "      <td>-0.004699</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>-0.009694</td>\n",
       "      <td>5.345149e+09</td>\n",
       "      <td>-0.010085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>73.704819</td>\n",
       "      <td>157.774948</td>\n",
       "      <td>299.614655</td>\n",
       "      <td>188.315918</td>\n",
       "      <td>139.304504</td>\n",
       "      <td>285.224213</td>\n",
       "      <td>212.600006</td>\n",
       "      <td>84.714340</td>\n",
       "      <td>264.399872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>-0.005878</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>-0.004330</td>\n",
       "      <td>-0.002059</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.037787</td>\n",
       "      <td>-0.007095</td>\n",
       "      <td>5.369933e+09</td>\n",
       "      <td>0.004626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>73.358185</td>\n",
       "      <td>156.336395</td>\n",
       "      <td>298.600159</td>\n",
       "      <td>187.818222</td>\n",
       "      <td>137.160599</td>\n",
       "      <td>292.177490</td>\n",
       "      <td>213.059998</td>\n",
       "      <td>87.123276</td>\n",
       "      <td>264.459442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.028039</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>-0.002897</td>\n",
       "      <td>0.029965</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>0.012891</td>\n",
       "      <td>5.352383e+09</td>\n",
       "      <td>-0.003274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>74.538239</td>\n",
       "      <td>158.826569</td>\n",
       "      <td>303.868805</td>\n",
       "      <td>191.033295</td>\n",
       "      <td>139.175476</td>\n",
       "      <td>295.856354</td>\n",
       "      <td>215.220001</td>\n",
       "      <td>86.868675</td>\n",
       "      <td>270.821075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>-0.002927</td>\n",
       "      <td>0.023770</td>\n",
       "      <td>-0.008743</td>\n",
       "      <td>0.013414</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>5.429361e+09</td>\n",
       "      <td>0.014280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>318.059998</td>\n",
       "      <td>193.070007</td>\n",
       "      <td>139.419998</td>\n",
       "      <td>347.630005</td>\n",
       "      <td>277.109985</td>\n",
       "      <td>126.199997</td>\n",
       "      <td>328.089996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027338</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.019110</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>-0.023690</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>-0.032373</td>\n",
       "      <td>-0.016834</td>\n",
       "      <td>7.530051e+09</td>\n",
       "      <td>-0.015019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>317.109985</td>\n",
       "      <td>190.059998</td>\n",
       "      <td>137.860001</td>\n",
       "      <td>343.829987</td>\n",
       "      <td>283.290009</td>\n",
       "      <td>125.910004</td>\n",
       "      <td>330.269989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022057</td>\n",
       "      <td>-0.002301</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>-0.041593</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>-0.007057</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>7.597413e+09</td>\n",
       "      <td>0.008906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>291.380005</td>\n",
       "      <td>180.869995</td>\n",
       "      <td>132.509995</td>\n",
       "      <td>338.899994</td>\n",
       "      <td>267.670013</td>\n",
       "      <td>121.580002</td>\n",
       "      <td>318.510010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056716</td>\n",
       "      <td>-0.034995</td>\n",
       "      <td>-0.036257</td>\n",
       "      <td>-0.031945</td>\n",
       "      <td>-0.006948</td>\n",
       "      <td>-0.037228</td>\n",
       "      <td>-0.016404</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>7.257499e+09</td>\n",
       "      <td>-0.045773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>293.179993</td>\n",
       "      <td>184.869995</td>\n",
       "      <td>125.019997</td>\n",
       "      <td>353.260010</td>\n",
       "      <td>280.829987</td>\n",
       "      <td>126.440002</td>\n",
       "      <td>325.609985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047995</td>\n",
       "      <td>0.039195</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.021278</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>-0.018288</td>\n",
       "      <td>0.048140</td>\n",
       "      <td>7.431202e+09</td>\n",
       "      <td>0.023652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>288.640015</td>\n",
       "      <td>181.710007</td>\n",
       "      <td>124.589996</td>\n",
       "      <td>342.079987</td>\n",
       "      <td>263.109985</td>\n",
       "      <td>123.360001</td>\n",
       "      <td>314.679993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065177</td>\n",
       "      <td>-0.024661</td>\n",
       "      <td>-0.034144</td>\n",
       "      <td>-0.035618</td>\n",
       "      <td>-0.069156</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>-0.031112</td>\n",
       "      <td>-0.007741</td>\n",
       "      <td>7.161201e+09</td>\n",
       "      <td>-0.037010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AAPL_Adj Close  MSFT_Adj Close  MA_Adj Close  V_Adj Close  \\\n",
       "253 2020-01-02       73.840042      159.352386    301.763092   190.237000   \n",
       "254 2020-01-03       73.122154      157.368179    298.818970   188.724014   \n",
       "255 2020-01-06       73.704819      157.774948    299.614655   188.315918   \n",
       "256 2020-01-07       73.358185      156.336395    298.600159   187.818222   \n",
       "257 2020-01-08       74.538239      158.826569    303.868805   191.033295   \n",
       "..         ...             ...             ...           ...          ...   \n",
       "459 2020-10-26      114.851852      210.080002    318.059998   193.070007   \n",
       "460 2020-10-27      116.399178      213.250000    317.109985   190.059998   \n",
       "461 2020-10-28      111.008476      202.679993    291.380005   180.869995   \n",
       "462 2020-10-29      115.121384      204.720001    293.179993   184.869995   \n",
       "463 2020-10-30      108.672516      202.470001    288.640015   181.710007   \n",
       "\n",
       "     FIS_Adj Close  LRCX_Adj Close  FB_Adj Close  QCOM_Adj Close  \\\n",
       "253     138.857864      293.804932    209.779999       86.849091   \n",
       "254     137.984436      290.648773    208.669998       85.213745   \n",
       "255     139.304504      285.224213    212.600006       84.714340   \n",
       "256     137.160599      292.177490    213.059998       87.123276   \n",
       "257     139.175476      295.856354    215.220001       86.868675   \n",
       "..             ...             ...           ...             ...   \n",
       "459     139.419998      347.630005    277.109985      126.199997   \n",
       "460     137.860001      343.829987    283.290009      125.910004   \n",
       "461     132.509995      338.899994    267.670013      121.580002   \n",
       "462     125.019997      353.260010    280.829987      126.440002   \n",
       "463     124.589996      342.079987    263.109985      123.360001   \n",
       "\n",
       "     INTU_Adj Close  ...  FB_log_return  QCOM_log_return  INTU_log_return  \\\n",
       "253      264.151794  ...       0.021831         0.005200         0.016020   \n",
       "254      262.385193  ...      -0.005305        -0.019009        -0.006710   \n",
       "255      264.399872  ...       0.018658        -0.005878         0.007649   \n",
       "256      264.459442  ...       0.002161         0.028039         0.000225   \n",
       "257      270.821075  ...       0.010087        -0.002927         0.023770   \n",
       "..              ...  ...            ...              ...              ...   \n",
       "459      328.089996  ...      -0.027338        -0.021014        -0.019110   \n",
       "460      330.269989  ...       0.022057        -0.002301         0.006623   \n",
       "461      318.510010  ...      -0.056716        -0.034995        -0.036257   \n",
       "462      325.609985  ...       0.047995         0.039195         0.022046   \n",
       "463      314.679993  ...      -0.065177        -0.024661        -0.034144   \n",
       "\n",
       "     AMD_log_return  MELI_log_return  G_log_return  MDB_log_return  \\\n",
       "253        0.068266         0.064736      0.011553        0.020456   \n",
       "254       -0.010236        -0.003925     -0.004699        0.007121   \n",
       "255       -0.004330        -0.002059      0.003761        0.037787   \n",
       "256       -0.002897         0.029965     -0.000235       -0.011741   \n",
       "257       -0.008743         0.013414      0.003046        0.010103   \n",
       "..              ...              ...           ...             ...   \n",
       "459        0.003289        -0.023690     -0.039978       -0.032373   \n",
       "460       -0.041593         0.000803     -0.007057        0.016154   \n",
       "461       -0.031945        -0.006948     -0.037228       -0.016404   \n",
       "462        0.020982         0.021278      0.006448       -0.018288   \n",
       "463       -0.035618        -0.069156      0.004082       -0.031112   \n",
       "\n",
       "     NXPI_log_return  Portfolio_Value  log_return  \n",
       "253         0.010008     5.399329e+09    0.020867  \n",
       "254        -0.009694     5.345149e+09   -0.010085  \n",
       "255        -0.007095     5.369933e+09    0.004626  \n",
       "256         0.012891     5.352383e+09   -0.003274  \n",
       "257         0.002496     5.429361e+09    0.014280  \n",
       "..               ...              ...         ...  \n",
       "459        -0.016834     7.530051e+09   -0.015019  \n",
       "460        -0.012383     7.597413e+09    0.008906  \n",
       "461        -0.026313     7.257499e+09   -0.045773  \n",
       "462         0.048140     7.431202e+09    0.023652  \n",
       "463        -0.007741     7.161201e+09   -0.037010  \n",
       "\n",
       "[211 rows x 31 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on 2019 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_optimal = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]\n",
    "returns_df_train = get_data_for_multiple_stocks_daily(tickers_optimal,\n",
    "                                          start_date = \"2018-01-01\", end_date = \"2019-04-30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>MA adj_close</th>\n",
       "      <th>MA prev_close</th>\n",
       "      <th>MA log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>MELI log_returns</th>\n",
       "      <th>G adj_close</th>\n",
       "      <th>G prev_close</th>\n",
       "      <th>G log_returns</th>\n",
       "      <th>MDB adj_close</th>\n",
       "      <th>MDB prev_close</th>\n",
       "      <th>MDB log_returns</th>\n",
       "      <th>NXPI adj_close</th>\n",
       "      <th>NXPI prev_close</th>\n",
       "      <th>NXPI log_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>41.098373</td>\n",
       "      <td>41.105534</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>82.983727</td>\n",
       "      <td>82.599319</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>151.327377</td>\n",
       "      <td>149.448349</td>\n",
       "      <td>0.012495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020557</td>\n",
       "      <td>31.626640</td>\n",
       "      <td>31.539005</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>29.150000</td>\n",
       "      <td>29.250000</td>\n",
       "      <td>-0.003425</td>\n",
       "      <td>114.775658</td>\n",
       "      <td>114.649292</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>41.289268</td>\n",
       "      <td>41.098373</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>83.714119</td>\n",
       "      <td>82.983727</td>\n",
       "      <td>0.008763</td>\n",
       "      <td>153.285095</td>\n",
       "      <td>151.327377</td>\n",
       "      <td>0.012854</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010379</td>\n",
       "      <td>32.055080</td>\n",
       "      <td>31.626640</td>\n",
       "      <td>0.013456</td>\n",
       "      <td>29.049999</td>\n",
       "      <td>29.150000</td>\n",
       "      <td>-0.003436</td>\n",
       "      <td>114.571541</td>\n",
       "      <td>114.775658</td>\n",
       "      <td>-0.001780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>41.759361</td>\n",
       "      <td>41.289268</td>\n",
       "      <td>0.011321</td>\n",
       "      <td>84.752014</td>\n",
       "      <td>83.714119</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>156.462784</td>\n",
       "      <td>153.285095</td>\n",
       "      <td>0.020519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015196</td>\n",
       "      <td>32.347202</td>\n",
       "      <td>32.055080</td>\n",
       "      <td>0.009072</td>\n",
       "      <td>29.049999</td>\n",
       "      <td>29.049999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.746513</td>\n",
       "      <td>114.571541</td>\n",
       "      <td>0.001526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>41.604263</td>\n",
       "      <td>41.759361</td>\n",
       "      <td>-0.003721</td>\n",
       "      <td>84.838486</td>\n",
       "      <td>84.752014</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>156.935776</td>\n",
       "      <td>156.462784</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029541</td>\n",
       "      <td>32.697735</td>\n",
       "      <td>32.347202</td>\n",
       "      <td>0.010778</td>\n",
       "      <td>28.809999</td>\n",
       "      <td>29.049999</td>\n",
       "      <td>-0.008296</td>\n",
       "      <td>114.970078</td>\n",
       "      <td>114.746513</td>\n",
       "      <td>0.001946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>41.599483</td>\n",
       "      <td>41.604263</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>84.780838</td>\n",
       "      <td>84.838486</td>\n",
       "      <td>-0.000680</td>\n",
       "      <td>157.162399</td>\n",
       "      <td>156.935776</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>32.678265</td>\n",
       "      <td>32.697735</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>28.809999</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>115.135300</td>\n",
       "      <td>114.970078</td>\n",
       "      <td>0.001436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>50.390892</td>\n",
       "      <td>50.468727</td>\n",
       "      <td>-0.001543</td>\n",
       "      <td>122.738281</td>\n",
       "      <td>123.160469</td>\n",
       "      <td>-0.003434</td>\n",
       "      <td>243.383362</td>\n",
       "      <td>241.597366</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028379</td>\n",
       "      <td>35.788841</td>\n",
       "      <td>35.936729</td>\n",
       "      <td>-0.004124</td>\n",
       "      <td>135.160004</td>\n",
       "      <td>137.330002</td>\n",
       "      <td>-0.015928</td>\n",
       "      <td>98.159485</td>\n",
       "      <td>97.081123</td>\n",
       "      <td>0.011047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>49.933590</td>\n",
       "      <td>50.390892</td>\n",
       "      <td>-0.009117</td>\n",
       "      <td>126.803055</td>\n",
       "      <td>122.738281</td>\n",
       "      <td>0.032581</td>\n",
       "      <td>243.700882</td>\n",
       "      <td>243.383362</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>35.660664</td>\n",
       "      <td>35.788841</td>\n",
       "      <td>-0.003588</td>\n",
       "      <td>137.660004</td>\n",
       "      <td>135.160004</td>\n",
       "      <td>0.018328</td>\n",
       "      <td>95.757698</td>\n",
       "      <td>98.159485</td>\n",
       "      <td>-0.024773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>49.695210</td>\n",
       "      <td>49.933590</td>\n",
       "      <td>-0.004785</td>\n",
       "      <td>127.529594</td>\n",
       "      <td>126.803055</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>244.762558</td>\n",
       "      <td>243.700882</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>35.700108</td>\n",
       "      <td>35.660664</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>138.979996</td>\n",
       "      <td>137.660004</td>\n",
       "      <td>0.009543</td>\n",
       "      <td>97.051727</td>\n",
       "      <td>95.757698</td>\n",
       "      <td>0.013423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2019-04-29</td>\n",
       "      <td>49.770615</td>\n",
       "      <td>49.695210</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>127.411781</td>\n",
       "      <td>127.529594</td>\n",
       "      <td>-0.000924</td>\n",
       "      <td>245.209091</td>\n",
       "      <td>244.762558</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009434</td>\n",
       "      <td>35.532501</td>\n",
       "      <td>35.700108</td>\n",
       "      <td>-0.004706</td>\n",
       "      <td>137.500000</td>\n",
       "      <td>138.979996</td>\n",
       "      <td>-0.010706</td>\n",
       "      <td>95.973366</td>\n",
       "      <td>97.051727</td>\n",
       "      <td>-0.011173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>48.812218</td>\n",
       "      <td>49.770615</td>\n",
       "      <td>-0.019444</td>\n",
       "      <td>128.226700</td>\n",
       "      <td>127.411781</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>252.263809</td>\n",
       "      <td>245.209091</td>\n",
       "      <td>0.028364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020485</td>\n",
       "      <td>35.788841</td>\n",
       "      <td>35.532501</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>140.919998</td>\n",
       "      <td>137.500000</td>\n",
       "      <td>0.024568</td>\n",
       "      <td>103.541443</td>\n",
       "      <td>95.973366</td>\n",
       "      <td>0.075901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AAPL adj_close  AAPL prev_close  AAPL log_returns  \\\n",
       "0   2018-01-03       41.098373        41.105534         -0.000174   \n",
       "1   2018-01-04       41.289268        41.098373          0.004634   \n",
       "2   2018-01-05       41.759361        41.289268          0.011321   \n",
       "3   2018-01-08       41.604263        41.759361         -0.003721   \n",
       "4   2018-01-09       41.599483        41.604263         -0.000115   \n",
       "..         ...             ...              ...               ...   \n",
       "327 2019-04-24       50.390892        50.468727         -0.001543   \n",
       "328 2019-04-25       49.933590        50.390892         -0.009117   \n",
       "329 2019-04-26       49.695210        49.933590         -0.004785   \n",
       "330 2019-04-29       49.770615        49.695210          0.001516   \n",
       "331 2019-04-30       48.812218        49.770615         -0.019444   \n",
       "\n",
       "     MSFT adj_close  MSFT prev_close  MSFT log_returns  MA adj_close  \\\n",
       "0         82.983727        82.599319          0.004643    151.327377   \n",
       "1         83.714119        82.983727          0.008763    153.285095   \n",
       "2         84.752014        83.714119          0.012322    156.462784   \n",
       "3         84.838486        84.752014          0.001020    156.935776   \n",
       "4         84.780838        84.838486         -0.000680    157.162399   \n",
       "..              ...              ...               ...           ...   \n",
       "327      122.738281       123.160469         -0.003434    243.383362   \n",
       "328      126.803055       122.738281          0.032581    243.700882   \n",
       "329      127.529594       126.803055          0.005713    244.762558   \n",
       "330      127.411781       127.529594         -0.000924    245.209091   \n",
       "331      128.226700       127.411781          0.006376    252.263809   \n",
       "\n",
       "     MA prev_close  MA log_returns  ...  MELI log_returns  G adj_close  \\\n",
       "0       149.448349        0.012495  ...          0.020557    31.626640   \n",
       "1       151.327377        0.012854  ...         -0.010379    32.055080   \n",
       "2       153.285095        0.020519  ...          0.015196    32.347202   \n",
       "3       156.462784        0.003018  ...          0.029541    32.697735   \n",
       "4       156.935776        0.001443  ...         -0.009257    32.678265   \n",
       "..             ...             ...  ...               ...          ...   \n",
       "327     241.597366        0.007365  ...         -0.028379    35.788841   \n",
       "328     243.383362        0.001304  ...          0.003205    35.660664   \n",
       "329     243.700882        0.004347  ...          0.003991    35.700108   \n",
       "330     244.762558        0.001823  ...          0.009434    35.532501   \n",
       "331     245.209091        0.028364  ...         -0.020485    35.788841   \n",
       "\n",
       "     G prev_close  G log_returns  MDB adj_close  MDB prev_close  \\\n",
       "0       31.539005       0.002775      29.150000       29.250000   \n",
       "1       31.626640       0.013456      29.049999       29.150000   \n",
       "2       32.055080       0.009072      29.049999       29.049999   \n",
       "3       32.347202       0.010778      28.809999       29.049999   \n",
       "4       32.697735      -0.000596      28.790001       28.809999   \n",
       "..            ...            ...            ...             ...   \n",
       "327     35.936729      -0.004124     135.160004      137.330002   \n",
       "328     35.788841      -0.003588     137.660004      135.160004   \n",
       "329     35.660664       0.001105     138.979996      137.660004   \n",
       "330     35.700108      -0.004706     137.500000      138.979996   \n",
       "331     35.532501       0.007188     140.919998      137.500000   \n",
       "\n",
       "     MDB log_returns  NXPI adj_close  NXPI prev_close  NXPI log_returns  \n",
       "0          -0.003425      114.775658       114.649292          0.001102  \n",
       "1          -0.003436      114.571541       114.775658         -0.001780  \n",
       "2           0.000000      114.746513       114.571541          0.001526  \n",
       "3          -0.008296      114.970078       114.746513          0.001946  \n",
       "4          -0.000694      115.135300       114.970078          0.001436  \n",
       "..               ...             ...              ...               ...  \n",
       "327        -0.015928       98.159485        97.081123          0.011047  \n",
       "328         0.018328       95.757698        98.159485         -0.024773  \n",
       "329         0.009543       97.051727        95.757698          0.013423  \n",
       "330        -0.010706       95.973366        97.051727         -0.011173  \n",
       "331         0.024568      103.541443        95.973366          0.075901  \n",
       "\n",
       "[332 rows x 43 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_train.dropna(inplace = True)\n",
    "returns_df_train.reset_index(inplace=True)\n",
    "returns_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_optimal = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]\n",
    "returns_df_validation = get_data_for_multiple_stocks_daily(tickers_optimal,\n",
    "                                          start_date = \"2019-05-01\", end_date = \"2019-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>MA adj_close</th>\n",
       "      <th>MA prev_close</th>\n",
       "      <th>MA log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>MELI log_returns</th>\n",
       "      <th>G adj_close</th>\n",
       "      <th>G prev_close</th>\n",
       "      <th>G log_returns</th>\n",
       "      <th>MDB adj_close</th>\n",
       "      <th>MDB prev_close</th>\n",
       "      <th>MDB log_returns</th>\n",
       "      <th>NXPI adj_close</th>\n",
       "      <th>NXPI prev_close</th>\n",
       "      <th>NXPI log_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>51.208199</td>\n",
       "      <td>48.812218</td>\n",
       "      <td>0.047919</td>\n",
       "      <td>125.556122</td>\n",
       "      <td>128.226700</td>\n",
       "      <td>-0.021047</td>\n",
       "      <td>246.816467</td>\n",
       "      <td>252.263809</td>\n",
       "      <td>-0.021830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>35.207150</td>\n",
       "      <td>35.788841</td>\n",
       "      <td>-0.016387</td>\n",
       "      <td>133.619995</td>\n",
       "      <td>140.919998</td>\n",
       "      <td>-0.053192</td>\n",
       "      <td>102.923836</td>\n",
       "      <td>103.541443</td>\n",
       "      <td>-0.005983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>50.874950</td>\n",
       "      <td>51.208199</td>\n",
       "      <td>-0.006529</td>\n",
       "      <td>123.916473</td>\n",
       "      <td>125.556122</td>\n",
       "      <td>-0.013145</td>\n",
       "      <td>245.268600</td>\n",
       "      <td>246.816467</td>\n",
       "      <td>-0.006291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004922</td>\n",
       "      <td>35.453625</td>\n",
       "      <td>35.207150</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>132.360001</td>\n",
       "      <td>133.619995</td>\n",
       "      <td>-0.009474</td>\n",
       "      <td>104.502151</td>\n",
       "      <td>102.923836</td>\n",
       "      <td>0.015218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>51.507393</td>\n",
       "      <td>50.874950</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>126.557594</td>\n",
       "      <td>123.916473</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>246.022705</td>\n",
       "      <td>245.268600</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182529</td>\n",
       "      <td>35.818417</td>\n",
       "      <td>35.453625</td>\n",
       "      <td>0.010237</td>\n",
       "      <td>134.460007</td>\n",
       "      <td>132.360001</td>\n",
       "      <td>0.015741</td>\n",
       "      <td>105.953033</td>\n",
       "      <td>104.502151</td>\n",
       "      <td>0.013788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>50.711975</td>\n",
       "      <td>51.507393</td>\n",
       "      <td>-0.015563</td>\n",
       "      <td>125.821205</td>\n",
       "      <td>126.557594</td>\n",
       "      <td>-0.005836</td>\n",
       "      <td>246.707321</td>\n",
       "      <td>246.022705</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019623</td>\n",
       "      <td>35.739544</td>\n",
       "      <td>35.818417</td>\n",
       "      <td>-0.002204</td>\n",
       "      <td>136.490005</td>\n",
       "      <td>134.460007</td>\n",
       "      <td>0.014985</td>\n",
       "      <td>103.933563</td>\n",
       "      <td>105.953033</td>\n",
       "      <td>-0.019244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-05-07</td>\n",
       "      <td>49.344929</td>\n",
       "      <td>50.711975</td>\n",
       "      <td>-0.027327</td>\n",
       "      <td>123.239006</td>\n",
       "      <td>125.821205</td>\n",
       "      <td>-0.020736</td>\n",
       "      <td>243.155167</td>\n",
       "      <td>246.707321</td>\n",
       "      <td>-0.014503</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051100</td>\n",
       "      <td>35.493065</td>\n",
       "      <td>35.739544</td>\n",
       "      <td>-0.006920</td>\n",
       "      <td>133.279999</td>\n",
       "      <td>136.490005</td>\n",
       "      <td>-0.023799</td>\n",
       "      <td>100.443626</td>\n",
       "      <td>103.933563</td>\n",
       "      <td>-0.034155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>69.886818</td>\n",
       "      <td>69.820442</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>156.137955</td>\n",
       "      <td>156.167740</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>295.884796</td>\n",
       "      <td>295.675903</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>42.035564</td>\n",
       "      <td>42.075264</td>\n",
       "      <td>-0.000944</td>\n",
       "      <td>132.550003</td>\n",
       "      <td>132.360001</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>127.816917</td>\n",
       "      <td>126.659447</td>\n",
       "      <td>0.009097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>71.273392</td>\n",
       "      <td>69.886818</td>\n",
       "      <td>0.019646</td>\n",
       "      <td>157.417786</td>\n",
       "      <td>156.137955</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>297.595612</td>\n",
       "      <td>295.884796</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>42.243958</td>\n",
       "      <td>42.035564</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>135.020004</td>\n",
       "      <td>132.550003</td>\n",
       "      <td>0.018463</td>\n",
       "      <td>127.302475</td>\n",
       "      <td>127.816917</td>\n",
       "      <td>-0.004033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>71.246353</td>\n",
       "      <td>71.273392</td>\n",
       "      <td>-0.000379</td>\n",
       "      <td>157.705505</td>\n",
       "      <td>157.417786</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>299.127319</td>\n",
       "      <td>297.595612</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>42.065338</td>\n",
       "      <td>42.243958</td>\n",
       "      <td>-0.004237</td>\n",
       "      <td>134.130005</td>\n",
       "      <td>135.020004</td>\n",
       "      <td>-0.006613</td>\n",
       "      <td>126.817734</td>\n",
       "      <td>127.302475</td>\n",
       "      <td>-0.003815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>71.669212</td>\n",
       "      <td>71.246353</td>\n",
       "      <td>0.005918</td>\n",
       "      <td>156.346298</td>\n",
       "      <td>157.705505</td>\n",
       "      <td>-0.008656</td>\n",
       "      <td>296.123474</td>\n",
       "      <td>299.127319</td>\n",
       "      <td>-0.010093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026018</td>\n",
       "      <td>41.797405</td>\n",
       "      <td>42.065338</td>\n",
       "      <td>-0.006390</td>\n",
       "      <td>128.929993</td>\n",
       "      <td>134.130005</td>\n",
       "      <td>-0.039540</td>\n",
       "      <td>126.184578</td>\n",
       "      <td>126.817734</td>\n",
       "      <td>-0.005005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>72.192863</td>\n",
       "      <td>71.669212</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>156.455429</td>\n",
       "      <td>156.346298</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>296.988831</td>\n",
       "      <td>296.123474</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020610</td>\n",
       "      <td>41.847019</td>\n",
       "      <td>41.797405</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>131.610001</td>\n",
       "      <td>128.929993</td>\n",
       "      <td>0.020573</td>\n",
       "      <td>125.897690</td>\n",
       "      <td>126.184578</td>\n",
       "      <td>-0.002276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AAPL adj_close  AAPL prev_close  AAPL log_returns  \\\n",
       "0   2019-05-01       51.208199        48.812218          0.047919   \n",
       "1   2019-05-02       50.874950        51.208199         -0.006529   \n",
       "2   2019-05-03       51.507393        50.874950          0.012355   \n",
       "3   2019-05-06       50.711975        51.507393         -0.015563   \n",
       "4   2019-05-07       49.344929        50.711975         -0.027327   \n",
       "..         ...             ...              ...               ...   \n",
       "165 2019-12-24       69.886818        69.820442          0.000950   \n",
       "166 2019-12-26       71.273392        69.886818          0.019646   \n",
       "167 2019-12-27       71.246353        71.273392         -0.000379   \n",
       "168 2019-12-30       71.669212        71.246353          0.005918   \n",
       "169 2019-12-31       72.192863        71.669212          0.007280   \n",
       "\n",
       "     MSFT adj_close  MSFT prev_close  MSFT log_returns  MA adj_close  \\\n",
       "0        125.556122       128.226700         -0.021047    246.816467   \n",
       "1        123.916473       125.556122         -0.013145    245.268600   \n",
       "2        126.557594       123.916473          0.021090    246.022705   \n",
       "3        125.821205       126.557594         -0.005836    246.707321   \n",
       "4        123.239006       125.821205         -0.020736    243.155167   \n",
       "..              ...              ...               ...           ...   \n",
       "165      156.137955       156.167740         -0.000191    295.884796   \n",
       "166      157.417786       156.137955          0.008163    297.595612   \n",
       "167      157.705505       157.417786          0.001826    299.127319   \n",
       "168      156.346298       157.705505         -0.008656    296.123474   \n",
       "169      156.455429       156.346298          0.000698    296.988831   \n",
       "\n",
       "     MA prev_close  MA log_returns  ...  MELI log_returns  G adj_close  \\\n",
       "0       252.263809       -0.021830  ...          0.001218    35.207150   \n",
       "1       246.816467       -0.006291  ...         -0.004922    35.453625   \n",
       "2       245.268600        0.003070  ...          0.182529    35.818417   \n",
       "3       246.022705        0.002779  ...         -0.019623    35.739544   \n",
       "4       246.707321       -0.014503  ...         -0.051100    35.493065   \n",
       "..             ...             ...  ...               ...          ...   \n",
       "165     295.675903        0.000706  ...          0.000639    42.035564   \n",
       "166     295.884796        0.005765  ...          0.004548    42.243958   \n",
       "167     297.595612        0.005134  ...          0.003343    42.065338   \n",
       "168     299.127319       -0.010093  ...         -0.026018    41.797405   \n",
       "169     296.123474        0.002918  ...         -0.020610    41.847019   \n",
       "\n",
       "     G prev_close  G log_returns  MDB adj_close  MDB prev_close  \\\n",
       "0       35.788841      -0.016387     133.619995      140.919998   \n",
       "1       35.207150       0.006976     132.360001      133.619995   \n",
       "2       35.453625       0.010237     134.460007      132.360001   \n",
       "3       35.818417      -0.002204     136.490005      134.460007   \n",
       "4       35.739544      -0.006920     133.279999      136.490005   \n",
       "..            ...            ...            ...             ...   \n",
       "165     42.075264      -0.000944     132.550003      132.360001   \n",
       "166     42.035564       0.004945     135.020004      132.550003   \n",
       "167     42.243958      -0.004237     134.130005      135.020004   \n",
       "168     42.065338      -0.006390     128.929993      134.130005   \n",
       "169     41.797405       0.001186     131.610001      128.929993   \n",
       "\n",
       "     MDB log_returns  NXPI adj_close  NXPI prev_close  NXPI log_returns  \n",
       "0          -0.053192      102.923836       103.541443         -0.005983  \n",
       "1          -0.009474      104.502151       102.923836          0.015218  \n",
       "2           0.015741      105.953033       104.502151          0.013788  \n",
       "3           0.014985      103.933563       105.953033         -0.019244  \n",
       "4          -0.023799      100.443626       103.933563         -0.034155  \n",
       "..               ...             ...              ...               ...  \n",
       "165         0.001434      127.816917       126.659447          0.009097  \n",
       "166         0.018463      127.302475       127.816917         -0.004033  \n",
       "167        -0.006613      126.817734       127.302475         -0.003815  \n",
       "168        -0.039540      126.184578       126.817734         -0.005005  \n",
       "169         0.020573      125.897690       126.184578         -0.002276  \n",
       "\n",
       "[170 rows x 43 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_validation.dropna(inplace = True)\n",
    "returns_df_validation.reset_index(inplace=True)\n",
    "returns_df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_optimal = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]\n",
    "returns_df_test = get_data_for_multiple_stocks_daily(tickers_optimal,\n",
    "                                          start_date = \"2020-01-01\", end_date = \"2020-10-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL adj_close</th>\n",
       "      <th>AAPL prev_close</th>\n",
       "      <th>AAPL log_returns</th>\n",
       "      <th>MSFT adj_close</th>\n",
       "      <th>MSFT prev_close</th>\n",
       "      <th>MSFT log_returns</th>\n",
       "      <th>MA adj_close</th>\n",
       "      <th>MA prev_close</th>\n",
       "      <th>MA log_returns</th>\n",
       "      <th>...</th>\n",
       "      <th>MELI log_returns</th>\n",
       "      <th>G adj_close</th>\n",
       "      <th>G prev_close</th>\n",
       "      <th>G log_returns</th>\n",
       "      <th>MDB adj_close</th>\n",
       "      <th>MDB prev_close</th>\n",
       "      <th>MDB log_returns</th>\n",
       "      <th>NXPI adj_close</th>\n",
       "      <th>NXPI prev_close</th>\n",
       "      <th>NXPI log_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>73.840042</td>\n",
       "      <td>72.192863</td>\n",
       "      <td>0.022560</td>\n",
       "      <td>159.352386</td>\n",
       "      <td>156.455429</td>\n",
       "      <td>0.018347</td>\n",
       "      <td>301.763092</td>\n",
       "      <td>296.988831</td>\n",
       "      <td>0.015948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064736</td>\n",
       "      <td>42.333267</td>\n",
       "      <td>41.847019</td>\n",
       "      <td>0.011553</td>\n",
       "      <td>134.330002</td>\n",
       "      <td>131.610001</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>127.163986</td>\n",
       "      <td>125.897690</td>\n",
       "      <td>0.010008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>73.122154</td>\n",
       "      <td>73.840042</td>\n",
       "      <td>-0.009770</td>\n",
       "      <td>157.368179</td>\n",
       "      <td>159.352386</td>\n",
       "      <td>-0.012530</td>\n",
       "      <td>298.818970</td>\n",
       "      <td>301.763092</td>\n",
       "      <td>-0.009804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003925</td>\n",
       "      <td>42.134800</td>\n",
       "      <td>42.333267</td>\n",
       "      <td>-0.004699</td>\n",
       "      <td>135.289993</td>\n",
       "      <td>134.330002</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>125.937263</td>\n",
       "      <td>127.163986</td>\n",
       "      <td>-0.009694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>73.704819</td>\n",
       "      <td>73.122154</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>157.774948</td>\n",
       "      <td>157.368179</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>299.614655</td>\n",
       "      <td>298.818970</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002059</td>\n",
       "      <td>42.293575</td>\n",
       "      <td>42.134800</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>135.289993</td>\n",
       "      <td>0.037787</td>\n",
       "      <td>125.046890</td>\n",
       "      <td>125.937263</td>\n",
       "      <td>-0.007095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>73.358185</td>\n",
       "      <td>73.704819</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>156.336395</td>\n",
       "      <td>157.774948</td>\n",
       "      <td>-0.009160</td>\n",
       "      <td>298.600159</td>\n",
       "      <td>299.614655</td>\n",
       "      <td>-0.003392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029965</td>\n",
       "      <td>42.283653</td>\n",
       "      <td>42.293575</td>\n",
       "      <td>-0.000235</td>\n",
       "      <td>138.860001</td>\n",
       "      <td>140.500000</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>126.669334</td>\n",
       "      <td>125.046890</td>\n",
       "      <td>0.012891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>74.538239</td>\n",
       "      <td>73.358185</td>\n",
       "      <td>0.015958</td>\n",
       "      <td>158.826569</td>\n",
       "      <td>156.336395</td>\n",
       "      <td>0.015803</td>\n",
       "      <td>303.868805</td>\n",
       "      <td>298.600159</td>\n",
       "      <td>0.017491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013414</td>\n",
       "      <td>42.412659</td>\n",
       "      <td>42.283653</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>140.270004</td>\n",
       "      <td>138.860001</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>126.985916</td>\n",
       "      <td>126.669334</td>\n",
       "      <td>0.002496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>114.841873</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>216.229996</td>\n",
       "      <td>-0.028854</td>\n",
       "      <td>318.059998</td>\n",
       "      <td>329.609985</td>\n",
       "      <td>-0.035670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023690</td>\n",
       "      <td>35.549999</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>240.100006</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>-0.032373</td>\n",
       "      <td>134.889999</td>\n",
       "      <td>137.179993</td>\n",
       "      <td>-0.016834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>0.013382</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>317.109985</td>\n",
       "      <td>318.059998</td>\n",
       "      <td>-0.002991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>35.549999</td>\n",
       "      <td>-0.007057</td>\n",
       "      <td>244.009995</td>\n",
       "      <td>240.100006</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>133.229996</td>\n",
       "      <td>134.889999</td>\n",
       "      <td>-0.012383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>-0.047419</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>-0.050837</td>\n",
       "      <td>291.380005</td>\n",
       "      <td>317.109985</td>\n",
       "      <td>-0.084620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006948</td>\n",
       "      <td>34.009998</td>\n",
       "      <td>35.299999</td>\n",
       "      <td>-0.037228</td>\n",
       "      <td>240.039993</td>\n",
       "      <td>244.009995</td>\n",
       "      <td>-0.016404</td>\n",
       "      <td>129.770004</td>\n",
       "      <td>133.229996</td>\n",
       "      <td>-0.026313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>0.036381</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>0.010015</td>\n",
       "      <td>293.179993</td>\n",
       "      <td>291.380005</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021278</td>\n",
       "      <td>34.230000</td>\n",
       "      <td>34.009998</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>235.690002</td>\n",
       "      <td>240.039993</td>\n",
       "      <td>-0.018288</td>\n",
       "      <td>136.169998</td>\n",
       "      <td>129.770004</td>\n",
       "      <td>0.048140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>-0.057648</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>-0.011051</td>\n",
       "      <td>288.640015</td>\n",
       "      <td>293.179993</td>\n",
       "      <td>-0.015606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069156</td>\n",
       "      <td>34.369999</td>\n",
       "      <td>34.230000</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>228.470001</td>\n",
       "      <td>235.690002</td>\n",
       "      <td>-0.031112</td>\n",
       "      <td>135.119995</td>\n",
       "      <td>136.169998</td>\n",
       "      <td>-0.007741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AAPL adj_close  AAPL prev_close  AAPL log_returns  \\\n",
       "0   2020-01-02       73.840042        72.192863          0.022560   \n",
       "1   2020-01-03       73.122154        73.840042         -0.009770   \n",
       "2   2020-01-06       73.704819        73.122154          0.007937   \n",
       "3   2020-01-07       73.358185        73.704819         -0.004714   \n",
       "4   2020-01-08       74.538239        73.358185          0.015958   \n",
       "..         ...             ...              ...               ...   \n",
       "206 2020-10-26      114.851852       114.841873          0.000087   \n",
       "207 2020-10-27      116.399178       114.851852          0.013382   \n",
       "208 2020-10-28      111.008476       116.399178         -0.047419   \n",
       "209 2020-10-29      115.121384       111.008476          0.036381   \n",
       "210 2020-10-30      108.672516       115.121384         -0.057648   \n",
       "\n",
       "     MSFT adj_close  MSFT prev_close  MSFT log_returns  MA adj_close  \\\n",
       "0        159.352386       156.455429          0.018347    301.763092   \n",
       "1        157.368179       159.352386         -0.012530    298.818970   \n",
       "2        157.774948       157.368179          0.002581    299.614655   \n",
       "3        156.336395       157.774948         -0.009160    298.600159   \n",
       "4        158.826569       156.336395          0.015803    303.868805   \n",
       "..              ...              ...               ...           ...   \n",
       "206      210.080002       216.229996         -0.028854    318.059998   \n",
       "207      213.250000       210.080002          0.014977    317.109985   \n",
       "208      202.679993       213.250000         -0.050837    291.380005   \n",
       "209      204.720001       202.679993          0.010015    293.179993   \n",
       "210      202.470001       204.720001         -0.011051    288.640015   \n",
       "\n",
       "     MA prev_close  MA log_returns  ...  MELI log_returns  G adj_close  \\\n",
       "0       296.988831        0.015948  ...          0.064736    42.333267   \n",
       "1       301.763092       -0.009804  ...         -0.003925    42.134800   \n",
       "2       298.818970        0.002659  ...         -0.002059    42.293575   \n",
       "3       299.614655       -0.003392  ...          0.029965    42.283653   \n",
       "4       298.600159        0.017491  ...          0.013414    42.412659   \n",
       "..             ...             ...  ...               ...          ...   \n",
       "206     329.609985       -0.035670  ...         -0.023690    35.549999   \n",
       "207     318.059998       -0.002991  ...          0.000803    35.299999   \n",
       "208     317.109985       -0.084620  ...         -0.006948    34.009998   \n",
       "209     291.380005        0.006158  ...          0.021278    34.230000   \n",
       "210     293.179993       -0.015606  ...         -0.069156    34.369999   \n",
       "\n",
       "     G prev_close  G log_returns  MDB adj_close  MDB prev_close  \\\n",
       "0       41.847019       0.011553     134.330002      131.610001   \n",
       "1       42.333267      -0.004699     135.289993      134.330002   \n",
       "2       42.134800       0.003761     140.500000      135.289993   \n",
       "3       42.293575      -0.000235     138.860001      140.500000   \n",
       "4       42.283653       0.003046     140.270004      138.860001   \n",
       "..            ...            ...            ...             ...   \n",
       "206     37.000000      -0.039978     240.100006      248.000000   \n",
       "207     35.549999      -0.007057     244.009995      240.100006   \n",
       "208     35.299999      -0.037228     240.039993      244.009995   \n",
       "209     34.009998       0.006448     235.690002      240.039993   \n",
       "210     34.230000       0.004082     228.470001      235.690002   \n",
       "\n",
       "     MDB log_returns  NXPI adj_close  NXPI prev_close  NXPI log_returns  \n",
       "0           0.020456      127.163986       125.897690          0.010008  \n",
       "1           0.007121      125.937263       127.163986         -0.009694  \n",
       "2           0.037787      125.046890       125.937263         -0.007095  \n",
       "3          -0.011741      126.669334       125.046890          0.012891  \n",
       "4           0.010103      126.985916       126.669334          0.002496  \n",
       "..               ...             ...              ...               ...  \n",
       "206        -0.032373      134.889999       137.179993         -0.016834  \n",
       "207         0.016154      133.229996       134.889999         -0.012383  \n",
       "208        -0.016404      129.770004       133.229996         -0.026313  \n",
       "209        -0.018288      136.169998       129.770004          0.048140  \n",
       "210        -0.031112      135.119995       136.169998         -0.007741  \n",
       "\n",
       "[211 rows x 43 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_df_test.dropna(inplace = True)\n",
    "returns_df_test.reset_index(inplace=True)\n",
    "returns_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsi_aapl = RSI(returns_df_train['AAPL adj_close'], timeperiod=2)\n",
    "\n",
    "#joan\n",
    "rsi_msft = RSI(returns_df_train['MSFT adj_close'], timeperiod=2)\n",
    "rsi_ma = RSI(returns_df_train['MA adj_close'], timeperiod=2)\n",
    "rsi_v = RSI(returns_df_train['V adj_close'], timeperiod=2)\n",
    "\n",
    "#xin hui\n",
    "rsi_fis = RSI(returns_df_train['FIS adj_close'], timeperiod=2)\n",
    "rsi_lrcx = RSI(returns_df_train['LRCX adj_close'], timeperiod=2)\n",
    "rsi_fb = RSI(returns_df_train['FB adj_close'], timeperiod=2)\n",
    "\n",
    "#xing ying\n",
    "rsi_qcom = RSI(returns_df_train['QCOM adj_close'], timeperiod=2)\n",
    "rsi_intu = RSI(returns_df_train['INTU adj_close'], timeperiod=2)\n",
    "rsi_amd = RSI(returns_df_train['AMD adj_close'], timeperiod=2)\n",
    "\n",
    "#yizhen\n",
    "rsi_meli = RSI(returns_df_train['MELI adj_close'], timeperiod=2)\n",
    "rsi_g = RSI(returns_df_train['G adj_close'], timeperiod=2)\n",
    "rsi_mdb = RSI(returns_df_train['MDB adj_close'], timeperiod=2)\n",
    "\n",
    "#eram\n",
    "rsi_nxpi = RSI(returns_df_train['NXPI adj_close'], timeperiod=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma_aapl = talib.SMA(returns_df_train['AAPL adj_close'],timeperiod=3)\n",
    "\n",
    "sma_msft = talib.SMA(returns_df_train['MSFT adj_close'],timeperiod=3)\n",
    "sma_ma = talib.SMA(returns_df_train['MA adj_close'],timeperiod=3)\n",
    "sma_v = talib.SMA(returns_df_train['V adj_close'],timeperiod=3)\n",
    "\n",
    "sma_fis = talib.SMA(returns_df_train['FIS adj_close'],timeperiod=3)\n",
    "sma_lrcx = talib.SMA(returns_df_train['LRCX adj_close'],timeperiod=3)\n",
    "sma_fb = talib.SMA(returns_df_train['FB adj_close'],timeperiod=3)\n",
    "\n",
    "sma_qcom = talib.SMA(returns_df_train['QCOM adj_close'],timeperiod=3)\n",
    "sma_intu = talib.SMA(returns_df_train['INTU adj_close'],timeperiod=3)\n",
    "sma_amd = talib.SMA(returns_df_train['AMD adj_close'],timeperiod=3)\n",
    "\n",
    "sma_meli = talib.SMA(returns_df_train['MELI adj_close'],timeperiod=3)\n",
    "sma_g = talib.SMA(returns_df_train['G adj_close'],timeperiod=3)\n",
    "sma_mdb = talib.SMA(returns_df_train['MDB adj_close'],timeperiod=3)\n",
    "\n",
    "sma_nxpi = talib.SMA(returns_df_train['NXPI adj_close'],timeperiod=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_aapl = talib.MOM(returns_df_train['AAPL adj_close'],timeperiod=3)\n",
    "\n",
    "mom_msft = talib.MOM(returns_df_train['MSFT adj_close'],timeperiod=3)\n",
    "mom_ma = talib.MOM(returns_df_train['MA adj_close'],timeperiod=3)\n",
    "mom_v = talib.MOM(returns_df_train['V adj_close'],timeperiod=3)\n",
    "\n",
    "mom_fis = talib.MOM(returns_df_train['FIS adj_close'],timeperiod=3)\n",
    "mom_lrcx = talib.MOM(returns_df_train['LRCX adj_close'],timeperiod=3)\n",
    "mom_fb = talib.MOM(returns_df_train['FB adj_close'],timeperiod=3)\n",
    "\n",
    "mom_qcom = talib.MOM(returns_df_train['QCOM adj_close'],timeperiod=3)\n",
    "mom_intu = talib.MOM(returns_df_train['INTU adj_close'],timeperiod=3)\n",
    "mom_amd = talib.MOM(returns_df_train['AMD adj_close'],timeperiod=3)\n",
    "\n",
    "mom_meli = talib.MOM(returns_df_train['MELI adj_close'],timeperiod=3)\n",
    "mom_g = talib.MOM(returns_df_train['G adj_close'],timeperiod=3)\n",
    "mom_mdb = talib.MOM(returns_df_train['MDB adj_close'],timeperiod=3)\n",
    "\n",
    "mom_nxpi = talib.MOM(returns_df_train['NXPI adj_close'],timeperiod=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation data TA Indicators\n",
    "#validation\n",
    "rsi_aapl_v = RSI(returns_df_validation['AAPL adj_close'], timeperiod=2)\n",
    "\n",
    "rsi_msft_v = RSI(returns_df_validation['MSFT adj_close'], timeperiod=2)\n",
    "rsi_ma_v = RSI(returns_df_validation['MA adj_close'], timeperiod=2)\n",
    "rsi_v_v = RSI(returns_df_validation['V adj_close'], timeperiod=2)\n",
    "\n",
    "rsi_fis_v = RSI(returns_df_validation['FIS adj_close'], timeperiod=2)\n",
    "rsi_lrcx_v = RSI(returns_df_validation['LRCX adj_close'], timeperiod=2)\n",
    "rsi_fb_v = RSI(returns_df_validation['FB adj_close'], timeperiod=2)\n",
    "\n",
    "rsi_qcom_v = RSI(returns_df_validation['QCOM adj_close'], timeperiod=2)\n",
    "rsi_intu_v = RSI(returns_df_validation['INTU adj_close'], timeperiod=2)\n",
    "rsi_amd_v = RSI(returns_df_validation['AMD adj_close'], timeperiod=2)\n",
    "\n",
    "rsi_meli_v = RSI(returns_df_validation['MELI adj_close'], timeperiod=2)\n",
    "rsi_g_v = RSI(returns_df_validation['G adj_close'], timeperiod=2)\n",
    "rsi_mdb_v = RSI(returns_df_validation['MDB adj_close'], timeperiod=2)\n",
    "\n",
    "rsi_nxpi_v = RSI(returns_df_validation['NXPI adj_close'], timeperiod=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "sma_aapl_v = talib.SMA(returns_df_validation['AAPL adj_close'],timeperiod=3)\n",
    "\n",
    "sma_msft_v = talib.SMA(returns_df_validation['MSFT adj_close'],timeperiod=3)\n",
    "sma_ma_v = talib.SMA(returns_df_validation['MA adj_close'],timeperiod=3)\n",
    "sma_v_v = talib.SMA(returns_df_validation['V adj_close'],timeperiod=3)\n",
    "\n",
    "sma_fis_v = talib.SMA(returns_df_validation['FIS adj_close'],timeperiod=3)\n",
    "sma_lrcx_v = talib.SMA(returns_df_validation['LRCX adj_close'],timeperiod=3)\n",
    "sma_fb_v = talib.SMA(returns_df_validation['FB adj_close'],timeperiod=3)\n",
    "\n",
    "sma_qcom_v = talib.SMA(returns_df_validation['QCOM adj_close'],timeperiod=3)\n",
    "sma_intu_v = talib.SMA(returns_df_validation['INTU adj_close'],timeperiod=3)\n",
    "sma_amd_v = talib.SMA(returns_df_validation['AMD adj_close'],timeperiod=3)\n",
    "\n",
    "sma_meli_v = talib.SMA(returns_df_validation['MELI adj_close'],timeperiod=3)\n",
    "sma_g_v = talib.SMA(returns_df_validation['G adj_close'],timeperiod=3)\n",
    "sma_mdb_v = talib.SMA(returns_df_validation['MDB adj_close'],timeperiod=3)\n",
    "\n",
    "sma_nxpi_v = talib.SMA(returns_df_validation['NXPI adj_close'],timeperiod=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "mom_aapl_v = talib.MOM(returns_df_validation['AAPL adj_close'],timeperiod=3)\n",
    "\n",
    "mom_msft_v = talib.MOM(returns_df_validation['MSFT adj_close'],timeperiod=3)\n",
    "mom_ma_v = talib.MOM(returns_df_validation['MA adj_close'],timeperiod=3)\n",
    "mom_v_v = talib.MOM(returns_df_validation['V adj_close'],timeperiod=3)\n",
    "\n",
    "mom_fis_v = talib.MOM(returns_df_validation['FIS adj_close'],timeperiod=3)\n",
    "mom_lrcx_v = talib.MOM(returns_df_validation['LRCX adj_close'],timeperiod=3)\n",
    "mom_fb_v = talib.MOM(returns_df_validation['FB adj_close'],timeperiod=3)\n",
    "\n",
    "mom_qcom_v = talib.MOM(returns_df_validation['QCOM adj_close'],timeperiod=3)\n",
    "mom_intu_v = talib.MOM(returns_df_validation['INTU adj_close'],timeperiod=3)\n",
    "mom_amd_v = talib.MOM(returns_df_validation['AMD adj_close'],timeperiod=3)\n",
    "\n",
    "mom_meli_v = talib.MOM(returns_df_validation['MELI adj_close'],timeperiod=3)\n",
    "mom_g_v = talib.MOM(returns_df_validation['G adj_close'],timeperiod=3)\n",
    "mom_mdb_v = talib.MOM(returns_df_validation['MDB adj_close'],timeperiod=3)\n",
    "\n",
    "mom_nxpi_v = talib.MOM(returns_df_validation['NXPI adj_close'],timeperiod=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data TA Indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "rsi_aapl_t = RSI(returns_df_test['AAPL adj_close'], timeperiod=2)\n",
    "\n",
    "rsi_msft_t = RSI(returns_df_test['MSFT adj_close'], timeperiod=2)\n",
    "rsi_ma_t = RSI(returns_df_test['MA adj_close'], timeperiod=2)\n",
    "rsi_v_t = RSI(returns_df_test['V adj_close'], timeperiod=2)\n",
    "\n",
    "rsi_fis_t = RSI(returns_df_test['FIS adj_close'], timeperiod=2)\n",
    "rsi_lrcx_t = RSI(returns_df_test['LRCX adj_close'], timeperiod=2)\n",
    "rsi_fb_t = RSI(returns_df_test['FB adj_close'], timeperiod=2)\n",
    "\n",
    "rsi_qcom_t = RSI(returns_df_test['QCOM adj_close'], timeperiod=2)\n",
    "rsi_intu_t = RSI(returns_df_test['INTU adj_close'], timeperiod=2)\n",
    "rsi_amd_t = RSI(returns_df_test['AMD adj_close'], timeperiod=2)\n",
    "\n",
    "rsi_meli_t = RSI(returns_df_test['MELI adj_close'], timeperiod=2)\n",
    "rsi_g_t = RSI(returns_df_test['G adj_close'], timeperiod=2)\n",
    "rsi_mdb_t = RSI(returns_df_test['MDB adj_close'], timeperiod=2)\n",
    "\n",
    "rsi_nxpi_t = RSI(returns_df_test['NXPI adj_close'], timeperiod=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "sma_aapl_t = talib.SMA(returns_df_test['AAPL adj_close'],timeperiod=3)\n",
    "\n",
    "sma_msft_t = talib.SMA(returns_df_test['MSFT adj_close'],timeperiod=3)\n",
    "sma_ma_t = talib.SMA(returns_df_test['MA adj_close'],timeperiod=3)\n",
    "sma_v_t = talib.SMA(returns_df_test['V adj_close'],timeperiod=3)\n",
    "\n",
    "sma_fis_t = talib.SMA(returns_df_test['FIS adj_close'],timeperiod=3)\n",
    "sma_lrcx_t = talib.SMA(returns_df_test['LRCX adj_close'],timeperiod=3)\n",
    "sma_fb_t = talib.SMA(returns_df_test['FB adj_close'],timeperiod=3)\n",
    "\n",
    "sma_qcom_t = talib.SMA(returns_df_test['QCOM adj_close'],timeperiod=3)\n",
    "sma_intu_t = talib.SMA(returns_df_test['INTU adj_close'],timeperiod=3)\n",
    "sma_amd_t = talib.SMA(returns_df_test['AMD adj_close'],timeperiod=3)\n",
    "\n",
    "sma_meli_t = talib.SMA(returns_df_test['MELI adj_close'],timeperiod=3)\n",
    "sma_g_t = talib.SMA(returns_df_test['G adj_close'],timeperiod=3)\n",
    "sma_mdb_t = talib.SMA(returns_df_test['MDB adj_close'],timeperiod=3)\n",
    "\n",
    "sma_nxpi_t = talib.SMA(returns_df_test['NXPI adj_close'],timeperiod=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "mom_aapl_t = talib.MOM(returns_df_test['AAPL adj_close'],timeperiod=3)\n",
    "\n",
    "mom_msft_t = talib.MOM(returns_df_test['MSFT adj_close'],timeperiod=3)\n",
    "mom_ma_t = talib.MOM(returns_df_test['MA adj_close'],timeperiod=3)\n",
    "mom_v_t = talib.MOM(returns_df_test['V adj_close'],timeperiod=3)\n",
    "\n",
    "mom_fis_t = talib.MOM(returns_df_test['FIS adj_close'],timeperiod=3)\n",
    "mom_lrcx_t = talib.MOM(returns_df_test['LRCX adj_close'],timeperiod=3)\n",
    "mom_fb_t = talib.MOM(returns_df_test['FB adj_close'],timeperiod=3)\n",
    "\n",
    "mom_qcom_t = talib.MOM(returns_df_test['QCOM adj_close'],timeperiod=3)\n",
    "mom_intu_t = talib.MOM(returns_df_test['INTU adj_close'],timeperiod=3)\n",
    "mom_amd_t = talib.MOM(returns_df_test['AMD adj_close'],timeperiod=3)\n",
    "\n",
    "mom_meli_t = talib.MOM(returns_df_test['MELI adj_close'],timeperiod=3)\n",
    "mom_g_t = talib.MOM(returns_df_test['G adj_close'],timeperiod=3)\n",
    "mom_mdb_t = talib.MOM(returns_df_test['MDB adj_close'],timeperiod=3)\n",
    "\n",
    "mom_nxpi_t = talib.MOM(returns_df_test['NXPI adj_close'],timeperiod=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new \n",
    "def create_df(returns_df, rsi, sma, mom, ticker):\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    df[ticker+\" log_returns\"] = returns_df[ticker+\" log_returns\"]\n",
    "    \n",
    "    df[ticker+\"_rsi\"] = rsi\n",
    "    df[ticker+\"_sma\"] = sma\n",
    "    df[ticker+\"_mom\"] = mom\n",
    "    \n",
    "    df[ticker+\"_label\"] = 0\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if (returns_df[ticker+\" log_returns\"][i] > 0):\n",
    "            df[ticker+\"_label\"][i] = 1\n",
    "        else:\n",
    "            df[ticker+\"_label\"][i] = 0\n",
    "            \n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_before_tune = []\n",
    "F1_after_tune = []\n",
    "predictions_oct = []\n",
    "stocks_names = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# XGBoost Model#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new \n",
    "def xgb_kfold_model(df_train, df_validation, ticker):\n",
    "    \n",
    "    #train and validate model \n",
    "    x_var = [i for i in list(df_train.columns) if (i != ticker+'_label')& (i != ticker+' log_returns')]\n",
    "    y_var = ticker+'_label'\n",
    " \n",
    " \n",
    "    X_train = df_train[x_var]\n",
    "    y_train = df_train[y_var]\n",
    "#     auc_scores = []\n",
    "#     all_y_preds = []\n",
    "#     all_y_proba = []\n",
    "#     all_y_true = []\n",
    "    \n",
    "    XG = XGBClassifier(random_state =1)\n",
    "    XG.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    #validation model\n",
    "    features_drop = [ticker+' log_returns', ticker+'_label']\n",
    "    output = ticker+'_label'\n",
    "    X_validation = df_validation.drop(features_drop, axis=1) # Here no need to set inplace=True\n",
    "    y_validation = df_validation[output]\n",
    "    \n",
    "    y_preds = XG.predict(X_validation)\n",
    "    y_proba = XG.predict_proba(X_validation)\n",
    " \n",
    "    print(\"accuracy:\", accuracy_score(y_validation, y_preds))\n",
    " \n",
    "    print(\"precision:\", precision_score(y_validation, y_preds))\n",
    "    print(\"recall:\", recall_score(y_validation, y_preds))\n",
    "    print(\"F1:\", f1_score(y_validation, y_preds))\n",
    "    F1_before_tune.append(f1_score(y_validation, y_preds))\n",
    "    print(\"confusion matrix:\\n\", confusion_matrix(y_validation, y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n",
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8263473053892215\n",
      "precision: 0.7818181818181819\n",
      "recall: 0.945054945054945\n",
      "F1: 0.8557213930348259\n",
      "confusion matrix:\n",
      " [[52 24]\n",
      " [ 5 86]]\n"
     ]
    }
   ],
   "source": [
    "aapl_df_train = create_df(returns_df_train, rsi_aapl, sma_aapl, mom_aapl, \"AAPL\")\n",
    "aapl_df_v = create_df(returns_df_validation, rsi_aapl_v, sma_aapl_v, mom_aapl_v, \"AAPL\")\n",
    "aapl_df_test= create_df(returns_df_test, rsi_aapl_t, sma_aapl_t, mom_aapl_t, \"AAPL\")\n",
    "xgb_kfold_model(aapl_df_train, aapl_df_v, \"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n",
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8682634730538922\n",
      "precision: 0.8686868686868687\n",
      "recall: 0.9052631578947369\n",
      "F1: 0.88659793814433\n",
      "confusion matrix:\n",
      " [[59 13]\n",
      " [ 9 86]]\n"
     ]
    }
   ],
   "source": [
    "msft_df_train = create_df(returns_df_train, rsi_msft, sma_msft, mom_msft, \"MSFT\")\n",
    "msft_df_v = create_df(returns_df_validation, rsi_msft_v, sma_msft_v, mom_msft_v, \"MSFT\")\n",
    "msft_df_test = create_df(returns_df_test, rsi_msft_t, sma_msft_t, mom_msft_t, \"MSFT\")\n",
    "xgb_kfold_model(msft_df_train, msft_df_v, \"MSFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8323353293413174\n",
      "precision: 0.865979381443299\n",
      "recall: 0.8484848484848485\n",
      "F1: 0.8571428571428571\n",
      "confusion matrix:\n",
      " [[55 13]\n",
      " [15 84]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n",
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n"
     ]
    }
   ],
   "source": [
    "ma_df_train = create_df(returns_df_train, rsi_ma, sma_ma, mom_ma, \"MA\")\n",
    "ma_df_v = create_df(returns_df_validation, rsi_ma_v, sma_ma_v, mom_ma_v, \"MA\")\n",
    "ma_df_test = create_df(returns_df_test, rsi_ma_t, sma_ma_t, mom_ma_t, \"MA\")\n",
    "xgb_kfold_model(ma_df_train, ma_df_v, \"MA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n",
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.8203592814371258\n",
      "precision: 0.9135802469135802\n",
      "recall: 0.7628865979381443\n",
      "F1: 0.8314606741573032\n",
      "confusion matrix:\n",
      " [[63  7]\n",
      " [23 74]]\n"
     ]
    }
   ],
   "source": [
    "v_df_train = create_df(returns_df_train, rsi_v, sma_v, mom_v, \"V\")\n",
    "v_df_v = create_df(returns_df_validation, rsi_v_v, sma_v_v, mom_v_v, \"V\")\n",
    "v_df_test = create_df(returns_df_test, rsi_v_t, sma_v_t, mom_v_t, \"V\")\n",
    "xgb_kfold_model(v_df_train, v_df_v, \"V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7844311377245509\n",
      "precision: 0.8444444444444444\n",
      "recall: 0.7755102040816326\n",
      "F1: 0.8085106382978723\n",
      "confusion matrix:\n",
      " [[55 14]\n",
      " [22 76]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n",
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n"
     ]
    }
   ],
   "source": [
    "fis_df = create_df(returns_df_train, rsi_fis, sma_fis, mom_fis, \"FIS\")\n",
    "fis_df_v = create_df(returns_df_validation, rsi_fis_v, sma_fis_v, mom_fis_v, \"FIS\")\n",
    "fis_df_t = create_df(returns_df_test, rsi_fis_t, sma_fis_t, mom_fis_t, \"FIS\")\n",
    "xgb_kfold_model(fis_df, fis_df_v, \"FIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8682634730538922\n",
      "precision: 0.9259259259259259\n",
      "recall: 0.8241758241758241\n",
      "F1: 0.872093023255814\n",
      "confusion matrix:\n",
      " [[70  6]\n",
      " [16 75]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n"
     ]
    }
   ],
   "source": [
    "lrcx_df_train = create_df(returns_df_train, rsi_lrcx, sma_lrcx, mom_lrcx, \"LRCX\")\n",
    "lrcx_df_v = create_df(returns_df_validation, rsi_lrcx_v, sma_lrcx_v, mom_lrcx_v, \"LRCX\")\n",
    "lrcx_df_test = create_df(returns_df_test, rsi_lrcx_t, sma_lrcx_t, mom_lrcx_t, \"LRCX\")\n",
    "xgb_kfold_model(lrcx_df_train, lrcx_df_v, \"LRCX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8682634730538922\n",
      "precision: 0.9024390243902439\n",
      "recall: 0.8409090909090909\n",
      "F1: 0.8705882352941177\n",
      "confusion matrix:\n",
      " [[71  8]\n",
      " [14 74]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n",
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n"
     ]
    }
   ],
   "source": [
    "fb_df_train = create_df(returns_df_train, rsi_fb, sma_fb, mom_fb, \"FB\")\n",
    "fb_df_v = create_df(returns_df_validation, rsi_fb_v, sma_fb_v, mom_fb_v, \"FB\")\n",
    "fb_df_test = create_df(returns_df_test, rsi_fb_t, sma_fb_t, mom_fb_t, \"FB\")\n",
    "xgb_kfold_model(fb_df_train, fb_df_v, \"FB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n",
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8682634730538922\n",
      "precision: 0.8725490196078431\n",
      "recall: 0.9081632653061225\n",
      "F1: 0.89\n",
      "confusion matrix:\n",
      " [[56 13]\n",
      " [ 9 89]]\n"
     ]
    }
   ],
   "source": [
    "g_df_train = create_df(returns_df_train, rsi_g, sma_g, mom_g, \"G\")\n",
    "g_df_v = create_df(returns_df_validation, rsi_g_v, sma_g_v, mom_g_v, \"G\")\n",
    "g_df_test = create_df(returns_df_test, rsi_g_t, sma_g_t, mom_g_t, \"G\")\n",
    "xgb_kfold_model(g_df_train, g_df_v, \"G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n",
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.49700598802395207\n",
      "precision: 0.5108695652173914\n",
      "recall: 0.5465116279069767\n",
      "F1: 0.5280898876404495\n",
      "confusion matrix:\n",
      " [[36 45]\n",
      " [39 47]]\n"
     ]
    }
   ],
   "source": [
    "mdb_df_train = create_df(returns_df_train, rsi_mdb, sma_mdb, mom_mdb, \"MDB\")\n",
    "mdb_df_v = create_df(returns_df_validation, rsi_g_v, sma_mdb_v, mom_mdb_v, \"MDB\")\n",
    "mdb_df_test = create_df(returns_df_test, rsi_g_t, sma_mdb_t, mom_mdb_t, \"MDB\")\n",
    "xgb_kfold_model(mdb_df_train, mdb_df_v, \"MDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n",
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8922155688622755\n",
      "precision: 0.9230769230769231\n",
      "recall: 0.8571428571428571\n",
      "F1: 0.888888888888889\n",
      "confusion matrix:\n",
      " [[77  6]\n",
      " [12 72]]\n"
     ]
    }
   ],
   "source": [
    "qcom_df = create_df(returns_df_train, rsi_qcom, sma_qcom, mom_qcom, \"QCOM\")\n",
    "qcom_df_v= create_df(returns_df_validation, rsi_qcom_v, sma_qcom_v, mom_qcom_v, \"QCOM\")\n",
    "qcom_df_test= create_df(returns_df_test, rsi_qcom_t, sma_qcom_t, mom_qcom_t, \"QCOM\")\n",
    "xgb_kfold_model(qcom_df, qcom_df_v, \"QCOM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n",
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.844311377245509\n",
      "precision: 0.8690476190476191\n",
      "recall: 0.8295454545454546\n",
      "F1: 0.8488372093023256\n",
      "confusion matrix:\n",
      " [[68 11]\n",
      " [15 73]]\n"
     ]
    }
   ],
   "source": [
    "intu_df = create_df(returns_df_train, rsi_intu, sma_intu, mom_intu, \"INTU\")\n",
    "intu_df_v = create_df(returns_df_validation, rsi_intu_v, sma_intu_v, mom_intu_v, \"INTU\")\n",
    "intu_df_test = create_df(returns_df_test, rsi_intu_t, sma_intu_t, mom_intu_t, \"INTU\")\n",
    "xgb_kfold_model(intu_df, intu_df_v, \"INTU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n",
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.874251497005988\n",
      "precision: 0.9294117647058824\n",
      "recall: 0.8404255319148937\n",
      "F1: 0.8826815642458101\n",
      "confusion matrix:\n",
      " [[67  6]\n",
      " [15 79]]\n"
     ]
    }
   ],
   "source": [
    "amd_df = create_df(returns_df_train, rsi_amd, sma_amd, mom_amd, \"AMD\")\n",
    "amd_df_v = create_df(returns_df_validation, rsi_amd_v, sma_amd_v, mom_amd_v, \"AMD\")\n",
    "amd_df_test = create_df(returns_df_test, rsi_amd_t, sma_amd_t, mom_amd_t, \"AMD\")\n",
    "xgb_kfold_model(amd_df, amd_df_v, \"AMD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n",
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9041916167664671\n",
      "precision: 0.8924731182795699\n",
      "recall: 0.9325842696629213\n",
      "F1: 0.9120879120879121\n",
      "confusion matrix:\n",
      " [[68 10]\n",
      " [ 6 83]]\n"
     ]
    }
   ],
   "source": [
    "meli_df = create_df(returns_df_train, rsi_meli, sma_meli, mom_meli, \"MELI\")\n",
    "meli_df_v = create_df(returns_df_validation, rsi_meli_v, sma_meli_v, mom_meli_v, \"MELI\")\n",
    "meli_df_test= create_df(returns_df_test, rsi_meli_t, sma_meli_t, mom_meli_t, \"MELI\")\n",
    "xgb_kfold_model(meli_df, meli_df_v, \"MELI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-130-a2e0d517f8a4>:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 1\n",
      "<ipython-input-130-a2e0d517f8a4>:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[ticker+\"_label\"][i] = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.874251497005988\n",
      "precision: 0.9058823529411765\n",
      "recall: 0.8555555555555555\n",
      "F1: 0.88\n",
      "confusion matrix:\n",
      " [[69  8]\n",
      " [13 77]]\n"
     ]
    }
   ],
   "source": [
    "nxpi_df = create_df(returns_df_train, rsi_nxpi, sma_nxpi, mom_nxpi, \"NXPI\")\n",
    "nxpi_df_v = create_df(returns_df_validation, rsi_nxpi_v, sma_nxpi_v, mom_nxpi_v, \"NXPI\")\n",
    "nxpi_df_test= create_df(returns_df_test, rsi_nxpi_t, sma_nxpi_t, mom_nxpi_t, \"NXPI\")\n",
    "xgb_kfold_model(nxpi_df, nxpi_df_v, \"NXPI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Tuning Model##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from hyperopt import hp\n",
    "from hyperopt.pyll import scope\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, matthews_corrcoef, make_scorer, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "import os, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "F1_before_tune = []\n",
    "F1_after_tune = []\n",
    "predictions_oct = []\n",
    "stocks_names = [\"AAPL\", \"MSFT\", \"MA\", \"V\", \"FIS\", \"LRCX\", \"FB\", \"QCOM\", \"INTU\", \"AMD\", \"MELI\", \"G\", \"MDB\", \"NXPI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('Tuning'): os.mkdir('Tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(path, data):\n",
    "    output = open(path, 'wb')\n",
    "    pickle.dump(data, output)\n",
    "    output.close()\n",
    "    \n",
    "def load_file(path):\n",
    "    pkl_file = open(path, 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt(param_space, X_train, y_train, X_test, y_test, num_eval, classifier, use_scaling = False):  \n",
    "    start = time()\n",
    "    def objective_function(params):\n",
    "        clf = classifier(**params, random_state=1234, class_weight='balanced')\n",
    "        if use_scaling: clf = scale_classifier(clf)\n",
    "        score = cross_val_score(clf, X_train, y_train).mean()\n",
    "        return {'loss': -score, 'status': STATUS_OK}\n",
    "    trials = Trials()\n",
    "    best_param = fmin(objective_function, param_space, algo=tpe.suggest, max_evals=num_eval, \n",
    "                      trials=trials, rstate= np.random.RandomState(1234))\n",
    "    loss = [x['result']['loss'] for x in trials.trials] \n",
    "    best_param_values = best_param\n",
    "    return trials, best_param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:47] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "  0%|                                                                           | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "  2%|▉                                               | 1/50 [00:00<00:12,  3.89trial/s, best loss: -0.8450349650349651]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "  6%|██▉                                             | 3/50 [00:00<00:09,  4.80trial/s, best loss: -0.8450349650349651]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n",
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 10%|████▊                                           | 5/50 [00:00<00:08,  5.32trial/s, best loss: -0.8450349650349651]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n",
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:48] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 12%|█████▊                                          | 6/50 [00:01<00:07,  5.82trial/s, best loss: -0.8450349650349651]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 14%|██████▊                                          | 7/50 [00:01<00:08,  5.09trial/s, best loss: -0.848018648018648]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 18%|████████▊                                        | 9/50 [00:01<00:07,  5.44trial/s, best loss: -0.848018648018648]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n",
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 22%|██████████▌                                     | 11/50 [00:02<00:07,  5.29trial/s, best loss: -0.848018648018648]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:49] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 24%|███████████▌                                    | 12/50 [00:02<00:06,  5.86trial/s, best loss: -0.848018648018648]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n",
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 26%|████████████▍                                   | 13/50 [00:02<00:05,  6.38trial/s, best loss: -0.848018648018648]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 30%|██████████████                                 | 15/50 [00:02<00:05,  6.19trial/s, best loss: -0.8511888111888112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n",
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 32%|███████████████                                | 16/50 [00:02<00:05,  6.66trial/s, best loss: -0.8511888111888112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:50] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 36%|████████████████▉                              | 18/50 [00:03<00:05,  6.36trial/s, best loss: -0.8511888111888112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n",
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 40%|██████████████████▊                            | 20/50 [00:03<00:04,  7.08trial/s, best loss: -0.8511888111888112]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n",
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 42%|███████████████████▋                           | 21/50 [00:03<00:05,  5.34trial/s, best loss: -0.8754312354312355]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 44%|████████████████████▋                          | 22/50 [00:04<00:06,  4.57trial/s, best loss: -0.8754312354312355]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 46%|█████████████████████▌                         | 23/50 [00:04<00:06,  4.20trial/s, best loss: -0.8754312354312355]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 48%|██████████████████████▌                        | 24/50 [00:04<00:06,  3.93trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 50%|███████████████████████▌                       | 25/50 [00:05<00:06,  3.86trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:52] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 52%|████████████████████████▍                      | 26/50 [00:05<00:06,  3.78trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 54%|█████████████████████████▍                     | 27/50 [00:05<00:06,  3.62trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 56%|██████████████████████████▎                    | 28/50 [00:05<00:06,  3.46trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 58%|███████████████████████████▎                   | 29/50 [00:06<00:07,  2.75trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 60%|████████████████████████████▏                  | 30/50 [00:06<00:06,  2.97trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 62%|█████████████████████████████▏                 | 31/50 [00:07<00:06,  3.04trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:54] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 64%|██████████████████████████████                 | 32/50 [00:07<00:05,  3.19trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 66%|███████████████████████████████                | 33/50 [00:07<00:05,  3.28trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 68%|███████████████████████████████▉               | 34/50 [00:07<00:04,  3.39trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:55] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 70%|████████████████████████████████▉              | 35/50 [00:08<00:04,  3.45trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 74%|██████████████████████████████████▊            | 37/50 [00:08<00:03,  3.70trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 74%|██████████████████████████████████▊            | 37/50 [00:08<00:03,  3.70trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 76%|███████████████████████████████████▋           | 38/50 [00:09<00:03,  3.52trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████████▌         | 40/50 [00:09<00:02,  3.67trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████████▌         | 40/50 [00:09<00:02,  3.67trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 82%|██████████████████████████████████████▌        | 41/50 [00:09<00:02,  3.63trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:57] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████████████▍      | 43/50 [00:10<00:01,  3.88trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████████████▍      | 43/50 [00:10<00:01,  3.88trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████████████▎    | 45/50 [00:10<00:01,  4.31trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n",
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████████████▏  | 47/50 [00:11<00:00,  4.41trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n",
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:58] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight, colsample_bylevel, colsample_bynode, colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████████████ | 49/50 [00:11<00:00,  4.77trial/s, best loss: -0.8785081585081584]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n",
      "C:\\Users\\Yi Zhen\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516:                   \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:11<00:00,  4.29trial/s, best loss: -0.8785081585081584]\n"
     ]
    }
   ],
   "source": [
    "num_eval = 50\n",
    "\n",
    "XGB_param_hyperopt = {\n",
    "    'booster': hp.choice('booster', ['gbtree', 'gblinear']), \n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 1, 33, 1)),\n",
    "    'subsample': hp.uniform('subsample', 0.1, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.1, 1.0),\n",
    "    'colsample_bynode': hp.uniform('colsample_bynode',0.1, 1.0),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.1, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0, 11),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 1.0, 5.0),\n",
    "    'n_estimators': 100,\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 1, 11),\n",
    "    'reg_alpha':hp.uniform('reg_alpha', 0.01, 0.1)\n",
    "}\n",
    "try:\n",
    "    XGB_hyperopt = load_file('Tuning/XGB_hyperopt.pkl')\n",
    "except:\n",
    "    X_train = aapl_df_train[['AAPL_rsi', 'AAPL_sma', 'AAPL_mom']]\n",
    "    y_train = aapl_df_train[['AAPL_label']]\n",
    "    X_test = aapl_df_v[['AAPL_rsi', 'AAPL_sma', 'AAPL_mom']]\n",
    "    y_test = aapl_df_v[['AAPL_label']]\n",
    "    XGB_hyperopt = hyperopt(XGB_param_hyperopt, X_train, y_train, X_test, y_test, num_eval, xgb.XGBClassifier)\n",
    "    save_file('Tuning/XGB_hyperopt.pkl', XGB_hyperopt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booster': 0,\n",
       " 'colsample_bylevel': 0.7620438319576415,\n",
       " 'colsample_bynode': 0.6195511771835642,\n",
       " 'colsample_bytree': 0.889550987101511,\n",
       " 'gamma': 4.9782083453735115,\n",
       " 'max_depth': 15.0,\n",
       " 'min_child_weight': 2.599340109467396,\n",
       " 'reg_alpha': 0.06465879790945829,\n",
       " 'reg_lambda': 8.085943608996297,\n",
       " 'subsample': 0.9901460267448288}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_hyperopt = load_file('Tuning/XGB_hyperopt.pkl')\n",
    "xg_chosen = XGB_hyperopt[1]\n",
    "xg_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new \n",
    "def xgb_kfold_model_tune(df_train, df_validation, ticker):\n",
    "    \n",
    "    #train and validate model \n",
    "    x_var = [i for i in list(df_train.columns) if (i != ticker+'_label')& (i != ticker+' log_returns')]\n",
    "    y_var = ticker+'_label'\n",
    " \n",
    " \n",
    "    X_train = df_train[x_var]\n",
    "    y_train = df_train[y_var]\n",
    "#     auc_scores = []\n",
    "#     all_y_preds = []\n",
    "#     all_y_proba = []\n",
    "#     all_y_true = []\n",
    "    \n",
    "    XG = xgb.XGBClassifier(booster=['gbtree', 'gblinear'][xg_chosen['booster']], max_depth=int(xg_chosen['max_depth']),\n",
    "                                  subsample = xg_chosen['subsample'], colsample_bytree=xg_chosen['colsample_bytree'],\n",
    "                                  colsample_bynode = xg_chosen['colsample_bynode'], \n",
    "                                  colsample_bylevel = xg_chosen['colsample_bylevel'],\n",
    "                                  n_estimators = 200, reg_alpha = xg_chosen['reg_alpha'], reg_lambda = xg_chosen['reg_lambda'],\n",
    "                                  gamma = xg_chosen['gamma'], min_child_weight = xg_chosen['min_child_weight'],\n",
    "                                  random_state=1, class_weight='balanced')\n",
    "\n",
    "    XG.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    #validation model\n",
    "    features_drop = [ticker+' log_returns', ticker+'_label']\n",
    "    output = ticker+'_label'\n",
    "    X_validation = df_validation.drop(features_drop, axis=1) # Here no need to set inplace=True\n",
    "    y_validation = df_validation[output]\n",
    "    \n",
    "    y_preds = XG.predict(X_validation)\n",
    "    y_proba = XG.predict_proba(X_validation)\n",
    "    predictions_oct.append(y_preds[-22:])\n",
    "    print(\"accuracy:\", accuracy_score(y_validation, y_preds))\n",
    "    print(\"precision:\", precision_score(y_validation, y_preds))\n",
    "    print(\"recall:\", recall_score(y_validation, y_preds))\n",
    "    print(\"F1:\", f1_score(y_validation, y_preds))\n",
    "    F1_after_tune.append(f1_score(y_validation, y_preds))\n",
    "    print(\"confusion matrix:\\n\", confusion_matrix(y_validation, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7836538461538461\n",
      "precision: 0.7575757575757576\n",
      "recall: 0.8849557522123894\n",
      "F1: 0.8163265306122449\n",
      "confusion matrix:\n",
      " [[ 63  32]\n",
      " [ 13 100]]\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.75\n",
      "precision: 0.7074829931972789\n",
      "recall: 0.9203539823008849\n",
      "F1: 0.8\n",
      "confusion matrix:\n",
      " [[ 52  43]\n",
      " [  9 104]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(aapl_df_train, aapl_df_test, \"AAPL\")\n",
    "xgb_kfold_model_tune(aapl_df_train, aapl_df_test, \"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.75\n",
      "precision: 0.7661290322580645\n",
      "recall: 0.8050847457627118\n",
      "F1: 0.7851239669421487\n",
      "confusion matrix:\n",
      " [[61 29]\n",
      " [23 95]]\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.8461538461538461\n",
      "precision: 0.8583333333333333\n",
      "recall: 0.8728813559322034\n",
      "F1: 0.865546218487395\n",
      "confusion matrix:\n",
      " [[ 73  17]\n",
      " [ 15 103]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(msft_df_train, msft_df_test, \"MSFT\")\n",
    "xgb_kfold_model_tune(msft_df_train, msft_df_test, \"MSFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8413461538461539\n",
      "precision: 0.8648648648648649\n",
      "recall: 0.8421052631578947\n",
      "F1: 0.8533333333333334\n",
      "confusion matrix:\n",
      " [[79 15]\n",
      " [18 96]]\n",
      "[00:12:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.8413461538461539\n",
      "precision: 0.8648648648648649\n",
      "recall: 0.8421052631578947\n",
      "F1: 0.8533333333333334\n",
      "confusion matrix:\n",
      " [[79 15]\n",
      " [18 96]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(ma_df_train, ma_df_test, \"MA\")\n",
    "xgb_kfold_model_tune(ma_df_train, ma_df_test, \"MA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8269230769230769\n",
      "precision: 0.8773584905660378\n",
      "recall: 0.8017241379310345\n",
      "F1: 0.8378378378378378\n",
      "confusion matrix:\n",
      " [[79 13]\n",
      " [23 93]]\n",
      "[00:13:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.8317307692307693\n",
      "precision: 0.8461538461538461\n",
      "recall: 0.853448275862069\n",
      "F1: 0.8497854077253219\n",
      "confusion matrix:\n",
      " [[74 18]\n",
      " [17 99]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(v_df_train, v_df_test, \"V\")\n",
    "xgb_kfold_model_tune(v_df_train, v_df_test, \"V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7932692307692307\n",
      "precision: 0.7894736842105263\n",
      "recall: 0.8256880733944955\n",
      "F1: 0.8071748878923767\n",
      "confusion matrix:\n",
      " [[75 24]\n",
      " [19 90]]\n",
      "[00:13:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.8461538461538461\n",
      "precision: 0.8347826086956521\n",
      "recall: 0.8807339449541285\n",
      "F1: 0.857142857142857\n",
      "confusion matrix:\n",
      " [[80 19]\n",
      " [13 96]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(fis_df, fis_df_t, \"FIS\")\n",
    "xgb_kfold_model_tune(fis_df, fis_df_t, \"FIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7692307692307693\n",
      "precision: 0.8404255319148937\n",
      "recall: 0.7053571428571429\n",
      "F1: 0.7669902912621359\n",
      "confusion matrix:\n",
      " [[81 15]\n",
      " [33 79]]\n",
      "[00:13:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.8509615384615384\n",
      "precision: 0.8521739130434782\n",
      "recall: 0.875\n",
      "F1: 0.8634361233480177\n",
      "confusion matrix:\n",
      " [[79 17]\n",
      " [14 98]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(lrcx_df_train, lrcx_df_test, \"LRCX\")\n",
    "xgb_kfold_model_tune(lrcx_df_train, lrcx_df_test, \"LRCX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7788461538461539\n",
      "precision: 0.8817204301075269\n",
      "recall: 0.7008547008547008\n",
      "F1: 0.7809523809523811\n",
      "confusion matrix:\n",
      " [[80 11]\n",
      " [35 82]]\n",
      "[00:13:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.8653846153846154\n",
      "precision: 0.9158878504672897\n",
      "recall: 0.8376068376068376\n",
      "F1: 0.875\n",
      "confusion matrix:\n",
      " [[82  9]\n",
      " [19 98]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(fb_df_train, fb_df_test, \"FB\")\n",
    "xgb_kfold_model_tune(fb_df_train, fb_df_test, \"FB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8173076923076923\n",
      "precision: 0.8469387755102041\n",
      "recall: 0.7830188679245284\n",
      "F1: 0.8137254901960785\n",
      "confusion matrix:\n",
      " [[87 15]\n",
      " [23 83]]\n",
      "[00:13:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.8365384615384616\n",
      "precision: 0.86\n",
      "recall: 0.8113207547169812\n",
      "F1: 0.8349514563106797\n",
      "confusion matrix:\n",
      " [[88 14]\n",
      " [20 86]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(qcom_df, qcom_df_test, \"QCOM\")\n",
    "xgb_kfold_model_tune(qcom_df, qcom_df_test, \"QCOM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8173076923076923\n",
      "precision: 0.8157894736842105\n",
      "recall: 0.8454545454545455\n",
      "F1: 0.8303571428571429\n",
      "confusion matrix:\n",
      " [[77 21]\n",
      " [17 93]]\n",
      "[00:13:00] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.8221153846153846\n",
      "precision: 0.8230088495575221\n",
      "recall: 0.8454545454545455\n",
      "F1: 0.8340807174887892\n",
      "confusion matrix:\n",
      " [[78 20]\n",
      " [17 93]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(intu_df, intu_df_test, \"INTU\")\n",
    "xgb_kfold_model_tune(intu_df, intu_df_test, \"INTU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8461538461538461\n",
      "precision: 0.8640776699029126\n",
      "recall: 0.8317757009345794\n",
      "F1: 0.8476190476190476\n",
      "confusion matrix:\n",
      " [[87 14]\n",
      " [18 89]]\n",
      "[00:13:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.8605769230769231\n",
      "precision: 0.8545454545454545\n",
      "recall: 0.8785046728971962\n",
      "F1: 0.8663594470046083\n",
      "confusion matrix:\n",
      " [[85 16]\n",
      " [13 94]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(amd_df, amd_df_test, \"AMD\")\n",
    "xgb_kfold_model_tune(amd_df, amd_df_test, \"AMD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8605769230769231\n",
      "precision: 0.9181818181818182\n",
      "recall: 0.8347107438016529\n",
      "F1: 0.8744588744588745\n",
      "confusion matrix:\n",
      " [[ 78   9]\n",
      " [ 20 101]]\n",
      "[00:13:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.8798076923076923\n",
      "precision: 0.8870967741935484\n",
      "recall: 0.9090909090909091\n",
      "F1: 0.8979591836734694\n",
      "confusion matrix:\n",
      " [[ 73  14]\n",
      " [ 11 110]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(meli_df, meli_df_test, \"MELI\")\n",
    "xgb_kfold_model_tune(meli_df, meli_df_test, \"MELI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8028846153846154\n",
      "precision: 0.8\n",
      "recall: 0.822429906542056\n",
      "F1: 0.8110599078341014\n",
      "confusion matrix:\n",
      " [[79 22]\n",
      " [19 88]]\n",
      "[00:13:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.8701923076923077\n",
      "precision: 0.8636363636363636\n",
      "recall: 0.8878504672897196\n",
      "F1: 0.8755760368663594\n",
      "confusion matrix:\n",
      " [[86 15]\n",
      " [12 95]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(g_df_train, g_df_test, \"G\")\n",
    "xgb_kfold_model_tune(g_df_train, g_df_test, \"G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.4375\n",
      "precision: 0.47619047619047616\n",
      "recall: 0.35398230088495575\n",
      "F1: 0.40609137055837563\n",
      "confusion matrix:\n",
      " [[51 44]\n",
      " [73 40]]\n",
      "[00:13:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.4807692307692308\n",
      "precision: 0.5263157894736842\n",
      "recall: 0.4424778761061947\n",
      "F1: 0.4807692307692308\n",
      "confusion matrix:\n",
      " [[50 45]\n",
      " [63 50]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(mdb_df_train, mdb_df_test, \"MDB\")\n",
    "xgb_kfold_model_tune(mdb_df_train, mdb_df_test, \"MDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8461538461538461\n",
      "precision: 0.8495575221238938\n",
      "recall: 0.8648648648648649\n",
      "F1: 0.8571428571428571\n",
      "confusion matrix:\n",
      " [[80 17]\n",
      " [15 96]]\n",
      "[00:13:01] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { class_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "accuracy: 0.8221153846153846\n",
      "precision: 0.8557692307692307\n",
      "recall: 0.8018018018018018\n",
      "F1: 0.8279069767441861\n",
      "confusion matrix:\n",
      " [[82 15]\n",
      " [22 89]]\n"
     ]
    }
   ],
   "source": [
    "xgb_kfold_model(nxpi_df, nxpi_df_test, \"NXPI\")\n",
    "xgb_kfold_model_tune(nxpi_df, nxpi_df_test, \"NXPI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(F1_before_tune)\n",
    "#len(F1_after_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stocks</th>\n",
       "      <th>F1 Score Before Tuning</th>\n",
       "      <th>F1 Score After Tuning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>0.785124</td>\n",
       "      <td>0.865546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MA</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.849785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIS</td>\n",
       "      <td>0.807175</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.863436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FB</td>\n",
       "      <td>0.780952</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>0.813725</td>\n",
       "      <td>0.834951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INTU</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.834081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AMD</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>0.866359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MELI</td>\n",
       "      <td>0.874459</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>G</td>\n",
       "      <td>0.811060</td>\n",
       "      <td>0.875576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MDB</td>\n",
       "      <td>0.406091</td>\n",
       "      <td>0.480769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NXPI</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.827907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stocks  F1 Score Before Tuning  F1 Score After Tuning\n",
       "0    AAPL                0.816327               0.800000\n",
       "1    MSFT                0.785124               0.865546\n",
       "2      MA                0.853333               0.853333\n",
       "3       V                0.837838               0.849785\n",
       "4     FIS                0.807175               0.857143\n",
       "5    LRCX                0.766990               0.863436\n",
       "6      FB                0.780952               0.875000\n",
       "7    QCOM                0.813725               0.834951\n",
       "8    INTU                0.830357               0.834081\n",
       "9     AMD                0.847619               0.866359\n",
       "10   MELI                0.874459               0.897959\n",
       "11      G                0.811060               0.875576\n",
       "12    MDB                0.406091               0.480769\n",
       "13   NXPI                0.857143               0.827907"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'stocks': stocks_names, 'F1 Score Before Tuning': F1_before_tune, 'F1 Score After Tuning': F1_after_tune})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stocks</th>\n",
       "      <th>Predictions for October</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MA</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIS</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FB</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INTU</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AMD</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MELI</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>G</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MDB</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NXPI</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stocks                            Predictions for October\n",
       "0    AAPL  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, ...\n",
       "1    MSFT  [1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, ...\n",
       "2      MA  [1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3       V  [1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ...\n",
       "4     FIS  [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ...\n",
       "5    LRCX  [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...\n",
       "6      FB  [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, ...\n",
       "7    QCOM  [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, ...\n",
       "8    INTU  [1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...\n",
       "9     AMD  [1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...\n",
       "10   MELI  [1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, ...\n",
       "11      G  [1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "12    MDB  [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "13   NXPI  [1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ..."
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame({'stocks': stocks_names, 'Predictions for October': predictions_oct})\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stocks</th>\n",
       "      <th>Predictions for October</th>\n",
       "      <th>Average</th>\n",
       "      <th>Buy/Hold/Sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MA</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIS</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LRCX</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FB</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, ...</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>INTU</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AMD</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MELI</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>G</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MDB</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NXPI</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stocks                            Predictions for October   Average  \\\n",
       "0    AAPL  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, ...  0.636364   \n",
       "1    MSFT  [1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, ...  0.500000   \n",
       "2      MA  [1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...  0.272727   \n",
       "3       V  [1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ...  0.318182   \n",
       "4     FIS  [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ...  0.272727   \n",
       "5    LRCX  [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...  0.454545   \n",
       "6      FB  [1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, ...  0.409091   \n",
       "7    QCOM  [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, ...  0.590909   \n",
       "8    INTU  [1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...  0.409091   \n",
       "9     AMD  [1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...  0.454545   \n",
       "10   MELI  [1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, ...  0.590909   \n",
       "11      G  [1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...  0.272727   \n",
       "12    MDB  [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...  0.136364   \n",
       "13   NXPI  [1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, ...  0.454545   \n",
       "\n",
       "   Buy/Hold/Sell  \n",
       "0              1  \n",
       "1              0  \n",
       "2             -1  \n",
       "3             -1  \n",
       "4             -1  \n",
       "5             -1  \n",
       "6             -1  \n",
       "7              1  \n",
       "8             -1  \n",
       "9             -1  \n",
       "10             1  \n",
       "11            -1  \n",
       "12            -1  \n",
       "13            -1  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(predictions)):\n",
    "    predictions.loc[i,'Average'] = sum(predictions.loc[i,'Predictions for October'])/22\n",
    "    if predictions.loc[i,\"Average\"] > 0.5:\n",
    "        predictions.loc[i, 'Buy/Hold/Sell'] = '1'\n",
    "    elif predictions.loc[i,\"Average\"] < 0.5:\n",
    "        predictions.loc[i, 'Buy/Hold/Sell'] = '-1'\n",
    "    else:\n",
    "        predictions.loc[i, 'Buy/Hold/Sell'] = '0'\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.042392000000000006,\n",
       " 0.0740552,\n",
       " 0.1255896,\n",
       " 0.11004799999999999,\n",
       " 0.059812000000000004,\n",
       " 0.040476000000000005,\n",
       " 0.0006976,\n",
       " 0.0324624,\n",
       " 0.15962400000000002,\n",
       " 0.0361392,\n",
       " 0.0129184,\n",
       " 0.035524,\n",
       " 0.012376,\n",
       " 0.057886400000000005]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimized weights\n",
    "lst = list(predictions['Buy/Hold/Sell'])\n",
    "weights = [0.052990, 0.092569, 0.156987, 0.137560, 0.074765, 0.050595, 0.000872, 0.040578, 0.199530, 0.045174, 0.016148, 0.044405, 0.015470, 0.072358]\n",
    "weights_adjusted = []\n",
    "for i in range(len(weights)):\n",
    "    if lst[i] == 0:\n",
    "        weights_adjusted.append(weights[i])\n",
    "    elif lst[i] == 1:\n",
    "        weights_adjusted.append(1.2*weights[i])\n",
    "    else:\n",
    "         weights_adjusted.append(0.8*weights[i])\n",
    "weights_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.052989947010052996,\n",
       " 0.09256890743109256,\n",
       " 0.15698684301315696,\n",
       " 0.13755986244013754,\n",
       " 0.07476492523507476,\n",
       " 0.0505949494050506,\n",
       " 0.000871999128000872,\n",
       " 0.04057795942204058,\n",
       " 0.19952980047019953,\n",
       " 0.04517395482604517,\n",
       " 0.016147983852016146,\n",
       " 0.0444049555950444,\n",
       " 0.015469984530015468,\n",
       " 0.07235792764207236]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = sum(weights_adjusted)\n",
    "weights_adjusted_normalised = []\n",
    "for i in weights_adjusted:\n",
    "    weights_adjusted_normalised.append(i/total)\n",
    "\n",
    "weights_adjusted_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_weights_after = [0.0609385, 0.1295965999999999998, 0.1334389499999999997, 0.137560,0.074765, 0.070833, 0.0556545, 0.040578, 0.119718, 0.0383979,\n",
    "                   0.016148, 0.044405, 0.015470, 0.072358]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.048750800000000004,\n",
       " 0.10367728000000001,\n",
       " 0.10675116000000001,\n",
       " 0.11004799999999999,\n",
       " 0.059812000000000004,\n",
       " 0.0566664,\n",
       " 0.0445236,\n",
       " 0.0324624,\n",
       " 0.09577440000000001,\n",
       " 0.03071832,\n",
       " 0.0129184,\n",
       " 0.035524,\n",
       " 0.012376,\n",
       " 0.057886400000000005]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = list(predictions['Buy/Hold/Sell'])\n",
    "optimal_weights_after = [0.0609385, 0.1295965999999999998, 0.1334389499999999997, 0.137560,0.074765, 0.070833, 0.0556545, 0.040578, 0.119718, 0.0383979,\n",
    "                   0.016148, 0.044405, 0.015470, 0.072358]\n",
    "optimal_weights_after_adjusted = []\n",
    "for i in range(len(optimal_weights_after)):\n",
    "    if lst[i] == 0:\n",
    "        optimal_weights_after_adjusted.append(optimal_weights_after[i])\n",
    "    elif lst[i] == 1:\n",
    "        optimal_weights_after_adjusted.append(1.2*optimal_weights_after[i])\n",
    "    else:\n",
    "         optimal_weights_after_adjusted.append(0.8*optimal_weights_after[i])\n",
    "optimal_weights_after_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06034342631853112,\n",
       " 0.12833106957394996,\n",
       " 0.13213589844428658,\n",
       " 0.13621670576691483,\n",
       " 0.07403490845204556,\n",
       " 0.0701413050275362,\n",
       " 0.05511102537877844,\n",
       " 0.04018174968457307,\n",
       " 0.11854893559903687,\n",
       " 0.038022938691243235,\n",
       " 0.015990312334429636,\n",
       " 0.043971378449984395,\n",
       " 0.015318933107110879,\n",
       " 0.07165141317157912]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = sum(optimal_weights_after_adjusted)\n",
    "optimal_weights_after_adjusted_normalised = []\n",
    "for i in optimal_weights_after_adjusted:\n",
    "    optimal_weights_after_adjusted_normalised.append(i/total)\n",
    "\n",
    "optimal_weights_after_adjusted_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL_Adj Close</th>\n",
       "      <th>MSFT_Adj Close</th>\n",
       "      <th>MA_Adj Close</th>\n",
       "      <th>V_Adj Close</th>\n",
       "      <th>FIS_Adj Close</th>\n",
       "      <th>LRCX_Adj Close</th>\n",
       "      <th>FB_Adj Close</th>\n",
       "      <th>QCOM_Adj Close</th>\n",
       "      <th>INTU_Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th>FB_log_return</th>\n",
       "      <th>QCOM_log_return</th>\n",
       "      <th>INTU_log_return</th>\n",
       "      <th>AMD_log_return</th>\n",
       "      <th>MELI_log_return</th>\n",
       "      <th>G_log_return</th>\n",
       "      <th>MDB_log_return</th>\n",
       "      <th>NXPI_log_return</th>\n",
       "      <th>Portfolio_Value</th>\n",
       "      <th>log_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>116.588860</td>\n",
       "      <td>212.460007</td>\n",
       "      <td>342.970612</td>\n",
       "      <td>203.350006</td>\n",
       "      <td>146.869995</td>\n",
       "      <td>339.130005</td>\n",
       "      <td>266.630005</td>\n",
       "      <td>119.519997</td>\n",
       "      <td>331.754517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017899</td>\n",
       "      <td>0.015515</td>\n",
       "      <td>0.018617</td>\n",
       "      <td>0.034406</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>-0.005406</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.048328</td>\n",
       "      <td>7.599051e+09</td>\n",
       "      <td>0.011688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>112.825348</td>\n",
       "      <td>206.190002</td>\n",
       "      <td>338.435883</td>\n",
       "      <td>201.460007</td>\n",
       "      <td>145.149994</td>\n",
       "      <td>328.709991</td>\n",
       "      <td>259.940002</td>\n",
       "      <td>115.470001</td>\n",
       "      <td>321.322937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025411</td>\n",
       "      <td>-0.034473</td>\n",
       "      <td>-0.031949</td>\n",
       "      <td>-0.036726</td>\n",
       "      <td>-0.032819</td>\n",
       "      <td>-0.004398</td>\n",
       "      <td>-0.006211</td>\n",
       "      <td>-0.027868</td>\n",
       "      <td>7.380244e+09</td>\n",
       "      <td>-0.029217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>116.299355</td>\n",
       "      <td>210.380005</td>\n",
       "      <td>342.850769</td>\n",
       "      <td>203.539993</td>\n",
       "      <td>145.570007</td>\n",
       "      <td>342.230011</td>\n",
       "      <td>264.649994</td>\n",
       "      <td>120.519997</td>\n",
       "      <td>330.776245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017957</td>\n",
       "      <td>0.042805</td>\n",
       "      <td>0.028995</td>\n",
       "      <td>0.051813</td>\n",
       "      <td>0.010369</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>0.035549</td>\n",
       "      <td>7.570234e+09</td>\n",
       "      <td>0.025417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>112.965111</td>\n",
       "      <td>205.910004</td>\n",
       "      <td>337.037506</td>\n",
       "      <td>200.449997</td>\n",
       "      <td>144.369995</td>\n",
       "      <td>340.980011</td>\n",
       "      <td>258.660004</td>\n",
       "      <td>119.540001</td>\n",
       "      <td>324.806793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022894</td>\n",
       "      <td>-0.008165</td>\n",
       "      <td>-0.018212</td>\n",
       "      <td>-0.019575</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>-0.016881</td>\n",
       "      <td>0.031831</td>\n",
       "      <td>-0.008368</td>\n",
       "      <td>7.409021e+09</td>\n",
       "      <td>-0.021526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>114.881805</td>\n",
       "      <td>209.830002</td>\n",
       "      <td>343.500000</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>144.600006</td>\n",
       "      <td>345.769989</td>\n",
       "      <td>258.119995</td>\n",
       "      <td>123.029999</td>\n",
       "      <td>334.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002090</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.025824</td>\n",
       "      <td>0.047953</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.020417</td>\n",
       "      <td>7.544122e+09</td>\n",
       "      <td>0.018070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>114.771988</td>\n",
       "      <td>210.580002</td>\n",
       "      <td>345.149994</td>\n",
       "      <td>202.979996</td>\n",
       "      <td>146.600006</td>\n",
       "      <td>355.429993</td>\n",
       "      <td>263.760010</td>\n",
       "      <td>122.339996</td>\n",
       "      <td>334.989990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021615</td>\n",
       "      <td>-0.005624</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>-0.002079</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>0.009164</td>\n",
       "      <td>7.565862e+09</td>\n",
       "      <td>0.002878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>116.768547</td>\n",
       "      <td>215.809998</td>\n",
       "      <td>352.390015</td>\n",
       "      <td>206.639999</td>\n",
       "      <td>149.029999</td>\n",
       "      <td>362.709991</td>\n",
       "      <td>264.450012</td>\n",
       "      <td>124.870003</td>\n",
       "      <td>341.809998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>0.020154</td>\n",
       "      <td>-0.040215</td>\n",
       "      <td>0.033449</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>0.024262</td>\n",
       "      <td>0.048497</td>\n",
       "      <td>7.708145e+09</td>\n",
       "      <td>0.018631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>124.185753</td>\n",
       "      <td>221.399994</td>\n",
       "      <td>352.040009</td>\n",
       "      <td>206.399994</td>\n",
       "      <td>149.190002</td>\n",
       "      <td>370.109985</td>\n",
       "      <td>275.750000</td>\n",
       "      <td>126.690002</td>\n",
       "      <td>350.929993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041842</td>\n",
       "      <td>0.014470</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>0.014219</td>\n",
       "      <td>0.013173</td>\n",
       "      <td>0.017860</td>\n",
       "      <td>0.015816</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>8.006618e+09</td>\n",
       "      <td>0.037991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>120.891434</td>\n",
       "      <td>222.860001</td>\n",
       "      <td>345.839996</td>\n",
       "      <td>204.320007</td>\n",
       "      <td>145.960007</td>\n",
       "      <td>374.190002</td>\n",
       "      <td>276.140015</td>\n",
       "      <td>127.459999</td>\n",
       "      <td>349.589996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.006059</td>\n",
       "      <td>-0.003826</td>\n",
       "      <td>0.011677</td>\n",
       "      <td>0.043002</td>\n",
       "      <td>-0.022949</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>-0.037578</td>\n",
       "      <td>7.930264e+09</td>\n",
       "      <td>-0.009582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2020-10-14</td>\n",
       "      <td>120.981277</td>\n",
       "      <td>220.860001</td>\n",
       "      <td>342.700012</td>\n",
       "      <td>202.199997</td>\n",
       "      <td>144.070007</td>\n",
       "      <td>374.239990</td>\n",
       "      <td>271.820007</td>\n",
       "      <td>129.880005</td>\n",
       "      <td>345.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015768</td>\n",
       "      <td>0.018808</td>\n",
       "      <td>-0.012347</td>\n",
       "      <td>-0.012626</td>\n",
       "      <td>-0.024301</td>\n",
       "      <td>-0.007169</td>\n",
       "      <td>-0.011100</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>7.894038e+09</td>\n",
       "      <td>-0.004579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2020-10-15</td>\n",
       "      <td>120.502106</td>\n",
       "      <td>219.660004</td>\n",
       "      <td>338.570007</td>\n",
       "      <td>199.550003</td>\n",
       "      <td>143.880005</td>\n",
       "      <td>375.489990</td>\n",
       "      <td>266.720001</td>\n",
       "      <td>128.580002</td>\n",
       "      <td>341.970001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018941</td>\n",
       "      <td>-0.010060</td>\n",
       "      <td>-0.009691</td>\n",
       "      <td>-0.012908</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>-0.003604</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>-0.001752</td>\n",
       "      <td>7.858095e+09</td>\n",
       "      <td>-0.004564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>118.815010</td>\n",
       "      <td>219.660004</td>\n",
       "      <td>339.399994</td>\n",
       "      <td>200.259995</td>\n",
       "      <td>143.880005</td>\n",
       "      <td>364.959991</td>\n",
       "      <td>265.929993</td>\n",
       "      <td>129.029999</td>\n",
       "      <td>341.149994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002966</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>-0.002401</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>-0.009587</td>\n",
       "      <td>-0.009569</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>7.805612e+09</td>\n",
       "      <td>-0.006701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>115.780251</td>\n",
       "      <td>214.220001</td>\n",
       "      <td>331.670013</td>\n",
       "      <td>196.970001</td>\n",
       "      <td>139.779999</td>\n",
       "      <td>363.570007</td>\n",
       "      <td>261.399994</td>\n",
       "      <td>128.419998</td>\n",
       "      <td>335.269989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017181</td>\n",
       "      <td>-0.004739</td>\n",
       "      <td>-0.017386</td>\n",
       "      <td>-0.014167</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>-0.026647</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>-0.006580</td>\n",
       "      <td>7.636255e+09</td>\n",
       "      <td>-0.021936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>117.307617</td>\n",
       "      <td>214.649994</td>\n",
       "      <td>331.720001</td>\n",
       "      <td>197.699997</td>\n",
       "      <td>140.699997</td>\n",
       "      <td>363.570007</td>\n",
       "      <td>267.559998</td>\n",
       "      <td>128.300003</td>\n",
       "      <td>334.510010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023292</td>\n",
       "      <td>-0.000935</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.005380</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>-0.001338</td>\n",
       "      <td>-0.032805</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>7.692465e+09</td>\n",
       "      <td>0.007334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>116.668724</td>\n",
       "      <td>214.800003</td>\n",
       "      <td>333.420013</td>\n",
       "      <td>198.429993</td>\n",
       "      <td>141.410004</td>\n",
       "      <td>366.619995</td>\n",
       "      <td>278.730011</td>\n",
       "      <td>128.550003</td>\n",
       "      <td>332.790009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>-0.005155</td>\n",
       "      <td>-0.029363</td>\n",
       "      <td>-0.026232</td>\n",
       "      <td>-0.011580</td>\n",
       "      <td>-0.031020</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>7.672447e+09</td>\n",
       "      <td>-0.002606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>115.550644</td>\n",
       "      <td>214.889999</td>\n",
       "      <td>333.600006</td>\n",
       "      <td>197.990005</td>\n",
       "      <td>142.720001</td>\n",
       "      <td>358.010010</td>\n",
       "      <td>278.119995</td>\n",
       "      <td>128.380005</td>\n",
       "      <td>331.820007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002191</td>\n",
       "      <td>-0.001323</td>\n",
       "      <td>-0.002919</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>-0.003709</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>-0.012495</td>\n",
       "      <td>-0.007165</td>\n",
       "      <td>7.634396e+09</td>\n",
       "      <td>-0.004972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>114.841873</td>\n",
       "      <td>216.229996</td>\n",
       "      <td>329.609985</td>\n",
       "      <td>198.009995</td>\n",
       "      <td>144.399994</td>\n",
       "      <td>353.920013</td>\n",
       "      <td>284.790009</td>\n",
       "      <td>128.880005</td>\n",
       "      <td>334.420013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023699</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>0.031481</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.009114</td>\n",
       "      <td>0.016834</td>\n",
       "      <td>7.644002e+09</td>\n",
       "      <td>0.001257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>318.059998</td>\n",
       "      <td>193.070007</td>\n",
       "      <td>139.419998</td>\n",
       "      <td>347.630005</td>\n",
       "      <td>277.109985</td>\n",
       "      <td>126.199997</td>\n",
       "      <td>328.089996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027338</td>\n",
       "      <td>-0.021014</td>\n",
       "      <td>-0.019110</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>-0.023690</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>-0.032373</td>\n",
       "      <td>-0.016834</td>\n",
       "      <td>7.530051e+09</td>\n",
       "      <td>-0.015019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>317.109985</td>\n",
       "      <td>190.059998</td>\n",
       "      <td>137.860001</td>\n",
       "      <td>343.829987</td>\n",
       "      <td>283.290009</td>\n",
       "      <td>125.910004</td>\n",
       "      <td>330.269989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022057</td>\n",
       "      <td>-0.002301</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>-0.041593</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>-0.007057</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>7.597413e+09</td>\n",
       "      <td>0.008906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>291.380005</td>\n",
       "      <td>180.869995</td>\n",
       "      <td>132.509995</td>\n",
       "      <td>338.899994</td>\n",
       "      <td>267.670013</td>\n",
       "      <td>121.580002</td>\n",
       "      <td>318.510010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056716</td>\n",
       "      <td>-0.034995</td>\n",
       "      <td>-0.036257</td>\n",
       "      <td>-0.031945</td>\n",
       "      <td>-0.006948</td>\n",
       "      <td>-0.037228</td>\n",
       "      <td>-0.016404</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>7.257499e+09</td>\n",
       "      <td>-0.045773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>293.179993</td>\n",
       "      <td>184.869995</td>\n",
       "      <td>125.019997</td>\n",
       "      <td>353.260010</td>\n",
       "      <td>280.829987</td>\n",
       "      <td>126.440002</td>\n",
       "      <td>325.609985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047995</td>\n",
       "      <td>0.039195</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.021278</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>-0.018288</td>\n",
       "      <td>0.048140</td>\n",
       "      <td>7.431202e+09</td>\n",
       "      <td>0.023652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>288.640015</td>\n",
       "      <td>181.710007</td>\n",
       "      <td>124.589996</td>\n",
       "      <td>342.079987</td>\n",
       "      <td>263.109985</td>\n",
       "      <td>123.360001</td>\n",
       "      <td>314.679993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065177</td>\n",
       "      <td>-0.024661</td>\n",
       "      <td>-0.034144</td>\n",
       "      <td>-0.035618</td>\n",
       "      <td>-0.069156</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>-0.031112</td>\n",
       "      <td>-0.007741</td>\n",
       "      <td>7.161201e+09</td>\n",
       "      <td>-0.037010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AAPL_Adj Close  MSFT_Adj Close  MA_Adj Close  V_Adj Close  \\\n",
       "442 2020-10-01      116.588860      212.460007    342.970612   203.350006   \n",
       "443 2020-10-02      112.825348      206.190002    338.435883   201.460007   \n",
       "444 2020-10-05      116.299355      210.380005    342.850769   203.539993   \n",
       "445 2020-10-06      112.965111      205.910004    337.037506   200.449997   \n",
       "446 2020-10-07      114.881805      209.830002    343.500000   202.470001   \n",
       "447 2020-10-08      114.771988      210.580002    345.149994   202.979996   \n",
       "448 2020-10-09      116.768547      215.809998    352.390015   206.639999   \n",
       "449 2020-10-12      124.185753      221.399994    352.040009   206.399994   \n",
       "450 2020-10-13      120.891434      222.860001    345.839996   204.320007   \n",
       "451 2020-10-14      120.981277      220.860001    342.700012   202.199997   \n",
       "452 2020-10-15      120.502106      219.660004    338.570007   199.550003   \n",
       "453 2020-10-16      118.815010      219.660004    339.399994   200.259995   \n",
       "454 2020-10-19      115.780251      214.220001    331.670013   196.970001   \n",
       "455 2020-10-20      117.307617      214.649994    331.720001   197.699997   \n",
       "456 2020-10-21      116.668724      214.800003    333.420013   198.429993   \n",
       "457 2020-10-22      115.550644      214.889999    333.600006   197.990005   \n",
       "458 2020-10-23      114.841873      216.229996    329.609985   198.009995   \n",
       "459 2020-10-26      114.851852      210.080002    318.059998   193.070007   \n",
       "460 2020-10-27      116.399178      213.250000    317.109985   190.059998   \n",
       "461 2020-10-28      111.008476      202.679993    291.380005   180.869995   \n",
       "462 2020-10-29      115.121384      204.720001    293.179993   184.869995   \n",
       "463 2020-10-30      108.672516      202.470001    288.640015   181.710007   \n",
       "\n",
       "     FIS_Adj Close  LRCX_Adj Close  FB_Adj Close  QCOM_Adj Close  \\\n",
       "442     146.869995      339.130005    266.630005      119.519997   \n",
       "443     145.149994      328.709991    259.940002      115.470001   \n",
       "444     145.570007      342.230011    264.649994      120.519997   \n",
       "445     144.369995      340.980011    258.660004      119.540001   \n",
       "446     144.600006      345.769989    258.119995      123.029999   \n",
       "447     146.600006      355.429993    263.760010      122.339996   \n",
       "448     149.029999      362.709991    264.450012      124.870003   \n",
       "449     149.190002      370.109985    275.750000      126.690002   \n",
       "450     145.960007      374.190002    276.140015      127.459999   \n",
       "451     144.070007      374.239990    271.820007      129.880005   \n",
       "452     143.880005      375.489990    266.720001      128.580002   \n",
       "453     143.880005      364.959991    265.929993      129.029999   \n",
       "454     139.779999      363.570007    261.399994      128.419998   \n",
       "455     140.699997      363.570007    267.559998      128.300003   \n",
       "456     141.410004      366.619995    278.730011      128.550003   \n",
       "457     142.720001      358.010010    278.119995      128.380005   \n",
       "458     144.399994      353.920013    284.790009      128.880005   \n",
       "459     139.419998      347.630005    277.109985      126.199997   \n",
       "460     137.860001      343.829987    283.290009      125.910004   \n",
       "461     132.509995      338.899994    267.670013      121.580002   \n",
       "462     125.019997      353.260010    280.829987      126.440002   \n",
       "463     124.589996      342.079987    263.109985      123.360001   \n",
       "\n",
       "     INTU_Adj Close  ...  FB_log_return  QCOM_log_return  INTU_log_return  \\\n",
       "442      331.754517  ...       0.017899         0.015515         0.018617   \n",
       "443      321.322937  ...      -0.025411        -0.034473        -0.031949   \n",
       "444      330.776245  ...       0.017957         0.042805         0.028995   \n",
       "445      324.806793  ...      -0.022894        -0.008165        -0.018212   \n",
       "446      334.320007  ...      -0.002090         0.028777         0.028868   \n",
       "447      334.989990  ...       0.021615        -0.005624         0.002002   \n",
       "448      341.809998  ...       0.002613         0.020469         0.020154   \n",
       "449      350.929993  ...       0.041842         0.014470         0.026332   \n",
       "450      349.589996  ...       0.001413         0.006059        -0.003826   \n",
       "451      345.299988  ...      -0.015768         0.018808        -0.012347   \n",
       "452      341.970001  ...      -0.018941        -0.010060        -0.009691   \n",
       "453      341.149994  ...      -0.002966         0.003494        -0.002401   \n",
       "454      335.269989  ...      -0.017181        -0.004739        -0.017386   \n",
       "455      334.510010  ...       0.023292        -0.000935        -0.002269   \n",
       "456      332.790009  ...       0.040900         0.001947        -0.005155   \n",
       "457      331.820007  ...      -0.002191        -0.001323        -0.002919   \n",
       "458      334.420013  ...       0.023699         0.003887         0.007805   \n",
       "459      328.089996  ...      -0.027338        -0.021014        -0.019110   \n",
       "460      330.269989  ...       0.022057        -0.002301         0.006623   \n",
       "461      318.510010  ...      -0.056716        -0.034995        -0.036257   \n",
       "462      325.609985  ...       0.047995         0.039195         0.022046   \n",
       "463      314.679993  ...      -0.065177        -0.024661        -0.034144   \n",
       "\n",
       "     AMD_log_return  MELI_log_return  G_log_return  MDB_log_return  \\\n",
       "442        0.034406         0.029905     -0.005406        0.018276   \n",
       "443       -0.036726        -0.032819     -0.004398       -0.006211   \n",
       "444        0.051813         0.010369      0.006718        0.018478   \n",
       "445       -0.019575         0.000743     -0.016881        0.031831   \n",
       "446        0.025824         0.047953      0.008346        0.026827   \n",
       "447       -0.002079         0.013334      0.010079       -0.000988   \n",
       "448       -0.040215         0.033449      0.013029        0.024262   \n",
       "449        0.014219         0.013173      0.017860        0.015816   \n",
       "450        0.011677         0.043002     -0.022949        0.018632   \n",
       "451       -0.012626        -0.024301     -0.007169       -0.011100   \n",
       "452       -0.012908         0.015373     -0.003604        0.017494   \n",
       "453        0.000481         0.010667     -0.009587       -0.009569   \n",
       "454       -0.014167         0.009916     -0.026647       -0.007737   \n",
       "455       -0.005380         0.037908     -0.001338       -0.032805   \n",
       "456       -0.029363        -0.026232     -0.011580       -0.031020   \n",
       "457        0.002774        -0.003709      0.001624       -0.012495   \n",
       "458        0.031481         0.013689      0.000541        0.009114   \n",
       "459        0.003289        -0.023690     -0.039978       -0.032373   \n",
       "460       -0.041593         0.000803     -0.007057        0.016154   \n",
       "461       -0.031945        -0.006948     -0.037228       -0.016404   \n",
       "462        0.020982         0.021278      0.006448       -0.018288   \n",
       "463       -0.035618        -0.069156      0.004082       -0.031112   \n",
       "\n",
       "     NXPI_log_return  Portfolio_Value  log_return  \n",
       "442         0.048328     7.599051e+09    0.011688  \n",
       "443        -0.027868     7.380244e+09   -0.029217  \n",
       "444         0.035549     7.570234e+09    0.025417  \n",
       "445        -0.008368     7.409021e+09   -0.021526  \n",
       "446         0.020417     7.544122e+09    0.018070  \n",
       "447         0.009164     7.565862e+09    0.002878  \n",
       "448         0.048497     7.708145e+09    0.018631  \n",
       "449         0.003879     8.006618e+09    0.037991  \n",
       "450        -0.037578     7.930264e+09   -0.009582  \n",
       "451         0.001971     7.894038e+09   -0.004579  \n",
       "452        -0.001752     7.858095e+09   -0.004564  \n",
       "453         0.002627     7.805612e+09   -0.006701  \n",
       "454        -0.006580     7.636255e+09   -0.021936  \n",
       "455        -0.008249     7.692465e+09    0.007334  \n",
       "456         0.004796     7.672447e+09   -0.002606  \n",
       "457        -0.007165     7.634396e+09   -0.004972  \n",
       "458         0.016834     7.644002e+09    0.001257  \n",
       "459        -0.016834     7.530051e+09   -0.015019  \n",
       "460        -0.012383     7.597413e+09    0.008906  \n",
       "461        -0.026313     7.257499e+09   -0.045773  \n",
       "462         0.048140     7.431202e+09    0.023652  \n",
       "463        -0.007741     7.161201e+09   -0.037010  \n",
       "\n",
       "[22 rows x 31 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_2020\n",
    "portfolio_oct=portfolio_opt[portfolio_opt['Date']>\"2020-09-30\"]\n",
    "portfolio_oct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL_Adj Close</th>\n",
       "      <th>MSFT_Adj Close</th>\n",
       "      <th>MA_Adj Close</th>\n",
       "      <th>V_Adj Close</th>\n",
       "      <th>FIS_Adj Close</th>\n",
       "      <th>LRCX_Adj Close</th>\n",
       "      <th>FB_Adj Close</th>\n",
       "      <th>QCOM_Adj Close</th>\n",
       "      <th>INTU_Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th>INTU_log_return</th>\n",
       "      <th>AMD_log_return</th>\n",
       "      <th>MELI_log_return</th>\n",
       "      <th>G_log_return</th>\n",
       "      <th>MDB_log_return</th>\n",
       "      <th>NXPI_log_return</th>\n",
       "      <th>Portfolio_Value</th>\n",
       "      <th>log_return</th>\n",
       "      <th>New Portfolio Return</th>\n",
       "      <th>New Portfolio Log Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>116.588860</td>\n",
       "      <td>212.460007</td>\n",
       "      <td>342.970612</td>\n",
       "      <td>203.350006</td>\n",
       "      <td>146.869995</td>\n",
       "      <td>339.130005</td>\n",
       "      <td>266.630005</td>\n",
       "      <td>119.519997</td>\n",
       "      <td>331.754517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018617</td>\n",
       "      <td>0.034406</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>-0.005406</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.048328</td>\n",
       "      <td>7.599051e+09</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>112.825348</td>\n",
       "      <td>206.190002</td>\n",
       "      <td>338.435883</td>\n",
       "      <td>201.460007</td>\n",
       "      <td>145.149994</td>\n",
       "      <td>328.709991</td>\n",
       "      <td>259.940002</td>\n",
       "      <td>115.470001</td>\n",
       "      <td>321.322937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031949</td>\n",
       "      <td>-0.036726</td>\n",
       "      <td>-0.032819</td>\n",
       "      <td>-0.004398</td>\n",
       "      <td>-0.006211</td>\n",
       "      <td>-0.027868</td>\n",
       "      <td>7.380244e+09</td>\n",
       "      <td>-0.029217</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>116.299355</td>\n",
       "      <td>210.380005</td>\n",
       "      <td>342.850769</td>\n",
       "      <td>203.539993</td>\n",
       "      <td>145.570007</td>\n",
       "      <td>342.230011</td>\n",
       "      <td>264.649994</td>\n",
       "      <td>120.519997</td>\n",
       "      <td>330.776245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028995</td>\n",
       "      <td>0.051813</td>\n",
       "      <td>0.010369</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>0.035549</td>\n",
       "      <td>7.570234e+09</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>112.965111</td>\n",
       "      <td>205.910004</td>\n",
       "      <td>337.037506</td>\n",
       "      <td>200.449997</td>\n",
       "      <td>144.369995</td>\n",
       "      <td>340.980011</td>\n",
       "      <td>258.660004</td>\n",
       "      <td>119.540001</td>\n",
       "      <td>324.806793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018212</td>\n",
       "      <td>-0.019575</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>-0.016881</td>\n",
       "      <td>0.031831</td>\n",
       "      <td>-0.008368</td>\n",
       "      <td>7.409021e+09</td>\n",
       "      <td>-0.021526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>114.881805</td>\n",
       "      <td>209.830002</td>\n",
       "      <td>343.500000</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>144.600006</td>\n",
       "      <td>345.769989</td>\n",
       "      <td>258.119995</td>\n",
       "      <td>123.029999</td>\n",
       "      <td>334.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.025824</td>\n",
       "      <td>0.047953</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.020417</td>\n",
       "      <td>7.544122e+09</td>\n",
       "      <td>0.018070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>114.771988</td>\n",
       "      <td>210.580002</td>\n",
       "      <td>345.149994</td>\n",
       "      <td>202.979996</td>\n",
       "      <td>146.600006</td>\n",
       "      <td>355.429993</td>\n",
       "      <td>263.760010</td>\n",
       "      <td>122.339996</td>\n",
       "      <td>334.989990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>-0.002079</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>0.009164</td>\n",
       "      <td>7.565862e+09</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>116.768547</td>\n",
       "      <td>215.809998</td>\n",
       "      <td>352.390015</td>\n",
       "      <td>206.639999</td>\n",
       "      <td>149.029999</td>\n",
       "      <td>362.709991</td>\n",
       "      <td>264.450012</td>\n",
       "      <td>124.870003</td>\n",
       "      <td>341.809998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020154</td>\n",
       "      <td>-0.040215</td>\n",
       "      <td>0.033449</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>0.024262</td>\n",
       "      <td>0.048497</td>\n",
       "      <td>7.708145e+09</td>\n",
       "      <td>0.018631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>124.185753</td>\n",
       "      <td>221.399994</td>\n",
       "      <td>352.040009</td>\n",
       "      <td>206.399994</td>\n",
       "      <td>149.190002</td>\n",
       "      <td>370.109985</td>\n",
       "      <td>275.750000</td>\n",
       "      <td>126.690002</td>\n",
       "      <td>350.929993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>0.014219</td>\n",
       "      <td>0.013173</td>\n",
       "      <td>0.017860</td>\n",
       "      <td>0.015816</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>8.006618e+09</td>\n",
       "      <td>0.037991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>120.891434</td>\n",
       "      <td>222.860001</td>\n",
       "      <td>345.839996</td>\n",
       "      <td>204.320007</td>\n",
       "      <td>145.960007</td>\n",
       "      <td>374.190002</td>\n",
       "      <td>276.140015</td>\n",
       "      <td>127.459999</td>\n",
       "      <td>349.589996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003826</td>\n",
       "      <td>0.011677</td>\n",
       "      <td>0.043002</td>\n",
       "      <td>-0.022949</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>-0.037578</td>\n",
       "      <td>7.930264e+09</td>\n",
       "      <td>-0.009582</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2020-10-14</td>\n",
       "      <td>120.981277</td>\n",
       "      <td>220.860001</td>\n",
       "      <td>342.700012</td>\n",
       "      <td>202.199997</td>\n",
       "      <td>144.070007</td>\n",
       "      <td>374.239990</td>\n",
       "      <td>271.820007</td>\n",
       "      <td>129.880005</td>\n",
       "      <td>345.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012347</td>\n",
       "      <td>-0.012626</td>\n",
       "      <td>-0.024301</td>\n",
       "      <td>-0.007169</td>\n",
       "      <td>-0.011100</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>7.894038e+09</td>\n",
       "      <td>-0.004579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2020-10-15</td>\n",
       "      <td>120.502106</td>\n",
       "      <td>219.660004</td>\n",
       "      <td>338.570007</td>\n",
       "      <td>199.550003</td>\n",
       "      <td>143.880005</td>\n",
       "      <td>375.489990</td>\n",
       "      <td>266.720001</td>\n",
       "      <td>128.580002</td>\n",
       "      <td>341.970001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009691</td>\n",
       "      <td>-0.012908</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>-0.003604</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>-0.001752</td>\n",
       "      <td>7.858095e+09</td>\n",
       "      <td>-0.004564</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>118.815010</td>\n",
       "      <td>219.660004</td>\n",
       "      <td>339.399994</td>\n",
       "      <td>200.259995</td>\n",
       "      <td>143.880005</td>\n",
       "      <td>364.959991</td>\n",
       "      <td>265.929993</td>\n",
       "      <td>129.029999</td>\n",
       "      <td>341.149994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002401</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>-0.009587</td>\n",
       "      <td>-0.009569</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>7.805612e+09</td>\n",
       "      <td>-0.006701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>115.780251</td>\n",
       "      <td>214.220001</td>\n",
       "      <td>331.670013</td>\n",
       "      <td>196.970001</td>\n",
       "      <td>139.779999</td>\n",
       "      <td>363.570007</td>\n",
       "      <td>261.399994</td>\n",
       "      <td>128.419998</td>\n",
       "      <td>335.269989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017386</td>\n",
       "      <td>-0.014167</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>-0.026647</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>-0.006580</td>\n",
       "      <td>7.636255e+09</td>\n",
       "      <td>-0.021936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>117.307617</td>\n",
       "      <td>214.649994</td>\n",
       "      <td>331.720001</td>\n",
       "      <td>197.699997</td>\n",
       "      <td>140.699997</td>\n",
       "      <td>363.570007</td>\n",
       "      <td>267.559998</td>\n",
       "      <td>128.300003</td>\n",
       "      <td>334.510010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.005380</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>-0.001338</td>\n",
       "      <td>-0.032805</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>7.692465e+09</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>116.668724</td>\n",
       "      <td>214.800003</td>\n",
       "      <td>333.420013</td>\n",
       "      <td>198.429993</td>\n",
       "      <td>141.410004</td>\n",
       "      <td>366.619995</td>\n",
       "      <td>278.730011</td>\n",
       "      <td>128.550003</td>\n",
       "      <td>332.790009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005155</td>\n",
       "      <td>-0.029363</td>\n",
       "      <td>-0.026232</td>\n",
       "      <td>-0.011580</td>\n",
       "      <td>-0.031020</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>7.672447e+09</td>\n",
       "      <td>-0.002606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>115.550644</td>\n",
       "      <td>214.889999</td>\n",
       "      <td>333.600006</td>\n",
       "      <td>197.990005</td>\n",
       "      <td>142.720001</td>\n",
       "      <td>358.010010</td>\n",
       "      <td>278.119995</td>\n",
       "      <td>128.380005</td>\n",
       "      <td>331.820007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002919</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>-0.003709</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>-0.012495</td>\n",
       "      <td>-0.007165</td>\n",
       "      <td>7.634396e+09</td>\n",
       "      <td>-0.004972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>114.841873</td>\n",
       "      <td>216.229996</td>\n",
       "      <td>329.609985</td>\n",
       "      <td>198.009995</td>\n",
       "      <td>144.399994</td>\n",
       "      <td>353.920013</td>\n",
       "      <td>284.790009</td>\n",
       "      <td>128.880005</td>\n",
       "      <td>334.420013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>0.031481</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.009114</td>\n",
       "      <td>0.016834</td>\n",
       "      <td>7.644002e+09</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>318.059998</td>\n",
       "      <td>193.070007</td>\n",
       "      <td>139.419998</td>\n",
       "      <td>347.630005</td>\n",
       "      <td>277.109985</td>\n",
       "      <td>126.199997</td>\n",
       "      <td>328.089996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019110</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>-0.023690</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>-0.032373</td>\n",
       "      <td>-0.016834</td>\n",
       "      <td>7.530051e+09</td>\n",
       "      <td>-0.015019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>317.109985</td>\n",
       "      <td>190.059998</td>\n",
       "      <td>137.860001</td>\n",
       "      <td>343.829987</td>\n",
       "      <td>283.290009</td>\n",
       "      <td>125.910004</td>\n",
       "      <td>330.269989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>-0.041593</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>-0.007057</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>7.597413e+09</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>291.380005</td>\n",
       "      <td>180.869995</td>\n",
       "      <td>132.509995</td>\n",
       "      <td>338.899994</td>\n",
       "      <td>267.670013</td>\n",
       "      <td>121.580002</td>\n",
       "      <td>318.510010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036257</td>\n",
       "      <td>-0.031945</td>\n",
       "      <td>-0.006948</td>\n",
       "      <td>-0.037228</td>\n",
       "      <td>-0.016404</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>7.257499e+09</td>\n",
       "      <td>-0.045773</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>293.179993</td>\n",
       "      <td>184.869995</td>\n",
       "      <td>125.019997</td>\n",
       "      <td>353.260010</td>\n",
       "      <td>280.829987</td>\n",
       "      <td>126.440002</td>\n",
       "      <td>325.609985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.021278</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>-0.018288</td>\n",
       "      <td>0.048140</td>\n",
       "      <td>7.431202e+09</td>\n",
       "      <td>0.023652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>288.640015</td>\n",
       "      <td>181.710007</td>\n",
       "      <td>124.589996</td>\n",
       "      <td>342.079987</td>\n",
       "      <td>263.109985</td>\n",
       "      <td>123.360001</td>\n",
       "      <td>314.679993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034144</td>\n",
       "      <td>-0.035618</td>\n",
       "      <td>-0.069156</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>-0.031112</td>\n",
       "      <td>-0.007741</td>\n",
       "      <td>7.161201e+09</td>\n",
       "      <td>-0.037010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AAPL_Adj Close  MSFT_Adj Close  MA_Adj Close  V_Adj Close  \\\n",
       "442 2020-10-01      116.588860      212.460007    342.970612   203.350006   \n",
       "443 2020-10-02      112.825348      206.190002    338.435883   201.460007   \n",
       "444 2020-10-05      116.299355      210.380005    342.850769   203.539993   \n",
       "445 2020-10-06      112.965111      205.910004    337.037506   200.449997   \n",
       "446 2020-10-07      114.881805      209.830002    343.500000   202.470001   \n",
       "447 2020-10-08      114.771988      210.580002    345.149994   202.979996   \n",
       "448 2020-10-09      116.768547      215.809998    352.390015   206.639999   \n",
       "449 2020-10-12      124.185753      221.399994    352.040009   206.399994   \n",
       "450 2020-10-13      120.891434      222.860001    345.839996   204.320007   \n",
       "451 2020-10-14      120.981277      220.860001    342.700012   202.199997   \n",
       "452 2020-10-15      120.502106      219.660004    338.570007   199.550003   \n",
       "453 2020-10-16      118.815010      219.660004    339.399994   200.259995   \n",
       "454 2020-10-19      115.780251      214.220001    331.670013   196.970001   \n",
       "455 2020-10-20      117.307617      214.649994    331.720001   197.699997   \n",
       "456 2020-10-21      116.668724      214.800003    333.420013   198.429993   \n",
       "457 2020-10-22      115.550644      214.889999    333.600006   197.990005   \n",
       "458 2020-10-23      114.841873      216.229996    329.609985   198.009995   \n",
       "459 2020-10-26      114.851852      210.080002    318.059998   193.070007   \n",
       "460 2020-10-27      116.399178      213.250000    317.109985   190.059998   \n",
       "461 2020-10-28      111.008476      202.679993    291.380005   180.869995   \n",
       "462 2020-10-29      115.121384      204.720001    293.179993   184.869995   \n",
       "463 2020-10-30      108.672516      202.470001    288.640015   181.710007   \n",
       "\n",
       "     FIS_Adj Close  LRCX_Adj Close  FB_Adj Close  QCOM_Adj Close  \\\n",
       "442     146.869995      339.130005    266.630005      119.519997   \n",
       "443     145.149994      328.709991    259.940002      115.470001   \n",
       "444     145.570007      342.230011    264.649994      120.519997   \n",
       "445     144.369995      340.980011    258.660004      119.540001   \n",
       "446     144.600006      345.769989    258.119995      123.029999   \n",
       "447     146.600006      355.429993    263.760010      122.339996   \n",
       "448     149.029999      362.709991    264.450012      124.870003   \n",
       "449     149.190002      370.109985    275.750000      126.690002   \n",
       "450     145.960007      374.190002    276.140015      127.459999   \n",
       "451     144.070007      374.239990    271.820007      129.880005   \n",
       "452     143.880005      375.489990    266.720001      128.580002   \n",
       "453     143.880005      364.959991    265.929993      129.029999   \n",
       "454     139.779999      363.570007    261.399994      128.419998   \n",
       "455     140.699997      363.570007    267.559998      128.300003   \n",
       "456     141.410004      366.619995    278.730011      128.550003   \n",
       "457     142.720001      358.010010    278.119995      128.380005   \n",
       "458     144.399994      353.920013    284.790009      128.880005   \n",
       "459     139.419998      347.630005    277.109985      126.199997   \n",
       "460     137.860001      343.829987    283.290009      125.910004   \n",
       "461     132.509995      338.899994    267.670013      121.580002   \n",
       "462     125.019997      353.260010    280.829987      126.440002   \n",
       "463     124.589996      342.079987    263.109985      123.360001   \n",
       "\n",
       "     INTU_Adj Close  ...  INTU_log_return  AMD_log_return  MELI_log_return  \\\n",
       "442      331.754517  ...         0.018617        0.034406         0.029905   \n",
       "443      321.322937  ...        -0.031949       -0.036726        -0.032819   \n",
       "444      330.776245  ...         0.028995        0.051813         0.010369   \n",
       "445      324.806793  ...        -0.018212       -0.019575         0.000743   \n",
       "446      334.320007  ...         0.028868        0.025824         0.047953   \n",
       "447      334.989990  ...         0.002002       -0.002079         0.013334   \n",
       "448      341.809998  ...         0.020154       -0.040215         0.033449   \n",
       "449      350.929993  ...         0.026332        0.014219         0.013173   \n",
       "450      349.589996  ...        -0.003826        0.011677         0.043002   \n",
       "451      345.299988  ...        -0.012347       -0.012626        -0.024301   \n",
       "452      341.970001  ...        -0.009691       -0.012908         0.015373   \n",
       "453      341.149994  ...        -0.002401        0.000481         0.010667   \n",
       "454      335.269989  ...        -0.017386       -0.014167         0.009916   \n",
       "455      334.510010  ...        -0.002269       -0.005380         0.037908   \n",
       "456      332.790009  ...        -0.005155       -0.029363        -0.026232   \n",
       "457      331.820007  ...        -0.002919        0.002774        -0.003709   \n",
       "458      334.420013  ...         0.007805        0.031481         0.013689   \n",
       "459      328.089996  ...        -0.019110        0.003289        -0.023690   \n",
       "460      330.269989  ...         0.006623       -0.041593         0.000803   \n",
       "461      318.510010  ...        -0.036257       -0.031945        -0.006948   \n",
       "462      325.609985  ...         0.022046        0.020982         0.021278   \n",
       "463      314.679993  ...        -0.034144       -0.035618        -0.069156   \n",
       "\n",
       "     G_log_return  MDB_log_return  NXPI_log_return  Portfolio_Value  \\\n",
       "442     -0.005406        0.018276         0.048328     7.599051e+09   \n",
       "443     -0.004398       -0.006211        -0.027868     7.380244e+09   \n",
       "444      0.006718        0.018478         0.035549     7.570234e+09   \n",
       "445     -0.016881        0.031831        -0.008368     7.409021e+09   \n",
       "446      0.008346        0.026827         0.020417     7.544122e+09   \n",
       "447      0.010079       -0.000988         0.009164     7.565862e+09   \n",
       "448      0.013029        0.024262         0.048497     7.708145e+09   \n",
       "449      0.017860        0.015816         0.003879     8.006618e+09   \n",
       "450     -0.022949        0.018632        -0.037578     7.930264e+09   \n",
       "451     -0.007169       -0.011100         0.001971     7.894038e+09   \n",
       "452     -0.003604        0.017494        -0.001752     7.858095e+09   \n",
       "453     -0.009587       -0.009569         0.002627     7.805612e+09   \n",
       "454     -0.026647       -0.007737        -0.006580     7.636255e+09   \n",
       "455     -0.001338       -0.032805        -0.008249     7.692465e+09   \n",
       "456     -0.011580       -0.031020         0.004796     7.672447e+09   \n",
       "457      0.001624       -0.012495        -0.007165     7.634396e+09   \n",
       "458      0.000541        0.009114         0.016834     7.644002e+09   \n",
       "459     -0.039978       -0.032373        -0.016834     7.530051e+09   \n",
       "460     -0.007057        0.016154        -0.012383     7.597413e+09   \n",
       "461     -0.037228       -0.016404        -0.026313     7.257499e+09   \n",
       "462      0.006448       -0.018288         0.048140     7.431202e+09   \n",
       "463      0.004082       -0.031112        -0.007741     7.161201e+09   \n",
       "\n",
       "     log_return  New Portfolio Return  New Portfolio Log Return  \n",
       "442    0.011688                     0                         0  \n",
       "443   -0.029217                     0                         0  \n",
       "444    0.025417                     0                         0  \n",
       "445   -0.021526                     0                         0  \n",
       "446    0.018070                     0                         0  \n",
       "447    0.002878                     0                         0  \n",
       "448    0.018631                     0                         0  \n",
       "449    0.037991                     0                         0  \n",
       "450   -0.009582                     0                         0  \n",
       "451   -0.004579                     0                         0  \n",
       "452   -0.004564                     0                         0  \n",
       "453   -0.006701                     0                         0  \n",
       "454   -0.021936                     0                         0  \n",
       "455    0.007334                     0                         0  \n",
       "456   -0.002606                     0                         0  \n",
       "457   -0.004972                     0                         0  \n",
       "458    0.001257                     0                         0  \n",
       "459   -0.015019                     0                         0  \n",
       "460    0.008906                     0                         0  \n",
       "461   -0.045773                     0                         0  \n",
       "462    0.023652                     0                         0  \n",
       "463   -0.037010                     0                         0  \n",
       "\n",
       "[22 rows x 33 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "portfolio_oct_adj=copy.deepcopy(portfolio_oct)\n",
    "portfolio_oct_adj['New Portfolio Return']=0\n",
    "portfolio_oct_adj['New Portfolio Log Return']=0\n",
    "portfolio_oct_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_weights=[0.052989947010052996,\n",
    " 0.09256890743109256,\n",
    " 0.15698684301315696,\n",
    " 0.13755986244013754,\n",
    " 0.07476492523507476,\n",
    " 0.0505949494050506,\n",
    " 0.000871999128000872,\n",
    " 0.04057795942204058,\n",
    " 0.19952980047019953,\n",
    " 0.04517395482604517,\n",
    " 0.016147983852016146,\n",
    " 0.0444049555950444,\n",
    " 0.015469984530015468,\n",
    " 0.07235792764207236]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#calculate portfolio return\n",
    "for x in range(14):\n",
    "    portfolio_oct_adj['New Portfolio Return']= portfolio_oct_adj['New Portfolio Return']+(adj_weights[x]*(np.exp(portfolio_oct_adj[tickers_optimal[x]+\"_log_return\"])-1))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#calculate log portfolio return\n",
    "        \n",
    "        \n",
    "\n",
    "portfolio_oct_adj['New Portfolio Log Return']=np.log( portfolio_oct_adj['New Portfolio Return']+1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AAPL_Adj Close</th>\n",
       "      <th>MSFT_Adj Close</th>\n",
       "      <th>MA_Adj Close</th>\n",
       "      <th>V_Adj Close</th>\n",
       "      <th>FIS_Adj Close</th>\n",
       "      <th>LRCX_Adj Close</th>\n",
       "      <th>FB_Adj Close</th>\n",
       "      <th>QCOM_Adj Close</th>\n",
       "      <th>INTU_Adj Close</th>\n",
       "      <th>...</th>\n",
       "      <th>INTU_log_return</th>\n",
       "      <th>AMD_log_return</th>\n",
       "      <th>MELI_log_return</th>\n",
       "      <th>G_log_return</th>\n",
       "      <th>MDB_log_return</th>\n",
       "      <th>NXPI_log_return</th>\n",
       "      <th>Portfolio_Value</th>\n",
       "      <th>log_return</th>\n",
       "      <th>New Portfolio Return</th>\n",
       "      <th>New Portfolio Log Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>116.588860</td>\n",
       "      <td>212.460007</td>\n",
       "      <td>342.970612</td>\n",
       "      <td>203.350006</td>\n",
       "      <td>146.869995</td>\n",
       "      <td>339.130005</td>\n",
       "      <td>266.630005</td>\n",
       "      <td>119.519997</td>\n",
       "      <td>331.754517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018617</td>\n",
       "      <td>0.034406</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>-0.005406</td>\n",
       "      <td>0.018276</td>\n",
       "      <td>0.048328</td>\n",
       "      <td>7.599051e+09</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>0.017178</td>\n",
       "      <td>0.017032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>112.825348</td>\n",
       "      <td>206.190002</td>\n",
       "      <td>338.435883</td>\n",
       "      <td>201.460007</td>\n",
       "      <td>145.149994</td>\n",
       "      <td>328.709991</td>\n",
       "      <td>259.940002</td>\n",
       "      <td>115.470001</td>\n",
       "      <td>321.322937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031949</td>\n",
       "      <td>-0.036726</td>\n",
       "      <td>-0.032819</td>\n",
       "      <td>-0.004398</td>\n",
       "      <td>-0.006211</td>\n",
       "      <td>-0.027868</td>\n",
       "      <td>7.380244e+09</td>\n",
       "      <td>-0.029217</td>\n",
       "      <td>-0.022327</td>\n",
       "      <td>-0.022580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>116.299355</td>\n",
       "      <td>210.380005</td>\n",
       "      <td>342.850769</td>\n",
       "      <td>203.539993</td>\n",
       "      <td>145.570007</td>\n",
       "      <td>342.230011</td>\n",
       "      <td>264.649994</td>\n",
       "      <td>120.519997</td>\n",
       "      <td>330.776245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028995</td>\n",
       "      <td>0.051813</td>\n",
       "      <td>0.010369</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>0.018478</td>\n",
       "      <td>0.035549</td>\n",
       "      <td>7.570234e+09</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>0.022716</td>\n",
       "      <td>0.022462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>112.965111</td>\n",
       "      <td>205.910004</td>\n",
       "      <td>337.037506</td>\n",
       "      <td>200.449997</td>\n",
       "      <td>144.369995</td>\n",
       "      <td>340.980011</td>\n",
       "      <td>258.660004</td>\n",
       "      <td>119.540001</td>\n",
       "      <td>324.806793</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018212</td>\n",
       "      <td>-0.019575</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>-0.016881</td>\n",
       "      <td>0.031831</td>\n",
       "      <td>-0.008368</td>\n",
       "      <td>7.409021e+09</td>\n",
       "      <td>-0.021526</td>\n",
       "      <td>-0.014698</td>\n",
       "      <td>-0.014807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>114.881805</td>\n",
       "      <td>209.830002</td>\n",
       "      <td>343.500000</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>144.600006</td>\n",
       "      <td>345.769989</td>\n",
       "      <td>258.119995</td>\n",
       "      <td>123.029999</td>\n",
       "      <td>334.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028868</td>\n",
       "      <td>0.025824</td>\n",
       "      <td>0.047953</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.020417</td>\n",
       "      <td>7.544122e+09</td>\n",
       "      <td>0.018070</td>\n",
       "      <td>0.019175</td>\n",
       "      <td>0.018993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2020-10-08</td>\n",
       "      <td>114.771988</td>\n",
       "      <td>210.580002</td>\n",
       "      <td>345.149994</td>\n",
       "      <td>202.979996</td>\n",
       "      <td>146.600006</td>\n",
       "      <td>355.429993</td>\n",
       "      <td>263.760010</td>\n",
       "      <td>122.339996</td>\n",
       "      <td>334.989990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>-0.002079</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>-0.000988</td>\n",
       "      <td>0.009164</td>\n",
       "      <td>7.565862e+09</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.005230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2020-10-09</td>\n",
       "      <td>116.768547</td>\n",
       "      <td>215.809998</td>\n",
       "      <td>352.390015</td>\n",
       "      <td>206.639999</td>\n",
       "      <td>149.029999</td>\n",
       "      <td>362.709991</td>\n",
       "      <td>264.450012</td>\n",
       "      <td>124.870003</td>\n",
       "      <td>341.809998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020154</td>\n",
       "      <td>-0.040215</td>\n",
       "      <td>0.033449</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>0.024262</td>\n",
       "      <td>0.048497</td>\n",
       "      <td>7.708145e+09</td>\n",
       "      <td>0.018631</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.019312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>124.185753</td>\n",
       "      <td>221.399994</td>\n",
       "      <td>352.040009</td>\n",
       "      <td>206.399994</td>\n",
       "      <td>149.190002</td>\n",
       "      <td>370.109985</td>\n",
       "      <td>275.750000</td>\n",
       "      <td>126.690002</td>\n",
       "      <td>350.929993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026332</td>\n",
       "      <td>0.014219</td>\n",
       "      <td>0.013173</td>\n",
       "      <td>0.017860</td>\n",
       "      <td>0.015816</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>8.006618e+09</td>\n",
       "      <td>0.037991</td>\n",
       "      <td>0.014702</td>\n",
       "      <td>0.014595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>120.891434</td>\n",
       "      <td>222.860001</td>\n",
       "      <td>345.839996</td>\n",
       "      <td>204.320007</td>\n",
       "      <td>145.960007</td>\n",
       "      <td>374.190002</td>\n",
       "      <td>276.140015</td>\n",
       "      <td>127.459999</td>\n",
       "      <td>349.589996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003826</td>\n",
       "      <td>0.011677</td>\n",
       "      <td>0.043002</td>\n",
       "      <td>-0.022949</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>-0.037578</td>\n",
       "      <td>7.930264e+09</td>\n",
       "      <td>-0.009582</td>\n",
       "      <td>-0.008666</td>\n",
       "      <td>-0.008704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>2020-10-14</td>\n",
       "      <td>120.981277</td>\n",
       "      <td>220.860001</td>\n",
       "      <td>342.700012</td>\n",
       "      <td>202.199997</td>\n",
       "      <td>144.070007</td>\n",
       "      <td>374.239990</td>\n",
       "      <td>271.820007</td>\n",
       "      <td>129.880005</td>\n",
       "      <td>345.299988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012347</td>\n",
       "      <td>-0.012626</td>\n",
       "      <td>-0.024301</td>\n",
       "      <td>-0.007169</td>\n",
       "      <td>-0.011100</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>7.894038e+09</td>\n",
       "      <td>-0.004579</td>\n",
       "      <td>-0.007597</td>\n",
       "      <td>-0.007626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2020-10-15</td>\n",
       "      <td>120.502106</td>\n",
       "      <td>219.660004</td>\n",
       "      <td>338.570007</td>\n",
       "      <td>199.550003</td>\n",
       "      <td>143.880005</td>\n",
       "      <td>375.489990</td>\n",
       "      <td>266.720001</td>\n",
       "      <td>128.580002</td>\n",
       "      <td>341.970001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009691</td>\n",
       "      <td>-0.012908</td>\n",
       "      <td>0.015373</td>\n",
       "      <td>-0.003604</td>\n",
       "      <td>0.017494</td>\n",
       "      <td>-0.001752</td>\n",
       "      <td>7.858095e+09</td>\n",
       "      <td>-0.004564</td>\n",
       "      <td>-0.007026</td>\n",
       "      <td>-0.007051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2020-10-16</td>\n",
       "      <td>118.815010</td>\n",
       "      <td>219.660004</td>\n",
       "      <td>339.399994</td>\n",
       "      <td>200.259995</td>\n",
       "      <td>143.880005</td>\n",
       "      <td>364.959991</td>\n",
       "      <td>265.929993</td>\n",
       "      <td>129.029999</td>\n",
       "      <td>341.149994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002401</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>-0.009587</td>\n",
       "      <td>-0.009569</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>7.805612e+09</td>\n",
       "      <td>-0.006701</td>\n",
       "      <td>-0.001811</td>\n",
       "      <td>-0.001813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>115.780251</td>\n",
       "      <td>214.220001</td>\n",
       "      <td>331.670013</td>\n",
       "      <td>196.970001</td>\n",
       "      <td>139.779999</td>\n",
       "      <td>363.570007</td>\n",
       "      <td>261.399994</td>\n",
       "      <td>128.419998</td>\n",
       "      <td>335.269989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017386</td>\n",
       "      <td>-0.014167</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>-0.026647</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>-0.006580</td>\n",
       "      <td>7.636255e+09</td>\n",
       "      <td>-0.021936</td>\n",
       "      <td>-0.017686</td>\n",
       "      <td>-0.017845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>117.307617</td>\n",
       "      <td>214.649994</td>\n",
       "      <td>331.720001</td>\n",
       "      <td>197.699997</td>\n",
       "      <td>140.699997</td>\n",
       "      <td>363.570007</td>\n",
       "      <td>267.559998</td>\n",
       "      <td>128.300003</td>\n",
       "      <td>334.510010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.005380</td>\n",
       "      <td>0.037908</td>\n",
       "      <td>-0.001338</td>\n",
       "      <td>-0.032805</td>\n",
       "      <td>-0.008249</td>\n",
       "      <td>7.692465e+09</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2020-10-21</td>\n",
       "      <td>116.668724</td>\n",
       "      <td>214.800003</td>\n",
       "      <td>333.420013</td>\n",
       "      <td>198.429993</td>\n",
       "      <td>141.410004</td>\n",
       "      <td>366.619995</td>\n",
       "      <td>278.730011</td>\n",
       "      <td>128.550003</td>\n",
       "      <td>332.790009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005155</td>\n",
       "      <td>-0.029363</td>\n",
       "      <td>-0.026232</td>\n",
       "      <td>-0.011580</td>\n",
       "      <td>-0.031020</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>7.672447e+09</td>\n",
       "      <td>-0.002606</td>\n",
       "      <td>-0.001381</td>\n",
       "      <td>-0.001382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>2020-10-22</td>\n",
       "      <td>115.550644</td>\n",
       "      <td>214.889999</td>\n",
       "      <td>333.600006</td>\n",
       "      <td>197.990005</td>\n",
       "      <td>142.720001</td>\n",
       "      <td>358.010010</td>\n",
       "      <td>278.119995</td>\n",
       "      <td>128.380005</td>\n",
       "      <td>331.820007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002919</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>-0.003709</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>-0.012495</td>\n",
       "      <td>-0.007165</td>\n",
       "      <td>7.634396e+09</td>\n",
       "      <td>-0.004972</td>\n",
       "      <td>-0.002393</td>\n",
       "      <td>-0.002396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>114.841873</td>\n",
       "      <td>216.229996</td>\n",
       "      <td>329.609985</td>\n",
       "      <td>198.009995</td>\n",
       "      <td>144.399994</td>\n",
       "      <td>353.920013</td>\n",
       "      <td>284.790009</td>\n",
       "      <td>128.880005</td>\n",
       "      <td>334.420013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>0.031481</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.009114</td>\n",
       "      <td>0.016834</td>\n",
       "      <td>7.644002e+09</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.003488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2020-10-26</td>\n",
       "      <td>114.851852</td>\n",
       "      <td>210.080002</td>\n",
       "      <td>318.059998</td>\n",
       "      <td>193.070007</td>\n",
       "      <td>139.419998</td>\n",
       "      <td>347.630005</td>\n",
       "      <td>277.109985</td>\n",
       "      <td>126.199997</td>\n",
       "      <td>328.089996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019110</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>-0.023690</td>\n",
       "      <td>-0.039978</td>\n",
       "      <td>-0.032373</td>\n",
       "      <td>-0.016834</td>\n",
       "      <td>7.530051e+09</td>\n",
       "      <td>-0.015019</td>\n",
       "      <td>-0.023353</td>\n",
       "      <td>-0.023630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2020-10-27</td>\n",
       "      <td>116.399178</td>\n",
       "      <td>213.250000</td>\n",
       "      <td>317.109985</td>\n",
       "      <td>190.059998</td>\n",
       "      <td>137.860001</td>\n",
       "      <td>343.829987</td>\n",
       "      <td>283.290009</td>\n",
       "      <td>125.910004</td>\n",
       "      <td>330.269989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>-0.041593</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>-0.007057</td>\n",
       "      <td>0.016154</td>\n",
       "      <td>-0.012383</td>\n",
       "      <td>7.597413e+09</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>-0.003419</td>\n",
       "      <td>-0.003424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>111.008476</td>\n",
       "      <td>202.679993</td>\n",
       "      <td>291.380005</td>\n",
       "      <td>180.869995</td>\n",
       "      <td>132.509995</td>\n",
       "      <td>338.899994</td>\n",
       "      <td>267.670013</td>\n",
       "      <td>121.580002</td>\n",
       "      <td>318.510010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036257</td>\n",
       "      <td>-0.031945</td>\n",
       "      <td>-0.006948</td>\n",
       "      <td>-0.037228</td>\n",
       "      <td>-0.016404</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>7.257499e+09</td>\n",
       "      <td>-0.045773</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>-0.044885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>115.121384</td>\n",
       "      <td>204.720001</td>\n",
       "      <td>293.179993</td>\n",
       "      <td>184.869995</td>\n",
       "      <td>125.019997</td>\n",
       "      <td>353.260010</td>\n",
       "      <td>280.829987</td>\n",
       "      <td>126.440002</td>\n",
       "      <td>325.609985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.020982</td>\n",
       "      <td>0.021278</td>\n",
       "      <td>0.006448</td>\n",
       "      <td>-0.018288</td>\n",
       "      <td>0.048140</td>\n",
       "      <td>7.431202e+09</td>\n",
       "      <td>0.023652</td>\n",
       "      <td>0.015818</td>\n",
       "      <td>0.015694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2020-10-30</td>\n",
       "      <td>108.672516</td>\n",
       "      <td>202.470001</td>\n",
       "      <td>288.640015</td>\n",
       "      <td>181.710007</td>\n",
       "      <td>124.589996</td>\n",
       "      <td>342.079987</td>\n",
       "      <td>263.109985</td>\n",
       "      <td>123.360001</td>\n",
       "      <td>314.679993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034144</td>\n",
       "      <td>-0.035618</td>\n",
       "      <td>-0.069156</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>-0.031112</td>\n",
       "      <td>-0.007741</td>\n",
       "      <td>7.161201e+09</td>\n",
       "      <td>-0.037010</td>\n",
       "      <td>-0.021878</td>\n",
       "      <td>-0.022120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  AAPL_Adj Close  MSFT_Adj Close  MA_Adj Close  V_Adj Close  \\\n",
       "442 2020-10-01      116.588860      212.460007    342.970612   203.350006   \n",
       "443 2020-10-02      112.825348      206.190002    338.435883   201.460007   \n",
       "444 2020-10-05      116.299355      210.380005    342.850769   203.539993   \n",
       "445 2020-10-06      112.965111      205.910004    337.037506   200.449997   \n",
       "446 2020-10-07      114.881805      209.830002    343.500000   202.470001   \n",
       "447 2020-10-08      114.771988      210.580002    345.149994   202.979996   \n",
       "448 2020-10-09      116.768547      215.809998    352.390015   206.639999   \n",
       "449 2020-10-12      124.185753      221.399994    352.040009   206.399994   \n",
       "450 2020-10-13      120.891434      222.860001    345.839996   204.320007   \n",
       "451 2020-10-14      120.981277      220.860001    342.700012   202.199997   \n",
       "452 2020-10-15      120.502106      219.660004    338.570007   199.550003   \n",
       "453 2020-10-16      118.815010      219.660004    339.399994   200.259995   \n",
       "454 2020-10-19      115.780251      214.220001    331.670013   196.970001   \n",
       "455 2020-10-20      117.307617      214.649994    331.720001   197.699997   \n",
       "456 2020-10-21      116.668724      214.800003    333.420013   198.429993   \n",
       "457 2020-10-22      115.550644      214.889999    333.600006   197.990005   \n",
       "458 2020-10-23      114.841873      216.229996    329.609985   198.009995   \n",
       "459 2020-10-26      114.851852      210.080002    318.059998   193.070007   \n",
       "460 2020-10-27      116.399178      213.250000    317.109985   190.059998   \n",
       "461 2020-10-28      111.008476      202.679993    291.380005   180.869995   \n",
       "462 2020-10-29      115.121384      204.720001    293.179993   184.869995   \n",
       "463 2020-10-30      108.672516      202.470001    288.640015   181.710007   \n",
       "\n",
       "     FIS_Adj Close  LRCX_Adj Close  FB_Adj Close  QCOM_Adj Close  \\\n",
       "442     146.869995      339.130005    266.630005      119.519997   \n",
       "443     145.149994      328.709991    259.940002      115.470001   \n",
       "444     145.570007      342.230011    264.649994      120.519997   \n",
       "445     144.369995      340.980011    258.660004      119.540001   \n",
       "446     144.600006      345.769989    258.119995      123.029999   \n",
       "447     146.600006      355.429993    263.760010      122.339996   \n",
       "448     149.029999      362.709991    264.450012      124.870003   \n",
       "449     149.190002      370.109985    275.750000      126.690002   \n",
       "450     145.960007      374.190002    276.140015      127.459999   \n",
       "451     144.070007      374.239990    271.820007      129.880005   \n",
       "452     143.880005      375.489990    266.720001      128.580002   \n",
       "453     143.880005      364.959991    265.929993      129.029999   \n",
       "454     139.779999      363.570007    261.399994      128.419998   \n",
       "455     140.699997      363.570007    267.559998      128.300003   \n",
       "456     141.410004      366.619995    278.730011      128.550003   \n",
       "457     142.720001      358.010010    278.119995      128.380005   \n",
       "458     144.399994      353.920013    284.790009      128.880005   \n",
       "459     139.419998      347.630005    277.109985      126.199997   \n",
       "460     137.860001      343.829987    283.290009      125.910004   \n",
       "461     132.509995      338.899994    267.670013      121.580002   \n",
       "462     125.019997      353.260010    280.829987      126.440002   \n",
       "463     124.589996      342.079987    263.109985      123.360001   \n",
       "\n",
       "     INTU_Adj Close  ...  INTU_log_return  AMD_log_return  MELI_log_return  \\\n",
       "442      331.754517  ...         0.018617        0.034406         0.029905   \n",
       "443      321.322937  ...        -0.031949       -0.036726        -0.032819   \n",
       "444      330.776245  ...         0.028995        0.051813         0.010369   \n",
       "445      324.806793  ...        -0.018212       -0.019575         0.000743   \n",
       "446      334.320007  ...         0.028868        0.025824         0.047953   \n",
       "447      334.989990  ...         0.002002       -0.002079         0.013334   \n",
       "448      341.809998  ...         0.020154       -0.040215         0.033449   \n",
       "449      350.929993  ...         0.026332        0.014219         0.013173   \n",
       "450      349.589996  ...        -0.003826        0.011677         0.043002   \n",
       "451      345.299988  ...        -0.012347       -0.012626        -0.024301   \n",
       "452      341.970001  ...        -0.009691       -0.012908         0.015373   \n",
       "453      341.149994  ...        -0.002401        0.000481         0.010667   \n",
       "454      335.269989  ...        -0.017386       -0.014167         0.009916   \n",
       "455      334.510010  ...        -0.002269       -0.005380         0.037908   \n",
       "456      332.790009  ...        -0.005155       -0.029363        -0.026232   \n",
       "457      331.820007  ...        -0.002919        0.002774        -0.003709   \n",
       "458      334.420013  ...         0.007805        0.031481         0.013689   \n",
       "459      328.089996  ...        -0.019110        0.003289        -0.023690   \n",
       "460      330.269989  ...         0.006623       -0.041593         0.000803   \n",
       "461      318.510010  ...        -0.036257       -0.031945        -0.006948   \n",
       "462      325.609985  ...         0.022046        0.020982         0.021278   \n",
       "463      314.679993  ...        -0.034144       -0.035618        -0.069156   \n",
       "\n",
       "     G_log_return  MDB_log_return  NXPI_log_return  Portfolio_Value  \\\n",
       "442     -0.005406        0.018276         0.048328     7.599051e+09   \n",
       "443     -0.004398       -0.006211        -0.027868     7.380244e+09   \n",
       "444      0.006718        0.018478         0.035549     7.570234e+09   \n",
       "445     -0.016881        0.031831        -0.008368     7.409021e+09   \n",
       "446      0.008346        0.026827         0.020417     7.544122e+09   \n",
       "447      0.010079       -0.000988         0.009164     7.565862e+09   \n",
       "448      0.013029        0.024262         0.048497     7.708145e+09   \n",
       "449      0.017860        0.015816         0.003879     8.006618e+09   \n",
       "450     -0.022949        0.018632        -0.037578     7.930264e+09   \n",
       "451     -0.007169       -0.011100         0.001971     7.894038e+09   \n",
       "452     -0.003604        0.017494        -0.001752     7.858095e+09   \n",
       "453     -0.009587       -0.009569         0.002627     7.805612e+09   \n",
       "454     -0.026647       -0.007737        -0.006580     7.636255e+09   \n",
       "455     -0.001338       -0.032805        -0.008249     7.692465e+09   \n",
       "456     -0.011580       -0.031020         0.004796     7.672447e+09   \n",
       "457      0.001624       -0.012495        -0.007165     7.634396e+09   \n",
       "458      0.000541        0.009114         0.016834     7.644002e+09   \n",
       "459     -0.039978       -0.032373        -0.016834     7.530051e+09   \n",
       "460     -0.007057        0.016154        -0.012383     7.597413e+09   \n",
       "461     -0.037228       -0.016404        -0.026313     7.257499e+09   \n",
       "462      0.006448       -0.018288         0.048140     7.431202e+09   \n",
       "463      0.004082       -0.031112        -0.007741     7.161201e+09   \n",
       "\n",
       "     log_return  New Portfolio Return  New Portfolio Log Return  \n",
       "442    0.011688              0.017178                  0.017032  \n",
       "443   -0.029217             -0.022327                 -0.022580  \n",
       "444    0.025417              0.022716                  0.022462  \n",
       "445   -0.021526             -0.014698                 -0.014807  \n",
       "446    0.018070              0.019175                  0.018993  \n",
       "447    0.002878              0.005243                  0.005230  \n",
       "448    0.018631              0.019500                  0.019312  \n",
       "449    0.037991              0.014702                  0.014595  \n",
       "450   -0.009582             -0.008666                 -0.008704  \n",
       "451   -0.004579             -0.007597                 -0.007626  \n",
       "452   -0.004564             -0.007026                 -0.007051  \n",
       "453   -0.006701             -0.001811                 -0.001813  \n",
       "454   -0.021936             -0.017686                 -0.017845  \n",
       "455    0.007334              0.000669                  0.000669  \n",
       "456   -0.002606             -0.001381                 -0.001382  \n",
       "457   -0.004972             -0.002393                 -0.002396  \n",
       "458    0.001257              0.003494                  0.003488  \n",
       "459   -0.015019             -0.023353                 -0.023630  \n",
       "460    0.008906             -0.003419                 -0.003424  \n",
       "461   -0.045773             -0.043892                 -0.044885  \n",
       "462    0.023652              0.015818                  0.015694  \n",
       "463   -0.037010             -0.021878                 -0.022120  \n",
       "\n",
       "[22 rows x 33 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_oct_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(portfolio_oct_adj['Date'], portfolio_oct_adj['log_return'], 'r--', label='Log returns before adjustments')\n",
    "plt.plot(portfolio_oct_adj['Date'], portfolio_oct_adj['New Portfolio Log Return'], 'b--', label='Log returns after adjustments')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log returns')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=45)\n",
    "plt.title('Log returns in october 2020')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
